[{"title":"Sentinel开源版接入InfluxDB数据持久化并使用Grafana可视化","date":"2021-01-22T00:00:00.000Z","updated":"2021-03-12T08:22:58.450Z","content":"[toc]\n 前言\nSentinel开源版本流量数据保存在内存中，有效期为最近5min，为了能让数据持久化保存并进行中长期分析，参照了一些文章，我们对Sentinel-dashboard流量数据进行改造、接入InfluxDB。\n\n为了阅读上更直观，本文里所有URL已做反转义处理，另，host名为杜撰，改造时请自行带入实际的hostname或ip\n\n 准备工作\n\n\nSentinel源代码\n1git pull git@github.com:alibaba/Sentinel.git\n\n\nInfluxDB 1.8 Docker镜像\n123docker pull influxdb:latest# 笔者从DockerHub拉取时最新的镜像版本为1.8.3，如2.x版本无法使用请使用下方拉取1.8.3版本docker pull influxdb:1.8.3\n\n\n 接入InfluxDB\n\nSentinelDB环境准备\n\n\n安装和权限配置本文不再展开，详细请参阅create database sentinel_db\n\n创建数据库以备使用，在influx命令行或者HTTP调用中\n\ncli\n\n1&gt; create database sentinel_db\n\nHTTP call\n\n1[POST] http://influxdb.idc.hanyuu.demo:8086/query?q=create database sentinel_db\n\n\n在pom.xml中、添加InfluxDB和Lombok（简化开发流程）依赖\n123456789101112131415&lt;!--    lqlu03    使用infulxdb作为数据持久化数据库--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.influxdb&lt;/groupId&gt;    &lt;artifactId&gt;influxdb-java&lt;/artifactId&gt;    &lt;version&gt;2.17&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;    &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;version&gt;1.18.16&lt;/version&gt;    &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;\n\n\n添加数据库工具类\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package com.alibaba.csp.sentinel.dashboard.util;import java.util.List;import java.util.Map;import java.util.Set;import lombok.AllArgsConstructor;import lombok.Data;import lombok.Getter;import lombok.extern.slf4j.Slf4j;import org.influxdb.InfluxDB;import org.influxdb.InfluxDBFactory;import org.influxdb.dto.BoundParameterQuery;import org.influxdb.dto.QueryResult;import org.influxdb.impl.InfluxDBResultMapper;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;/** * @author HanyuuLu * @date 2020-01-14 * * Sentinel */@Data@AllArgsConstructor@Slf4j@Componentpublic class InfluxDBUtils &#123;    private static String url;    private static String username;    private static String password;    private static InfluxDBResultMapper resultMapper = new InfluxDBResultMapper();    @Value(\"$&#123;influxdb.url&#125;\")    public void setUrl(String url) &#123;        InfluxDBUtils.url = url;    &#125;    @Value(\"$&#123;influxdb.username&#125;\")    public void setUsername(String username) &#123;        InfluxDBUtils.username = username;    &#125;    @Value(\"$&#123;influxdb.password&#125;\")    public void setPassword(String password) &#123;        InfluxDBUtils.password = password;    &#125;    public static &lt;T&gt; T process(String database, InfluxDBCallback callback) &#123;        InfluxDB influxDb = null;        T t = null;        try &#123;            influxDb = InfluxDBFactory.connect(url, username, password);            influxDb.setDatabase(database);            t = callback.doCallBack(database, influxDb);        &#125; catch (Exception e) &#123;            log.error(\"[process exception]\", e);        &#125; finally &#123;            if (influxDb != null) &#123;                try &#123;                    influxDb.close();                &#125; catch (Exception e) &#123;                    log.error(\"[influxDB.close exception]\", e);                &#125;            &#125;        &#125;        return t;    &#125;    public static void insert(String database, InfluxDBInsertCallback influxDBInsertCallback) &#123;        process(database, new InfluxDBCallback() &#123;            @Override            public &lt;T&gt; T doCallBack(String database, InfluxDB influxDB) &#123;                influxDBInsertCallback.doCallBack(database, influxDB);                return null;            &#125;        &#125;);    &#125;    public static QueryResult query(String database, InfluxDBQueryCallback influxDBQueryCallback) &#123;        return process(database, new InfluxDBCallback() &#123;            @Override            public &lt;T&gt; T doCallBack(String database, InfluxDB influxDB) &#123;                QueryResult queryResult = influxDBQueryCallback.doCallBack(database, influxDB);                return (T) queryResult;            &#125;        &#125;);    &#125;    public static &lt;T&gt; List&lt;T&gt; queryList(String database, String sql, Map&lt;String, Object&gt; paramMap, Class&lt;T&gt; clasz) &#123;        QueryResult queryResult = query(database, new InfluxDBQueryCallback() &#123;            @Override            public QueryResult doCallBack(String database, InfluxDB influxDB) &#123;                BoundParameterQuery.QueryBuilder queryBuilder = BoundParameterQuery.QueryBuilder.newQuery(sql);                queryBuilder.forDatabase(database);                if (paramMap != null &amp;&amp; paramMap.size() &gt; 0) &#123;                    Set&lt;Map.Entry&lt;String, Object&gt;&gt; entries = paramMap.entrySet();                    for (Map.Entry&lt;String, Object&gt; entry : entries) &#123;                        queryBuilder.bind(entry.getKey(), entry.getValue());                    &#125;                &#125;                return influxDB.query(queryBuilder.create());            &#125;        &#125;);        return resultMapper.toPOJO(queryResult, clasz);    &#125;    public interface InfluxDBCallback &#123;        &lt;T&gt; T doCallBack(String database, InfluxDB influxDB);    &#125;    public interface InfluxDBInsertCallback &#123;        void doCallBack(String database, InfluxDB influxDB);    &#125;    public interface InfluxDBQueryCallback &#123;        QueryResult doCallBack(String database, InfluxDB influxDB);    &#125;&#125;\n\n\nurl、username、password用于存储InfluxDB的连接、用户名、密码信息，定义为static属性，因此在set方法上使用@Value注解从配置文件读取属性值；\n\n\nresultMapper用于查询结果到实体类的映射；\n\n\ninit方法用于初始化url、username、password；\n\n\nprocess为通用的处理方法，负责打开关闭连接，并且调用InfluxDBCallback回调方法；\n\n\ninsert为插入数据方法，配合InfluxDBInsertCallback回调使用；\n\n\nquery为通用的查询方法，配合InfluxDBQueryCallback回调方法使用，返回QueryResult对象；\n\n\nqueryList为查询列表方法，调用query得到QueryResult，再通过resultMapper转换为List&lt;实体类&gt;;\n\n\n在resources目录下的application.properties文件中，增加InfluxDB的配置：\n  123influxdb.url=http://influxdb.idc.hanyuu.demo:8086influxdb.username=usernameinfluxdb.password=p@ssw0rd\n\n\n添加实体类\n 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.alibaba.csp.sentinel.dashboard.datasource.entity.InfluxDb;import java.time.Instant;import org.influxdb.annotation.Column;import org.influxdb.annotation.Measurement;import lombok.Data;/** * @author HanyuuLu * @date 2020-01-14 */@Data@Measurement(name = \"sentinel_metric\")public class MetricPO &#123;    @Column(name = \"time\")    private Instant time;    @Column(name = \"id\")    private Long id;    @Column(name = \"gmtCreate\")    private Long gmtCreate;    @Column(name = \"gmtModified\")    private Long gmtModified;    @Column(name = \"app\", tag = true)    private String app;    @Column(name = \"resource\", tag = true)    private String resource;    @Column(name = \"passQps\")    private Long passQps;    @Column(name = \"successQps\")    private Long successQps;    @Column(name = \"blockQps\")    private Long blockQps;    @Column(name = \"exceptionQps\")    private Long exceptionQps;    @Column(name = \"rt\")    private double rt;    @Column(name = \"count\")    private int count;    @Column(name = \"resourceCode\")    private int resourceCode;&#125;\n该类参考MetricEntity创建，加上influxdb-java包提供的注解，通过@Measurement(name = “sentinel_metric”)指定数据表(measurement)名称，\ntime作为时序数据库的时间列；\napp、resource设置为tag列，通过注解标识为tag=true；\n其它字段为filed列；\n\n\n实现MetricsRepository接口\n\n\n在如下package中，找到接口public interface MetricsRepository&lt;T&gt;,这是一个关于指标数据保存和应用信息查询的借口，我们从这里重写方法以保存到InfluxDB。\n1package com.alibaba.csp.sentinel.dashboard.repository.metric;\n对接口重新进行实现\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214package com.alibaba.csp.sentinel.dashboard.repository.metric;import com.alibaba.csp.sentinel.util.StringUtil;import com.alibaba.csp.sentinel.dashboard.datasource.entity.MetricEntity;import com.alibaba.csp.sentinel.dashboard.datasource.entity.InfluxDb.MetricPO;import com.alibaba.csp.sentinel.dashboard.util.InfluxDBUtils;import org.apache.commons.lang.time.DateFormatUtils;import org.apache.commons.lang.time.DateUtils;import org.influxdb.InfluxDB;import org.influxdb.dto.Point;import org.springframework.stereotype.Repository;import org.springframework.util.CollectionUtils;import java.util.*;import java.util.concurrent.TimeUnit;import java.util.stream.Collectors;/** * metrics数据InfluxDB存储实现 * @author HanyuuLu * @date 2020-01-14 */@Repository(\"influxDBMetricsRepository\")public class InfluxDBMetricsRepository implements MetricsRepository&lt;MetricEntity&gt; &#123;    /**时间格式*/    private static final String DATE_FORMAT_PATTERN = \"yyyy-MM-dd HH:mm:ss.SSS\";    /**数据库名称*/    private static final String SENTINEL_DATABASE = \"sentinel_db\";    /**数据表名称*/    private static final String METRIC_MEASUREMENT = \"sentinel_metric\";    /**北京时间领先UTC时间8小时 UTC: Universal Time Coordinated,世界统一时间*/    private static final Integer UTC_8 = 8;    @Override    public void save(MetricEntity metric) &#123;        if (metric == null || StringUtil.isBlank(metric.getApp())) &#123;            return;        &#125;        InfluxDBUtils.insert(SENTINEL_DATABASE, new InfluxDBUtils.InfluxDBInsertCallback() &#123;            @Override            public void doCallBack(String database, InfluxDB influxDB) &#123;                if (metric.getId() == null) &#123;                    metric.setId(System.currentTimeMillis());                &#125;                doSave(influxDB, metric);            &#125;        &#125;);    &#125;    @Override    public void saveAll(Iterable&lt;MetricEntity&gt; metrics) &#123;        if (metrics == null) &#123;            return;        &#125;        Iterator&lt;MetricEntity&gt; iterator = metrics.iterator();        boolean next = iterator.hasNext();        if (!next) &#123;            return;        &#125;        InfluxDBUtils.insert(SENTINEL_DATABASE, new InfluxDBUtils.InfluxDBInsertCallback() &#123;            @Override            public void doCallBack(String database, InfluxDB influxDB) &#123;                while (iterator.hasNext()) &#123;                    MetricEntity metric = iterator.next();                    if (metric.getId() == null) &#123;                        metric.setId(System.currentTimeMillis());                    &#125;                    doSave(influxDB, metric);                &#125;            &#125;        &#125;);    &#125;    @Override    public List&lt;MetricEntity&gt; queryByAppAndResourceBetween(String app, String resource, long startTime, long endTime) &#123;        List&lt;MetricEntity&gt; results = new ArrayList&lt;MetricEntity&gt;();        if (StringUtil.isBlank(app)) &#123;            return results;        &#125;        if (StringUtil.isBlank(resource)) &#123;            return results;        &#125;        StringBuilder sql = new StringBuilder();        sql.append(\"SELECT * FROM \" + METRIC_MEASUREMENT);        sql.append(\" WHERE app=$app\");        sql.append(\" AND resource=$resource\");        sql.append(\" AND time&gt;=$startTime\");        sql.append(\" AND time&lt;=$endTime\");        Map&lt;String, Object&gt; paramMap = new HashMap&lt;String, Object&gt;();        paramMap.put(\"app\", app);        paramMap.put(\"resource\", resource);        paramMap.put(\"startTime\", DateFormatUtils.format(new Date(startTime), DATE_FORMAT_PATTERN));        paramMap.put(\"endTime\", DateFormatUtils.format(new Date(endTime), DATE_FORMAT_PATTERN));        List&lt;MetricPO&gt; metricPOS = InfluxDBUtils.queryList(SENTINEL_DATABASE, sql.toString(), paramMap, MetricPO.class);        if (CollectionUtils.isEmpty(metricPOS)) &#123;            return results;        &#125;        for (MetricPO metricPO : metricPOS) &#123;            results.add(convertToMetricEntity(metricPO));        &#125;        return results;    &#125;    @Override    public List&lt;String&gt; listResourcesOfApp(String app) &#123;        List&lt;String&gt; results = new ArrayList&lt;&gt;();        if (StringUtil.isBlank(app)) &#123;            return results;        &#125;        StringBuilder sql = new StringBuilder();        sql.append(\"SELECT * FROM \" + METRIC_MEASUREMENT);        sql.append(\" WHERE app=$app\");        sql.append(\" AND time&gt;=$startTime\");        Map&lt;String, Object&gt; paramMap = new HashMap&lt;String, Object&gt;();        long startTime = System.currentTimeMillis() - 1000 * 60;        paramMap.put(\"app\", app);        paramMap.put(\"startTime\", DateFormatUtils.format(new Date(startTime), DATE_FORMAT_PATTERN));        List&lt;MetricPO&gt; metricPOS = InfluxDBUtils.queryList(SENTINEL_DATABASE, sql.toString(), paramMap, MetricPO.class);        if (CollectionUtils.isEmpty(metricPOS)) &#123;            return results;        &#125;        List&lt;MetricEntity&gt; metricEntities = new ArrayList&lt;MetricEntity&gt;();        for (MetricPO metricPO : metricPOS) &#123;            metricEntities.add(convertToMetricEntity(metricPO));        &#125;        Map&lt;String, MetricEntity&gt; resourceCount = new HashMap&lt;&gt;(32);        for (MetricEntity metricEntity : metricEntities) &#123;            String resource = metricEntity.getResource();            if (resourceCount.containsKey(resource)) &#123;                MetricEntity oldEntity = resourceCount.get(resource);                oldEntity.addPassQps(metricEntity.getPassQps());                oldEntity.addRtAndSuccessQps(metricEntity.getRt(), metricEntity.getSuccessQps());                oldEntity.addBlockQps(metricEntity.getBlockQps());                oldEntity.addExceptionQps(metricEntity.getExceptionQps());                oldEntity.addCount(1);            &#125; else &#123;                resourceCount.put(resource, MetricEntity.copyOf(metricEntity));            &#125;        &#125;        // Order by last minute b_qps DESC.        return resourceCount.entrySet()                .stream()                .sorted((o1, o2) -&gt; &#123;                    MetricEntity e1 = o1.getValue();                    MetricEntity e2 = o2.getValue();                    int t = e2.getBlockQps().compareTo(e1.getBlockQps());                    if (t != 0) &#123;                        return t;                    &#125;                    return e2.getPassQps().compareTo(e1.getPassQps());                &#125;)                .map(Map.Entry::getKey)                .collect(Collectors.toList());    &#125;    private MetricEntity convertToMetricEntity(MetricPO metricPO) &#123;        MetricEntity metricEntity = new MetricEntity();        metricEntity.setId(metricPO.getId());        metricEntity.setGmtCreate(new Date(metricPO.getGmtCreate()));        metricEntity.setGmtModified(new Date(metricPO.getGmtModified()));        metricEntity.setApp(metricPO.getApp());        metricEntity.setTimestamp(Date.from(metricPO.getTime().minusMillis(TimeUnit.HOURS.toMillis(UTC_8))));        metricEntity.setResource(metricPO.getResource());        metricEntity.setPassQps(metricPO.getPassQps());        metricEntity.setSuccessQps(metricPO.getSuccessQps());        metricEntity.setBlockQps(metricPO.getBlockQps());        metricEntity.setExceptionQps(metricPO.getExceptionQps());        metricEntity.setRt(metricPO.getRt());        metricEntity.setCount(metricPO.getCount());        return metricEntity;    &#125;    private void doSave(InfluxDB influxDB, MetricEntity metric) &#123;        influxDB.write(Point.measurement(METRIC_MEASUREMENT)                .time(DateUtils.addHours(metric.getTimestamp(), UTC_8).getTime(), TimeUnit.MILLISECONDS)// UTC -&gt; Shanghai(UTC+8) time zone.                .tag(\"app\", metric.getApp())                .tag(\"resource\", metric.getResource())                .addField(\"id\", metric.getId())                .addField(\"gmtCreate\", metric.getGmtCreate().getTime())                .addField(\"gmtModified\", metric.getGmtModified().getTime())                .addField(\"passQps\", metric.getPassQps())                .addField(\"successQps\", metric.getSuccessQps())                .addField(\"blockQps\", metric.getBlockQps())                .addField(\"exceptionQps\", metric.getExceptionQps())                .addField(\"rt\", metric.getRt())                .addField(\"count\", metric.getCount())                .addField(\"resourceCode\", metric.getResourceCode())                .build());    &#125;&#125;\n其中：\nsave、saveAll方法通过调用InfluxDBUtils.insert和InfluxDBInsertCallback回调方法，往sentinel_db库的sentinel_metric数据表写数据；\nsaveAll方法不是循环调用save方法，而是在回调内部循环Iterable metrics处理，这样InfluxDBFactory.connect连接只打开关闭一次；\ndoSave方法中，.time(DateUtils.addHours(metric.getTimestamp(), 8).getTime(), TimeUnit.MILLISECONDS)\n因InfluxDB的UTC时间暂时没找到修改方法，所以这里time时间列加了8个小时时差；\nqueryByAppAndResourceBetween、listResourcesOfApp里面的查询方法，使用InfluxDB提供的类sql语法，编写查询语句即可。\n\n注册Spring Bean,使用@Qualifier指定要使用的bean name\n\n在com.alibaba.csp.sentinel.dashboard.controlle.MetricController、``com.alibaba.csp.sentinel.dashboard.metric.MetricFetcher`类，找到metricStore属性，在@Autowired注解上面加上@Qualifier注解：\n123@Autowired@Qualifier(\"influxDBMetricsRepository\")private MetricsRepository&lt;MetricEntity&gt; metricStore;\n 验证\n\n在需要的工程里接入Sentinel，并启动改造后的Sentinel dashboard\n\n1mvn spring-boot:run [-Pdev]\n证实项目正常启动，若否，通过git记录和上文核对问题并修正\n\n正常打开dashboard，确认有流量流入\n打开InfluxDB，发送HTTP请求查询measurements\n\n1[GET] http://influxdb.idc.hanyuu.demo:8086/query?pretty=true&amp;db=sentinel_db&amp;q=show measurements\n证实measurement已被创建\n1234567891011121314151617181920&#123;  \"results\": [    &#123;      \"statement_id\": 0,      \"series\": [        &#123;          \"name\": \"measurements\",          \"columns\": [            \"name\"          ],          \"values\": [            [              \"sentinel_metric\"            ]          ]        &#125;      ]    &#125;  ]&#125;\n\n查询最新三条记录\n\n1[GET] http://influxdb.idc.hanyuu.demo:8086/query?pretty=true&amp;db=sentinel_db&amp;q=select * from sentinel_metric order by time limit 3\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&#123;  \"results\": [    &#123;      \"statement_id\": 0,      \"series\": [        &#123;          \"name\": \"sentinel_metric\",          \"columns\": [            \"time\",            \"app\",            \"blockQps\",            \"count\",            \"exceptionQps\",            \"gmtCreate\",            \"gmtModified\",            \"id\",            \"passQps\",            \"resource\",            \"resourceCode\",            \"rt\",            \"successQps\"          ],          \"values\": [            [              \"2021-01-21T15:57:28Z\",              \"com.github.hanyuulu.demo.demo.DemoApplication\",              0,              1,              0,              1611215851663,              1611215851663,              1611215862422,              1,              \"/wait\",              47047204,              19,              1            ],            [              \"2021-01-21T15:57:28Z\",              \"com.github.hanyuulu.demo.demo.DemoApplication\",              0,              1,              0,              1611215851663,              1611215851663,              1611215862399,              1,              \"LONG_TIME_CONTROLLER\",              1822368907,              4,              1            ],            [              \"2021-01-21T15:57:29Z\",              \"com.github.hanyuulu.demo.demo.DemoApplication\",              0,              1,              0,              1611215851663,              1611215851663,              1611215856013,              2,              \"/error\",              1442355001,              44,              2            ]          ]        &#125;      ]    &#125;  ]&#125;\n 接入Grafana\n为了更直观的分析数据，我们接入Grafana进行可视化分析\n\n\n通过Docker拉取安装Grafana镜像\n12docker pull grafana/grafanadocker run -d -p 3000:3000 --name grafana grafana/grafana\n\n\n使用默认账户密码admin、admin登陆，创建dashboard，自行创建需要的图表即可，下面简单介绍下各个参数的含义\n\n\n\nfield\nnote\n\n\n\n\ntime\n时间戳\n\n\napp\n接入应用[tag]\n\n\nresource\n资源名称[tag]\n\n\nresourceCode\n资源code\n\n\nid\n聚合id\n\n\ngmtCreate\ngmt创建时间\n\n\ngmtModified\ngmt修改时间\n\n\ncount\n本次聚合的总条数\n\n\nsuccessQps\n成功QPS\n\n\npassQps\n通过QPS\n\n\nblockQps\n阻拦QPS\n\n\nexceptionQPS\n异常QPS\n\n\nrt\n所有成功退出的计数\n\n\n\n 参考文档\n\n\n\n\nsentinel控制台监控数据持久化【InfluxDB】\n\n\nhttps://github.com/alibaba/Sentinel/wiki/控制台\n\n\nhttps://github.com/alibaba/Sentinel/wiki/在生产环境中使用-Sentinel-控制台\n\n\nhttps://docs.influxdata.com/influxdb/v1.6/introduction/getting-started/ InfluxDB官网文档\n\n\nhttps://xtutu.gitbooks.io/influxdb-handbook/content/ InfluxDB简明手册\n\n\n","plink":"hanyuulu.github.io/SentinelInfluxDB改造/"},{"title":"InfluxDB 配置用户权限（Docker）","date":"2021-01-20T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":" 配置InfluxDB容器\n\n拉取镜像\n\n镜像地址：https://hub.docker.com/_/influxdb\n1docker pull influxdb\n\n确认镜像存在\n  1234&gt;   # docker image ls&gt;   REPOSITORY   TAG       IMAGE ID       CREATED      SIZE&gt;   influxdb     latest    0454d5d215cc   7 days ago   307MB&gt;\n\n\n运行\n\n 1docker run -d --name influxDB -p 8086:8086 influxdb:latest\n\n确认容器存活\n  1234&gt;   # docker container ls&gt;   CONTAINER ID   IMAGE      COMMAND                  CREATED          STATUS         PORTS                    NAMES&gt;   **********   influxdb   \"/entrypoint.sh infl…\"   48 minutes ago   Up 8 minutes   0.0.0.0:8086-&gt;8086/tcp   influxdb&gt;\n\nInfluxDB远程访问默认不需要权限校验，在生产环境中显然不合适，下面配置用户权限\n 配置用户权限\n12345678# 进入容器# docker exec -it influxdb /bin/bashroot@07a5ee195563:/# influxConnected to http://localhost:8086 version 1.8.3InfluxDB shell version: 1.8.3#创建用户并赋予所有权限&gt; create user \"admin\" with password 'p@ssword'&gt; grant all privileges to admin\n 启用权限验证\n12345678910111213root@07a5ee195563:/# echo /etc/influxdb/influxdb.conf/etc/influxdb/influxdb.confroot@07a5ee195563:/# cat /etc/influxdb/influxdb.conf[meta]  dir = \"/var/lib/influxdb/meta\"[data]  dir = \"/var/lib/influxdb/data\"  engine = \"tsm1\"  wal-dir = \"/var/lib/influxdb/wal\"[http]  auth-enabled = true\n\n重启服务即可\n\n1docker restart influxDB\n 常用命令参考\n12345678910111213141516# 显示用户SHOW USERS# 创建用户CREATE USER \"username\" WITH PASSWORD 'password'# 赋予用户管理员权限GRANT ALL PRIVILEGES TO username# 创建管理员权限的用户CREATE USER &lt;username&gt; WITH PASSWORD '&lt;password&gt;' WITH ALL PRIVILEGES# 修改用户密码SET PASSWORD FOR username = 'password'# 撤消权限REVOKE ALL ON mydb FROM username# 查看权限SHOW GRANTS FOR username# 删除用户DROP USER \"username\"\n","plink":"hanyuulu.github.io/InfluxDB 配置用户权限（Docker）/"},{"title":"Spring MVC 拦截器规则的“例外”问题","date":"2021-01-17T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":" 问题描述\n在一个Spring boot 1.5.x工程（业务逻辑，URL等均已变更成不影响问题描述和解决但是和原工程毫无关系）中，我们有如下几个Controller的URL\n123SALARY_IMPORT_URL = \"/api/hr/salary/import\"SALARY_EXPORT_URL = \"/api/hr/salary/export\"# 其他URL\n由于一些原因，我们的项目中使用了拦截器（用于校验登录信息），原拦截逻辑如下：\n\n默认拦截所有URL\n所有&quot;/api&quot;开头的URL添加例外\n\n因为业务需要，我们需要校验访问SALARY_IMPORT_URL和SALARY_EXPORT_URLURL的权限，所以新的拦截逻辑应当如下：\n\n默认拦截所有URL\n所有&quot;/api&quot;开头的URL添加例外\n&quot;/api/hr/salary/import&quot;和&quot;/api/hr/salary/export&quot;需要拦截\n\n显然，逻辑3和逻辑2有干涉\n原代码\n12345interceptorRegistry.addInterceptor(loginInterceptor)    .addPathPatterns(\"/**\")    .excludePathPatterns(\"/api/**\");interceptorRegistry.addInterceptor(loginInterceptor).addPathPatterns(whiteList);\n一开始的想法\n12345678910SALARY_IMPORT_URL = \"/api/hr/salary/import\"SALARY_EXPORT_URL = \"/api/hr/salary/export\"interceptorRegistry.addInterceptor(loginInterceptor)    .addPathPatterns(\"/**\")    .excludePathPatterns(\"/api/**\")    .addPathPatterns(SALARY_IMPORT_URL)    .addPathPatterns(SALARY_EXPORT_URL);interceptorRegistry.addInterceptor(loginInterceptor).addPathPatterns(whiteList);\n然而这两个URL依然没有被拦截，通过多方查证，在同事的帮助下，终于抽干了脑子里的水。\n添加后的代码\n1234567SALARY_IMPORT_URL = \"/api/hr/salary/import\"SALARY_EXPORT_URL = \"/api/hr/salary/export\"interceptorRegistry.addInterceptor(loginInterceptor)    .addPathPatterns(\"/**\")    .excludePathPatterns(\"/api/**\");interceptorRegistry.addInterceptor(loginInterceptor).addPathPatterns(SALARY_IMPORT_URL,SALARY_EXPORT_URL);\n成功添加了“例外”。\n一些基本原理之类的之后补，太晚了要睡觉了~\n 参考资料\n\nSpring doc\n\n","plink":"hanyuulu.github.io/InterceptorSpringMVC/"},{"title":"数据结构-跳表（Skip List）","date":"2020-11-24T00:00:00.000Z","updated":"2021-03-12T08:22:58.594Z","content":"loading…\n 参考\n\nSkip List–跳表（全网最详细的跳表文章没有之一）\n\n","plink":"hanyuulu.github.io/skip_list/"},{"title":"Elastic Search 学习","date":"2020-11-20T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" Elastic Search 学习\n12from elasticsearch import Elasticsearch as ESes = ES('http://localhost',port = 9200)\n12345import requests as rimport jsondef url(src:str)-&gt;str:    return f'http://localhost:9200&#123;src&#125;?pretty=true'p = &#123;\"pretty\":\"true\"&#125;\n\n本文档包含了从快速部署开始到一些较为高级的用法的演示和说明，使用环境是Windows，使用Power Shell作为命令行环境，在jupyter notebook中进行测试\n\n 快速部署（Docker）\n1234# 安装Elasticsearchdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.3# 运行单节点docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:7.9.3 --name elastic_search\n\n测试cluster\n\n1print(r.get(url('/')).text)\n{\n  &quot;name&quot; : &quot;f0a5b2ffad4a&quot;,\n  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,\n  &quot;cluster_uuid&quot; : &quot;NIdw38XdQBi5rmtiroeIVA&quot;,\n  &quot;version&quot; : {\n    &quot;number&quot; : &quot;7.9.2&quot;,\n    &quot;build_flavor&quot; : &quot;default&quot;,\n    &quot;build_type&quot; : &quot;docker&quot;,\n    &quot;build_hash&quot; : &quot;d34da0ea4a966c4e49417f2da2f244e3e97b4e6e&quot;,\n    &quot;build_date&quot; : &quot;2020-09-23T00:45:33.626720Z&quot;,\n    &quot;build_snapshot&quot; : false,\n    &quot;lucene_version&quot; : &quot;8.6.2&quot;,\n    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,\n    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;\n  },\n  &quot;tagline&quot; : &quot;You Know, for Search&quot;\n}\n\n 安装Kibana\n12345docker pull docker.elastic.co/kibana/kibana:7.9.3# 启动容器并链接elasticsearchdocker run --link elastic_search:elasticsearch -p 5601:5601 docker.elastic.co/kibana/kibana:7.9.3# 测试Kibana# 浏览器能访问5601端口即可\n 基本概念\n Node &amp; Cluster\nElastic 是一个分布式数据库，单个Elastic实例为一个节点（Node），若干节点组成一个集群（Cluster）。\n Index\n类似于SQL数据库的database,索引（Index）是数据管理的一级单位，index名必须小写\nElastic索引所有字段，经过处理后产生一个反向索引（Inverted Index）用以在查询的时候搜索文档。\n\n新建一个索引\n\n1print(r.put(url('/todo')).text)\n{\n  &quot;error&quot; : {\n    &quot;root_cause&quot; : [\n      {\n        &quot;type&quot; : &quot;resource_already_exists_exception&quot;,\n        &quot;reason&quot; : &quot;index [todo/BShbis0RR3aA-X3wdcD2cQ] already exists&quot;,\n        &quot;index_uuid&quot; : &quot;BShbis0RR3aA-X3wdcD2cQ&quot;,\n        &quot;index&quot; : &quot;todo&quot;\n      }\n    ],\n    &quot;type&quot; : &quot;resource_already_exists_exception&quot;,\n    &quot;reason&quot; : &quot;index [todo/BShbis0RR3aA-X3wdcD2cQ] already exists&quot;,\n    &quot;index_uuid&quot; : &quot;BShbis0RR3aA-X3wdcD2cQ&quot;,\n    &quot;index&quot; : &quot;todo&quot;\n  },\n  &quot;status&quot; : 400\n}\n\n\n删除一个索引\n\n1print(r.delete(url('/todo')).text)\n{\n  &quot;acknowledged&quot; : true\n}\n\n\n查阅Node下所有Index\n\n1print(r.get(url('/_cat/indices')).text)\ngreen  open .kibana-event-log-7.9.2-000001 6z4diegrSYusecVp-8YnJA 1 0     1  0   5.5kb   5.5kb\ngreen  open .apm-custom-link               70A0r6x_To2MvZXsyGUTlA 1 0     0  0    208b    208b\ngreen  open .kibana_task_manager_1         Bn7h59PXSQqqWaJT21idlw 1 0     6 68 137.9kb 137.9kb\ngreen  open .kibana-event-log-7.9.2-000002 KDsEyuhwR6K1pngNoseQag 1 0     1  0   5.5kb   5.5kb\ngreen  open .apm-agent-configuration       XhYtj6-qRpC8-TLAo85ZYg 1 0     0  0    208b    208b\ngreen  open kibana_sample_data_logs        0Ov2Tb15QYOHrSAhd5VbvQ 1 0 14074  0  10.3mb  10.3mb\nyellow open gb                             zgJK4tsDR96ok9yXBFfOBA 1 1     1  0     5kb     5kb\ngreen  open .async-search                  S6V9_mcIRO2ADOl3ZZB7kw 1 0     0  0    234b    234b\ngreen  open .kibana_1                      eYLHd8UzTcOupTc_QJRIEQ 1 0    73  0  10.4mb  10.4mb\nyellow open us                             w6zNSJ7uQta8gsbPnpkTUw 1 1     1  0     5kb     5kb\n\n Type\n文档的虚拟的逻辑分组，可以用于过滤文档，一个索引下的文档应当具有相似的结构（Schema）\n Document\n文档（Document）类似SQL数据库里的一个记录（Record），一个索引由多个文档组成。\n 接口和功能说明\n 文档操作演示\n\n尝试建立并查询一个索引，以此加深对Index，Type和Document的概念\n\n12345678910111213# 新建一个docprint(r.put(url('/todo/things/0'),json=&#123;    'title':'待办事项A',    'priority':0.6,    'date':'2020-11-01',    'assignment':['aicy','rin']&#125;).text)print(r.put(url('/todo/things/1'),json=&#123;    'title':'待办事项B_backup',    'priority':0.5,    'date':'2020-11-02',    'assignment':['hanyuu','rin']&#125;).text)\n{\n  &quot;_index&quot; : &quot;todo&quot;,\n  &quot;_type&quot; : &quot;things&quot;,\n  &quot;_id&quot; : &quot;0&quot;,\n  &quot;_version&quot; : 1,\n  &quot;result&quot; : &quot;created&quot;,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 2,\n    &quot;successful&quot; : 1,\n    &quot;failed&quot; : 0\n  },\n  &quot;_seq_no&quot; : 0,\n  &quot;_primary_term&quot; : 1\n}\n\n{\n  &quot;_index&quot; : &quot;todo&quot;,\n  &quot;_type&quot; : &quot;things&quot;,\n  &quot;_id&quot; : &quot;1&quot;,\n  &quot;_version&quot; : 1,\n  &quot;result&quot; : &quot;created&quot;,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 2,\n    &quot;successful&quot; : 1,\n    &quot;failed&quot; : 0\n  },\n  &quot;_seq_no&quot; : 1,\n  &quot;_primary_term&quot; : 1\n}\n\n123456print(r.post(url('/todo/things/'),json=&#123;    'title':'待办事项C',    'priority':0.8,    'date':'2020-11-02',    'assignment':['aicy','rin']&#125;).text)\n{\n  &quot;_index&quot; : &quot;todo&quot;,\n  &quot;_type&quot; : &quot;things&quot;,\n  &quot;_id&quot; : &quot;qLE2A3YBPtTv4vAuC6e7&quot;,\n  &quot;_version&quot; : 1,\n  &quot;result&quot; : &quot;created&quot;,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 2,\n    &quot;successful&quot; : 1,\n    &quot;failed&quot; : 0\n  },\n  &quot;_seq_no&quot; : 2,\n  &quot;_primary_term&quot; : 1\n}\n\n12# 查询docprint(r.get(url('/todo/things/0')).text)\n{\n  &quot;_index&quot; : &quot;todo&quot;,\n  &quot;_type&quot; : &quot;things&quot;,\n  &quot;_id&quot; : &quot;0&quot;,\n  &quot;_version&quot; : 1,\n  &quot;_seq_no&quot; : 0,\n  &quot;_primary_term&quot; : 1,\n  &quot;found&quot; : true,\n  &quot;_source&quot; : {\n    &quot;title&quot; : &quot;待办事项A&quot;,\n    &quot;priority&quot; : 0.6,\n    &quot;date&quot; : &quot;2020-11-01&quot;,\n    &quot;assignment&quot; : [\n      &quot;aicy&quot;,\n      &quot;rin&quot;\n    ]\n  }\n}\n\n12# 查询schemaprint(r.get(url('/todo/')).text)\n{\n  &quot;todo&quot; : {\n    &quot;aliases&quot; : { },\n    &quot;mappings&quot; : {\n      &quot;properties&quot; : {\n        &quot;assignment&quot; : {\n          &quot;type&quot; : &quot;text&quot;,\n          &quot;fields&quot; : {\n            &quot;keyword&quot; : {\n              &quot;type&quot; : &quot;keyword&quot;,\n              &quot;ignore_above&quot; : 256\n            }\n          }\n        },\n        &quot;date&quot; : {\n          &quot;type&quot; : &quot;date&quot;\n        },\n        &quot;priority&quot; : {\n          &quot;type&quot; : &quot;float&quot;\n        },\n        &quot;title&quot; : {\n          &quot;type&quot; : &quot;text&quot;,\n          &quot;fields&quot; : {\n            &quot;keyword&quot; : {\n              &quot;type&quot; : &quot;keyword&quot;,\n              &quot;ignore_above&quot; : 256\n            }\n          }\n        }\n      }\n    },\n    &quot;settings&quot; : {\n      &quot;index&quot; : {\n        &quot;creation_date&quot; : &quot;1606371641662&quot;,\n        &quot;number_of_shards&quot; : &quot;1&quot;,\n        &quot;number_of_replicas&quot; : &quot;1&quot;,\n        &quot;uuid&quot; : &quot;aKIUpjivSWGDCrgYoWUy0w&quot;,\n        &quot;version&quot; : {\n          &quot;created&quot; : &quot;7090299&quot;\n        },\n        &quot;provided_name&quot; : &quot;todo&quot;\n      }\n    }\n  }\n}\n\n\n使用post可以不指定ip新增文档，elastic回返回一个随机字符串\n使用PUT，POST，GET，DELETE动词进行新增，更新，查询，删除操作\n\n 数据查询\n 返回所有记录\n1print(r.get(url('/todo/things/_search')).text)\n{\n  &quot;took&quot; : 3,\n  &quot;timed_out&quot; : false,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 1,\n    &quot;successful&quot; : 1,\n    &quot;skipped&quot; : 0,\n    &quot;failed&quot; : 0\n  },\n  &quot;hits&quot; : {\n    &quot;total&quot; : {\n      &quot;value&quot; : 0,\n      &quot;relation&quot; : &quot;eq&quot;\n    },\n    &quot;max_score&quot; : null,\n    &quot;hits&quot; : [ ]\n  }\n}\n\n12# 轻量搜索print(r.get(url('/todo/things/_search?q=title:\"待办事项B_backup\"'),params = p).text)\n{\n  &quot;took&quot; : 287,\n  &quot;timed_out&quot; : false,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 1,\n    &quot;successful&quot; : 1,\n    &quot;skipped&quot; : 0,\n    &quot;failed&quot; : 0\n  },\n  &quot;hits&quot; : {\n    &quot;total&quot; : {\n      &quot;value&quot; : 0,\n      &quot;relation&quot; : &quot;eq&quot;\n    },\n    &quot;max_score&quot; : null,\n    &quot;hits&quot; : [ ]\n  }\n}\n\n 全文搜索\n\nelastic使用DSL进行索引\n\n12345678910# 搜索单字段print(r.get(url(\"/todo/things/_search\"),json = &#123;    \"query\": &#123;    \"match\": &#123;        \"title\": \"待办事项\"    &#125;    &#125;,    \"from\": 0,    \"size\": 10&#125;).text)\n{\n  &quot;took&quot; : 22,\n  &quot;timed_out&quot; : false,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 1,\n    &quot;successful&quot; : 1,\n    &quot;skipped&quot; : 0,\n    &quot;failed&quot; : 0\n  },\n  &quot;hits&quot; : {\n    &quot;total&quot; : {\n      &quot;value&quot; : 3,\n      &quot;relation&quot; : &quot;eq&quot;\n    },\n    &quot;max_score&quot; : 0.53412557,\n    &quot;hits&quot; : [\n      {\n        &quot;_index&quot; : &quot;todo&quot;,\n        &quot;_type&quot; : &quot;things&quot;,\n        &quot;_id&quot; : &quot;0&quot;,\n        &quot;_score&quot; : 0.53412557,\n        &quot;_source&quot; : {\n          &quot;title&quot; : &quot;待办事项A&quot;,\n          &quot;priority&quot; : 0.6,\n          &quot;date&quot; : &quot;2020-11-01&quot;,\n          &quot;assignment&quot; : [\n            &quot;aicy&quot;,\n            &quot;rin&quot;\n          ]\n        }\n      },\n      {\n        &quot;_index&quot; : &quot;todo&quot;,\n        &quot;_type&quot; : &quot;things&quot;,\n        &quot;_id&quot; : &quot;1&quot;,\n        &quot;_score&quot; : 0.53412557,\n        &quot;_source&quot; : {\n          &quot;title&quot; : &quot;待办事项B_backup&quot;,\n          &quot;priority&quot; : 0.5,\n          &quot;date&quot; : &quot;2020-11-02&quot;,\n          &quot;assignment&quot; : [\n            &quot;hanyuu&quot;,\n            &quot;rin&quot;\n          ]\n        }\n      },\n      {\n        &quot;_index&quot; : &quot;todo&quot;,\n        &quot;_type&quot; : &quot;things&quot;,\n        &quot;_id&quot; : &quot;qLE2A3YBPtTv4vAuC6e7&quot;,\n        &quot;_score&quot; : 0.53412557,\n        &quot;_source&quot; : {\n          &quot;title&quot; : &quot;待办事项C&quot;,\n          &quot;priority&quot; : 0.8,\n          &quot;date&quot; : &quot;2020-11-02&quot;,\n          &quot;assignment&quot; : [\n            &quot;aicy&quot;,\n            &quot;rin&quot;\n          ]\n        }\n      }\n    ]\n  }\n}\n\n12345678910111213141516171819202122# 搜索多字段print(r.get(url('/todo/things/_search'),json = &#123;    \"query\":&#123;        \"bool\":&#123;            \"must\":&#123;                \"multi_match\":&#123;                \"query\":\"hanyuu\",                \"fields\":[                    \"title\",\"assignment\"                ]                &#125;            &#125;,            \"should\":&#123;                \"range\":&#123;                    \"priority\":&#123;                        \"gt\":0.2                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;).text)\n{\n  &quot;took&quot; : 2,\n  &quot;timed_out&quot; : false,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 1,\n    &quot;successful&quot; : 1,\n    &quot;skipped&quot; : 0,\n    &quot;failed&quot; : 0\n  },\n  &quot;hits&quot; : {\n    &quot;total&quot; : {\n      &quot;value&quot; : 1,\n      &quot;relation&quot; : &quot;eq&quot;\n    },\n    &quot;max_score&quot; : 1.9808291,\n    &quot;hits&quot; : [\n      {\n        &quot;_index&quot; : &quot;todo&quot;,\n        &quot;_type&quot; : &quot;things&quot;,\n        &quot;_id&quot; : &quot;1&quot;,\n        &quot;_score&quot; : 1.9808291,\n        &quot;_source&quot; : {\n          &quot;title&quot; : &quot;待办事项B_backup&quot;,\n          &quot;priority&quot; : 0.5,\n          &quot;date&quot; : &quot;2020-11-02&quot;,\n          &quot;assignment&quot; : [\n            &quot;hanyuu&quot;,\n            &quot;rin&quot;\n          ]\n        }\n      }\n    ]\n  }\n}\n\n 多条件搜索逻辑运算\n123456789101112131415161718# 与逻辑print(r.get(url('/todo/things/_search'),json = &#123;    \"query\":&#123;        \"bool\":&#123;            \"must\":[                &#123;                    \"match\":&#123;                        \"title\":\"待办事项\"                    &#125;,                    \"match\":                    &#123;                        \"priority\": 0.5                    &#125;                &#125;            ]        &#125;    &#125;&#125;).text)\n{\n  &quot;took&quot; : 6,\n  &quot;timed_out&quot; : false,\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 1,\n    &quot;successful&quot; : 1,\n    &quot;skipped&quot; : 0,\n    &quot;failed&quot; : 0\n  },\n  &quot;hits&quot; : {\n    &quot;total&quot; : {\n      &quot;value&quot; : 1,\n      &quot;relation&quot; : &quot;eq&quot;\n    },\n    &quot;max_score&quot; : 1.0,\n    &quot;hits&quot; : [\n      {\n        &quot;_index&quot; : &quot;todo&quot;,\n        &quot;_type&quot; : &quot;things&quot;,\n        &quot;_id&quot; : &quot;1&quot;,\n        &quot;_score&quot; : 1.0,\n        &quot;_source&quot; : {\n          &quot;title&quot; : &quot;待办事项B_backup&quot;,\n          &quot;priority&quot; : 0.5,\n          &quot;date&quot; : &quot;2020-11-02&quot;,\n          &quot;assignment&quot; : [\n            &quot;hanyuu&quot;,\n            &quot;rin&quot;\n          ]\n        }\n      }\n    ]\n  }\n}\n\n1234567# SQLprint(r.post(url('/_sql'),params = &#123;\"format\":\"txt\"&#125;,json = &#123;    \"query\":\"select title,priority from todo where priority&gt;0\"&#125;).text)print(r.post(url('/_sql'),json = &#123;    \"query\":\"select title,priority from todo where priority&gt;0\"&#125;).text)\n     title     |     priority     \n---------------+------------------\nå¾\n\nåäºé¡¹A          |0.6000000238418579\nå¾\nåäºé¡¹B_backup   |0.5\nå¾\nåäºé¡¹C          |0.800000011920929\n{\n  &quot;columns&quot; : [\n    {\n      &quot;name&quot; : &quot;title&quot;,\n      &quot;type&quot; : &quot;text&quot;\n    },\n    {\n      &quot;name&quot; : &quot;priority&quot;,\n      &quot;type&quot; : &quot;float&quot;\n    }\n  ],\n  &quot;rows&quot; : [\n    [\n      &quot;待办事项A&quot;,\n      0.6000000238418579\n    ],\n    [\n      &quot;待办事项B_backup&quot;,\n      0.5\n    ],\n    [\n      &quot;待办事项C&quot;,\n      0.800000011920929\n    ]\n  ]\n}\n\n 合法性和错误提示以及合法解释\n12345678910111213141516171819202122print(r.get(url('/todo/things/_validate/query'),params = &#123;\"explain\":\"true\"&#125;,json = &#123;        \"query\":&#123;        \"bool\":&#123;            \"must\":&#123;                \"multi_match\":&#123;                \"query\":\"hanyuu\",                \"fields\":[                    \"title\",\"assignment\"                ]                &#125;            &#125;,            \"should\":&#123;                \"range\":&#123;                    \"priority\":&#123;                        \"gt\":0.2                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;).text)\n{\n  &quot;_shards&quot; : {\n    &quot;total&quot; : 1,\n    &quot;successful&quot; : 1,\n    &quot;failed&quot; : 0\n  },\n  &quot;valid&quot; : true,\n  &quot;explanations&quot; : [\n    {\n      &quot;index&quot; : &quot;todo&quot;,\n      &quot;valid&quot; : true,\n      &quot;explanation&quot; : &quot;+(+(assignment:hanyuu | title:hanyuu) priority:[0.20000002 TO Infinity]) #*:*&quot;\n    }\n  ]\n}\n\n 排序与相关性\n Elastic Search中的数据结构\n\n\n\n数据结构\n优缺点\n\n\n\n\n排序列表Array/List\n使用二分法查找，不平衡\n\n\nHashMap/TreeMap\n性能高，内存消耗大，几乎是原始数据的三倍\n\n\nSkip List\n跳跃表，可快速查找词语，在lucene、redis、Hbase等均有实现。相对于TreeMap等结构，特别适合高并发场景（Skip List介绍）\n\n\nTrie\n适合英文词典，如果系统中存在大量字符串且这些字符串基本没有公共前缀，则相应的trie树将非常消耗内存（数据结构之trie树）\n\n\nDouble Array Trie\n适合做中文词典，内存占用小，很多分词工具均采用此种算法（深入双数组Trie）\n\n\nTernary Search Tree\n三叉树，每一个node有3个节点，兼具省空间和查询快的优点（Ternary Search Tree）\n\n\nFinite State Transducers (FST)\n一种有限状态转移机，Lucene 4有开源实现，并大量使用\n\n\n\n Kibana\n 参考文档\n\nElasticsearch: The Definitive Guide by Clinton Gormley and Zachary Tong (O’Reilly). Copyright 2015 Elasticsearch BV, 978-1-449-35854-9。\nInstall Elasticsearch with Docker\n全文搜索引擎 Elasticsearch 入门教程 - 知乎 (zhihu.com)\nElasticSearch中的数据结构\n\n","plink":"hanyuulu.github.io/elasticsearch_study/"},{"title":"在Spring中获取当前环境字符串","date":"2020-11-12T00:00:00.000Z","updated":"2021-03-12T08:22:58.594Z","content":" Spring程序在运行时获取激活的配置\n1234567891011121314151617181920212223package com.demo;import lombok.val;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.ApplicationContext;import org.springframework.test.context.ActiveProfiles;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@ActiveProfiles(&#123;\"dev\"&#125;)public class ProfileTest &#123;    @Autowired    ApplicationContext applicationContext;    @Test    public void test()    &#123;        val res = applicationContext.getEnvironment().getActiveProfiles()[0];        System.out.println(res);    &#125;&#125;\n输出\ndev\n","plink":"hanyuulu.github.io/spring_profile_activate/"},{"title":".NET Core 应用打包和部署到docker上的一些注意事项","date":"2020-10-28T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":"[toc]\n 环境概要\n本文档使用\n\n.NET Core 3.1.401 win-x64\nDocker Community win-x64\n\nDocker Engine 19.03.13\n\n\n\n 打包\n 自带依赖发布到目标平台\n\n例子\n\n1dotnet publish -r linux-x64 --configuration Release\n\n\n说明\n\n\npublish命令会自动restore依赖\n\n\nconfiguration分为Debug和Release，建议使用Release发布应用（并配置对应的配置文件）\n\n\n-r：要编译的目标平台，具体请参阅.NET Core 运行时标识符 (RID) 目录 | Microsoft Docs\n一些常用的RID如下\n\n\n\n可移植（.NET Core 2.0 或更高版本）\n\n\nwin-x64\n\n\nwin-x86\n\n\nwin-arm\n\n\nwin-arm64\n\n\nlinux-x64（大多数桌面发行版，如 CentOS、Debian、Fedora、Ubuntu 及派生版本）\n\n\nlinux-musl-x64（使用 musl 的轻量级发行版，如 Alpine Linux）\n\n\nlinux-arm（在 ARM 上运行的 Linux 发行版本，如 Raspberry Pi Model 2 及更高版本上的 Raspbian）\n\n\nlinux-arm64（在 64 位 ARM 上运行的 Linux 发行版本，如 Raspberry Pi Model 3 及更高版本上的 Ubuntu 服务器 64 位）\n\n\nosx-x64（最低 OS 版本为 macOS 10.12 Sierra）\n\n\n\n\n\n\n\n\n\n 打包程序为单文件\n添加参数-p:PublishSingleFile=true\n1dotnet publish -r linux-x64 --configuration Release -p:PublishSingleFile=true\n 裁剪未使用的依赖\n\n从 .NET Core 3.0 开始，SDK 作为预览功能提供。此功能可能会导致问题，如果发现问题请尝试不启用此参数\n\n添加参数-p:PublishTrimmed=true\n1dotnet publish -r linux-x64 --configuration Release -p:PublishSingleFile=true -p:PublishTrimmed=true\n\n-p 参数也可写在配置文件中，请参阅dotnet publish 命令 - .NET Core CLI | Microsoft Docs和用于 ASP.NET Core 应用部署的 Visual Studio 发布配置文件 (.pubxml) | Microsoft Docs\n\n .NET Core 发布后在Ubuntu基础镜像上运行的常见问题\n\n\n提示没有icu依赖\nicu是ASP.NET Core在Linux系统上的全球化实现，Docker基础镜像默认无此依赖，需要在打包镜像时先安装依赖，参照全球化和 ICU | Microsoft Docs\n\n\n提示没有合适版本的libssl\nUbuntu基础镜像缺省libssl版本对.NET Core 3不兼容\n\n\n解决方案：参考如下Dockerfile，使用国内镜像安装依赖\n1234567FROM ubuntu:latestADD ./KoroneLibrary/bin/Release/netcoreapp3.1/linux-x64/publish/  /ADD ./sources.list /etc/apt/sources.listRUN chmod 744 /KoroneLibrary &amp;&amp; apt update &amp;&amp; apt upgrade -y &amp;&amp; apt install icu-devtools -y &amp;&amp; apt install libssl1.1 -y &amp;&amp; apt auto-remove -y &amp;&amp; apt clean -yCMD [\"/KoroneLibrary\"]VOLUME [\"/Lib\"]EXPOSE 5000\n 参考文档\n\ndotnet publish 命令 - .NET Core CLI | Microsoft Docs\n\n","plink":"hanyuulu.github.io/dotnetcore_docker_icu/"},{"title":"Python进程池、线程池和进程间通信实践参考","date":"2020-08-21T00:00:00.000Z","updated":"2021-03-12T08:22:58.614Z","content":" 业务需求\n业务中有一个计算量比较大的、可以并行执行的操作，为了提升资源利用率，故考虑多进程分配。\n性能：多线程&lt;线程池&lt;多进程&lt;进程池\n\n在Windows中创建一个进程耗费的时间以秒计算，故要避免频繁的进程创建销毁\n\n 业务流程\n\n一个数据产生源，串行产生数据，速度快\n数据源产生的数据需要比较长的时间进行计算才能得到结果\n所有结果要汇总起来进行过滤和处理最终发放下游服务器\n\n 结构设计\n\n每个核心分配一个处理进程、附加两个低资源占用低工作进程负责产生数据和发送数据\n使用阻塞式的多进程间队列\n\n当任务队列满时数据产生进程阻塞暂时不产生数据（处理不及时）\n当结果队列满时数据处理队列阻塞不产生数据（网络问题或故障）\n\n网络请求使用多线程发送，避免过多资源占用低同时保证请求异步不阻塞\n\n\n\n\n抽离业务代码的进程池和多线程设计代码如下\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import osimport multiprocessingimport threadingimport timeimport json# 发送请求地址CONNECTION_URL = 'url:'# CPU核心数CPU_COUNT = os.cpu_count()# 工作进程数PROC_COUNT = CPU_COUNT + 2# 发送更新数据请求def upload(msg: dict):    r = requests.post(CONNECTION_URL, json=msg)# 多进程任务def process(i, frameQueue, resQueue):     print(f\"[proc &#123;i&#125;] pid &#123;os.getpid()&#125;\")    # fetch frame and push to work queqe    if i == 0:\t\t\twhile True:        #.do some work        frame =.work()      \tframeQueue.put(frame)    # fetch result from resQueue and post it to server by multthreading    elif i == 1:        while True:            res = resQueue.get()            # do some work            data = work2(res)            # 多线程发送请求            threading.Thread(target=upload, args=(data,)).start()   # data processer process, cost many resources and require multprocessing to speed up    else:        while True:            frame = frameQueue.get()            res = work3(frame)            resQueue.put(res)def client():    print(f\"Process :&#123;PROC_COUNT&#125;\")    # 进程池创建    pool = multiprocessing.Pool(PROC_COUNT)    # 任务队列    frameQueue = multiprocessing.Manager().Queue(PROC_COUNT)    # 结果队列    resQueue = multiprocessing.Manager().Queue(PROC_COUNT)    # 给进程池分配函数    for i in range(PROC_COUNT):        pool.apply_async(            process, (i, frameQueue, resQueue))    # 关闭进程池不再接受新进程    pool.close()    # 阻塞主进程    pool.join()    print(\"finish\")if __name__ == '__main__':    client()\n","plink":"hanyuulu.github.io/thread_process_pool/"},{"title":"Spring生态学习笔记","date":"2020-07-13T00:00:00.000Z","updated":"2021-03-12T08:22:58.594Z","content":"[toc]\n 概览\n 体系结构\n\n 核心容器\n核心容器由核心，Bean，上下文和表达式语言模块组成，它们的细节如下：\n\n核心模块提供了框架的基本组成部分，包括 IoC 和依赖注入功能。\nBean 模块提供 BeanFactory，它是一个工厂模式的复杂实现。\n上下文模块建立在由核心和 Bean 模块提供的坚实基础上，它是访问定义和配置的任何对象的媒介。ApplicationContext 接口是上下文模块的重点。\n表达式语言模块在运行时提供了查询和操作一个对象图的强大的表达式语言。\n\n 数据访问/集成\n数据访问/集成层包括 JDBC，ORM，OXM，JMS 和事务处理模块，它们的细节如下：\n\nJDBC 模块提供了删除冗余的 JDBC 相关编码的 JDBC 抽象层。\nORM 模块为流行的对象关系映射 API，包括 JPA，JDO，Hibernate 和 iBatis，提供了集成层。\nOXM 模块提供了抽象层，它支持对 JAXB，Castor，XMLBeans，JiBX 和 XStream 的对象/XML 映射实现。\nJava 消息服务 JMS 模块包含生产和消费的信息的功能。\n事务模块为实现特殊接口的类及所有的 POJO 支持编程式和声明式事务管理。\n\n Web\nWeb 层由 Web，Web-MVC，Web-Socket 和 Web-Portlet 组成，它们的细节如下：\n\nWeb 模块提供了基本的面向 web 的集成功能，例如多个文件上传的功能和使用 servlet 监听器和面向 web 应用程序的上下文来初始化 IoC 容器。\nWeb-MVC 模块包含 Spring 的模型-视图-控制器（MVC），实现了 web 应用程序。\nWeb-Socket 模块为 WebSocket-based 提供了支持，而且在 web 应用程序中提供了客户端和服务器端之间通信的两种方式。\nWeb-Portlet 模块提供了在 portlet 环境中实现 MVC，并且反映了 Web-Servlet 模块的功能。\n\n 其他\n还有其他一些重要的模块，像 AOP，Aspects，Instrumentation，Web 和测试模块，它们的细节如下：\n\nAOP 模块提供了面向方面的编程实现，允许你定义方法拦截器和切入点对代码进行干净地解耦，它实现了应该分离的功能。\nAspects 模块提供了与 AspectJ 的集成，这是一个功能强大且成熟的面向切面编程（AOP）框架。\nInstrumentation 模块在一定的应用服务器中提供了类 instrumentation 的支持和类加载器的实现。\nMessaging 模块为 STOMP 提供了支持作为在应用程序中 WebSocket 子协议的使用。它也支持一个注解编程模型，它是为了选路和处理来自 WebSocket 客户端的 STOMP 信息。\n测试模块支持对具有 JUnit 或 TestNG 框架的 Spring 组件的测试。\n\n IOC\n BeanFactory容器\nHelloWorld.java\n12345678910package com.hanyuu;public class HelloWorld &#123;   private String message;   public void setMessage(String message)&#123;    this.message  = message;   &#125;   public void getMessage()&#123;    System.out.println(\"Your Message : \" + message);   &#125;&#125;\nMain.java\n123456789101112package com.hanyuu;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.core.io.ClassPathResource;public class MainApp &#123;   public static void main(String[] args) &#123;      XmlBeanFactory factory = new XmlBeanFactory                             (new ClassPathResource(\"Beans.xml\"));      HelloWorld obj = (HelloWorld) factory.getBean(\"helloWorld\");      obj.getMessage();   &#125;&#125;\nBeans.xml\n1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xsi:schemaLocation=\"http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\"&gt;   &lt;bean id=\"helloWorld\" class=\"com.hanyuu.HelloWorld\"&gt;       &lt;property name=\"message\" value=\"Hello World!\"/&gt;   &lt;/bean&gt;&lt;/beans&gt;\n ApplicationContent容器\n\nApplicationContent 接口实现\n\nFileSystemXmlApplicationContext：使用文件完整路径加载bean\nClassPathXmlApplicationContext：在ClassPath中搜索（只需要提供文件名）\nWebXmlApplicationContext：该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean。\n\n\n\nStudent.java\n12345678910package com.hanyuu.test;import lombok.Data;@Datapublic class Student &#123;   private Integer age;   private String name;&#125;\nDemoApplication.java\n123456789101112131415161718192021222324package com.hanyuu.test;import java.io.BufferedWriter;import java.io.File;import java.io.FileWriter;import java.util.Date;import javax.sound.midi.SysexMessage;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext;@SpringBootApplicationpublic class DemoApplication &#123;\tpublic static void main(final String[] args) &#123;\t\t\t\tfinal ApplicationContext applicationContext = new FileSystemXmlApplicationContext(\"beans.xml\");\t\tfinal Student student = (Student) applicationContext.getBean(\"student\");\t\tSystem.out.println(\"Name : \" + student.getName());\t\tSystem.out.println(\"Age : \" + student.getAge());\t&#125;\nbeans.xml\n12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xmlns:context=\"http://www.springframework.org/schema/context\"    xsi:schemaLocation=\"http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd    http://www.springframework.org/schema/context    http://www.springframework.org/schema/context/spring-context-3.0.xsd\"&gt;   &lt;context:annotation-config/&gt;   &lt;!-- bean definitions go here --&gt;   &lt;!-- Definition for student bean --&gt;   &lt;bean id=\"student\" class=\"com.hanyuu.test.Student\"&gt;      &lt;property name=\"name\"  value=\"Hanyuu\" /&gt;      &lt;property name=\"age\"  value=\"3\"/&gt;   &lt;/bean&gt;&lt;/beans&gt;\n Bean 定义\n\n\n\n属性\n描述\n\n\n\n\nclass\n强制性，并且指定用来创建 bean 的 bean 类。\n\n\nname\n指定唯一的 bean 标识符。在基于 XML 的配置元数据中，你可以使用 ID 和/或 name 属性来指定 bean 标识符。\n\n\nscope\n指定由特定的 bean 定义创建的对象的作用域\n\n\nconstructor-arg\n注入依赖关系\n\n\nproperties\n注入依赖关系\n\n\nautowiring mode\n注入依赖关系\n\n\nlazy-initialization mode\n延迟初始化\n\n\ninitialization 方法\n在 bean 的所有必需的属性被容器设置之后，调用回调方法\n\n\ndestruction 方法\n当包含该 bean 的容器被销毁时，使用回调方法\n\n\n\n 配置元数据来源\n\n基于 XML 的配置文件。\n基于注解的配置\n基于 Java 的配置\n\n xml样例\n123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xsi:schemaLocation=\"http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\"&gt;   &lt;!-- A simple bean definition --&gt;   &lt;bean id=\"...\" class=\"...\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- A bean definition with lazy init set on --&gt;   &lt;bean id=\"...\" class=\"...\" lazy-init=\"true\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- A bean definition with initialization method --&gt;   &lt;bean id=\"...\" class=\"...\" init-method=\"...\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- A bean definition with destruction method --&gt;   &lt;bean id=\"...\" class=\"...\" destroy-method=\"...\"&gt;       &lt;!-- collaborators and configuration for this bean go here --&gt;   &lt;/bean&gt;   &lt;!-- more bean definitions go here --&gt;&lt;/beans&gt;\n 区别\n\n\n功能\n\nBeanFactory提供了最简单的功能（实例化对象和获取对象）\nApplicationContent提供了MessageSource（国际化）、ResourceLoader（资源访问）、载入多个上下文、ApplicationEventPublisher（消息发送、响应机制）和AOP（拦截器）\n\n\n\n加载机制\n\nBeanFactory懒加载\nApplicationContext启动时全部加载\n\n\n\n 作用域（Scope）\n\n\n\n作用域\n描述\n\n\n\n\nsingleton\n该作用域将 bean 的定义的限制在每一个 Spring IoC 容器中的一个单一实例(默认)。\n\n\nprototype\n该作用域将单一 bean 的定义限制在任意数量的对象实例。\n\n\nrequest\n该作用域将 bean 的定义限制为 HTTP 请求。只在 web-aware Spring ApplicationContext 的上下文中有效。\n\n\nsession\n该作用域将 bean 的定义限制为 HTTP 会话。 只在web-aware Spring ApplicationContext的上下文中有效。\n\n\nglobal-session\n该作用域将 bean 的定义限制为全局 HTTP 会话。只在 web-aware Spring ApplicationContext 的上下文中有效。\n\n\n\n Reference\n\n\nhttps://wiki.jikexueyuan.com/project/spring/\n\n\nhttps://blog.csdn.net/pythias_/article/details/82752881\n\n\n","plink":"hanyuulu.github.io/springLearn/"},{"title":"Oracle数据库复习提纲","date":"2020-06-20T00:00:00.000Z","updated":"2021-03-12T08:22:58.566Z","content":"[toc]\n Introduction\n\n Instance\np10\nAn Oracle instance:\n\nIs a means to access an Oracle database\nAlways opens one and only one database\nConsists of memory and process structures\n\n Database\np12\nAn Oracle database:\n\nIs a collection of data that is treated as a unit\nConsists of three file types\n\nData files\nControl files\nRedo log files\n\n\n\n Physical Structure\np13\nThe physical structure of an Oracle database is determined by the operating system files that provide the actual physical storage for database information.\n\nControl files\nData files(includes data dictionary)\nRedo log files\n\n Memory Structure\nP14\nOracle’s memory structure consists of two memory areas known as:\n SGA\nSystem Global Area (SGA): Allocated at instance startup, and is a fundamental component of an Oracle Instance\n\n\nThe SGA consists of several memory structures:\n\n\nShared pool\n\n\nDatabase buffer cache\n\n\nRedo log buffer\n\n\nOther structures (e.g. lock and latch management, statistical data)\n\n\nThere are two optional memory structures that can be configured within the SGA:\n\nLarge pool\nJava pool\n\n\n\nSGA is dynamic and sized using SGA_MAX_SIZE.\n\n\nSGA memory allocated and tracked in granules by SGA components\n\nContiguous virtual memory allocation\nSize based on SGA_MAX_SIZE\n\n\n\n Shared Pool\nThe shared pool is used to store the most recently executed SQL statements and the most recently used data definitions.\n\nIt consists of two key performance-related memory structures:\n\nLibrary cache\nData dictionary cache\n\n\nSized by the parameter SHARED_POOL_SIZE.\n\n Library Cache\nThe library cache stores information about the most recently used SQL and PL/SQL statements. The library cache:\n\nEnables the sharing of commonly used statements\nIs managed by a least recently used (LRU) algorithm\nConsists of two structures:\n\nShared SQL area\nShared PL/SQL area\n\n\nHas its size determined by the shared pool sizing\n\n Data Dictionary Cache\n\nThe data dictionary cache is a collection of the most recently used definitions in the database.\n\nIt includes information about database files, tables, indexes, columns, users, privileges, and other database objects.\nDuring the parse phase, the server process looks at the data dictionary for information to resolve object names and validate access.\nCaching the data dictionary information into memory improves response time on queries.\nSize is determined by the shared pool sizing.\n\n\n\n Database Buffer Cache\nThe database buffer cache stores copies of data blocks that have been retrieved from the data files. • It enables great performance gains when you obtain and update data.\n\nIt is managed through a least recently used (LRU) algorithm.\nDB_BLOCK_SIZE determines the primary block size.\n\n Redo Log Buffer Cache\nThe redo log buffer cache records all changes made to the database data blocks.\n\nIts primary purpose is recovery.\nChanges recorded within are called redo entries.\nRedo entries contain information to reconstruct or redo changes.\nSize is defined by LOG_BUFFER.\n\n Large Pool\nThe large pool is an optional area of memory in the SGA configured only in a shared server environment.\n\n\nIt relieves the burden placed on the shared pool.\n\n\nThis configured memory area is used for session memory (UGA), I/O slaves, and backup and restore operations.\n\n\nUnlike the shared pool, the large pool does not use an LRU list.\n\n\nSized by LARGE_POOL_SIZE.\nALTER SYSTEM SET LARGE_POOL_SIZE = 64M;\n\n\n Java Pool\nThe Java pool services the parsing requirements for Java commands.\n\nRequired if installing and using Java.\nIt is stored much the same way as PL/SQL in database tables.\nIt is sized by the JAVA_POOL_SIZE parameter.\n\n PGA\np25\nProgram Global Area (PGA): Allocated when the server process is started\nThe PGA is memory reserved for each user process that connects to an Oracle database\n Process Structure\nAn Oracle process is a program that depending on its type can request information, execute a series of steps, or perform a specific task.\nOracle takes advantage of various types of processes:\n\n\nUser process: Started at the time a database user requests connection to the Oracle server\n\nA user process is a program that requests interaction with the Oracle server.\n\nIt must first establish a connection.\nIt does not interact directly with the Oracle server.\n\n\n\n\n\nServer process: Connects to the Oracle Instance and is started when a user establishes a session.\nA server process is a program that directly interacts with the Oracle server.\n\nIt fulfills calls generated and returns results.\nCan be dedicated or shared server.\n\n\n\nBackground process: Available when an Oracle instance is started\nThe relationship between the physical and memory structures is maintained and enforced by Oracle’s background processes\n\nMandatory background processes\n\nDBWn PMON CKPT LGWR SMON RECO P29\n\n\nOptional background processes\n\nARCn LMON Snnn QMNn LMDn CJQ0 Pnnn LCKn Dnnn P35\n\n\n\n\n\n Logical Structure\np36\nThe logical structure of the Oracle architecture dictates how the physical space of a database is to be used.\nA hierarchy exists in this structure that consists of tablespaces, segments, extents, and blocks.\n\n Processing a SQL Statement\n\nConnect to an instance using:\n\nThe user process\nThe server process\n\n\nThe Oracle server components that are used depend on the type of SQL statement:\n\nQueries return rows.\nDML statements log changes.\nCommit ensures transaction recovery.\n\n\nSome Oracle server components do not participate in SQL statement processing.\n\n Oracle Server\n Database Administration Tools\nP42\n Managing Oracle Instances\np60\n Initialization Parameter Files\n\n\nEntries are specific to the instance being accessed\nThere are two kinds of parameters:\n\nExplicit: Having an entry in the file\nImplicit: No entry within the file, but assuming the Oracle default values\n\n\nMultiple files can be used for a single database to optimize performance in different situations.\nChanges to entries in the file take effect based on the type of initialization parameter file used;\n\nStatic parameter file, PFILE\nPersistent parameter file, SPFILE\n\n\n\n PFILE initSID.ora\n\n\nThe PFILE is a text file that can be modified with an operating system editor.\n\n\nModifications to the file are made manually.\n\n\nChanges to the file take effect on the next startup. • Its default location is $ORACLE_HOME/dbs.\n\n\nexample\n123456789101112131415# Initialization Parameter File: initdb01.oradb_name = db01instance_name = db01control_files = ( /u03/oradata/db01/control01db01.ctl,/u03/oradata/db01/control02db01.ctl)db_block_size = 4096db_block_buffers = 500shared_pool_size = 31457280 # 30M Shared Pooldb_files = 1024max_dump_file_size = 10240background_dump_dest = /u05/oracle9i/admin/db01/bdumpuser_dump_dest = /u05/oracle9i/admin/db01/udumpcore_dump_dest = /u05/oracle9i/admin/db01/cdumpundo_management = autoundo_tablespace = undtbs\n\n\n SPFILE spfileSID.ora\np66\n\n\nBinary file with the ability to make changes persistent across shutdown and startup\n\n\nMaintained by the Oracle server\n\n\nRecords parameter value changes made with the ALTER SYSTEM command\n\n\nCan specify whether the change being made is temporary or persistent\n\n\nValues can be deleted or reset to allow an instance to revert to the default value\nALTER SYSTEM SET undo_tablespace = 'UNDO2';\n\n\nSPFILE can be created from an initSID.ora file using the CREATE SPFILE command, which can be executed before or after instance startup:\nSPFILE FROM PFILE;```12*   example\n*.background_dump_dest=‘ORACLEHOME/admin/db01/bdump′∗.compatible=′9.0.0′∗.controlfiles=′/u03/oradata/db01/ctrl01db01.ctl′,′/u03/oradata/db01/ctrl02db01.ctl′∗.coredumpdest=′ORACLE_HOME/admin/db01/bdump&#x27;\n*.compatible=&#x27;9.0.0&#x27;\n*.control_files=&#x27;/u03/oradata/db01/ctrl01db01.ctl&#x27;,&#x27;/u03/orad\nata/db01/ctrl02db01.ctl&#x27;\n*.core_dump_dest=&#x27;ORACLEH​OME/admin/db01/bdump′∗.compatible=′9.0.0′∗.controlf​iles=′/u03/oradata/db01/ctrl01db01.ctl′,′/u03/oradata/db01/ctrl02db01.ctl′∗.cored​umpd​est=′ORACLE_HOME/admin/db01/cdump’\n*.db_block_buffers=500\n*.db_block_size=4096\n*.db_files=40\n*.db_name=‘db01’\n*.instance_name=‘db01’\n*.remote_login_passwordfile=‘exclusive’\n*.shared_pool_size=31457280 # 30M Shared Pool\n*.undo_management=‘AUTO’\ndb01.undo_tablespace=‘UNDOTBS01’\ndb02.undo_tablespace=‘UNDOTBS02’\n12345678910111213141516171819### Oracle Managed Filesp69Oracle Managed Files (OMF) simplify file administration*   OMF are created and deleted by the Oracle server as directed by SQL commands*   OMF are established by setting two parameters:    *   DB_CREATE_FILE_DEST: Set to give the default location for data files     *   DB_CREATE_ONLINE_LOG_DEST_N: Set to give the default locations for online redo logs and control files, up to a maximum of 5 locations## Starting Up a Databasep73![image-20200621165731327](oracle_review/image-20200621165731327.png)### Start up the instance and open the database:\n\n\nSTARTUP\nSTARTUP PFILE=$ORACLE_HOME/dbs/initdb01.ora\n123456### The ALTER DATABASE Command*   Change the state of the database from NOMOUNT to MOUNT:```ALTER DATABASE db01 MOUNT;\n\nOpen the database as a read–only database:\n\nDATABASE db01 OPEN READ ONLY;```123456### Opening a Database in Restricted Mode*   Use the STARTUP command to restrict access to a database:``` STARTUP RESTRICT\n\nUse the ALTER SYSTEM command to place an instance in restricted mode:\n\nSYSTEM ENABLE RESTRICTED SESSION;```1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Opening a Database in Read-Only Mode*   A databases can be   opened as a read-only database.*   A read-only database can be used to:    *   Execute queries    *   Execute disk sorts using locally managed tablespaces    *   Take data files offline and online, not tablespaces    *   Perform recovery of offline data files and tablespaces### Shutting Down the Databasep78![image-20200621194559674](oracle_review/image-20200621194559674.png)### Managing an Instance by Monitoring Diagnostic Filesp81### Alert Log FileThe alertSID.log file records the commands and Results of major events while the database is operational.### Background Trace FilesBackground trace files support information errors detected by any background process.### User Trace FileA user trace file is produced by the user process connected to the Oracle server through the server process.# Create Databasep88## Creation Prerequisitesp91To create a new database, you must have the following:*   A privileged account authenticated in one of the following ways:    *   By the operating system    *   Using a password file*   Sufficient memory to start the instance*   Sufficient disk space for the planned database## Planning Database File Locations## Creating a Databasep93base can be created using:*   Oracle Database Configuration Assistant*   The CREATE DATABASE command An Oracle datab## Operating System Environment### PATH\nORACLE_BASE\nORACLE_HOME\nORACLE_SID\nORA_NLS33\nPATH\nsLD_LIBRARY_PATH\n\n##  Database Configuration Assistant\n\np95\n\n## Database Information\n\np97\n\nSpecify: \n\n*   Global database name and SID\n*   The features you want to use for your database, such as:\n    *   Oracle Spatial\n    *   Oracle OLAP Services\n    *   Example Schemas\n*   Mode in which you want the database to operate\n    *   Dedicated server mode\n    *   Shared server mode\n\n## Other Parameters\n\n*   Archive Parameters\n    *   Use for database recovery\n    *   May also be used for a standby database\n*   Data Block Sizing\n    *   Sets the default database block size\n    *   Helps to determine the SORT_AREA_SIZE\n*   File Locations\n    *   Specify paths for trace files\n    *   Specify paths for parameter files\n    *   Database storage – Specify storage parameters\n\n## Creating a Database Manually\n\np101\n\n*   Decide on a unique instance and database name \n*   Choose a database character set \n*   Set the operating system variables\n*   Edit / Create the initialization parameter file\n*   Start the instance (nomount) \n*   Execute the CREATE DATABASE command\n*   Run scripts to generate the data dictionary and accomplish post creation steps\n\n### Preparing the Parameter File\n\n### Creating SPFILE\n\n### Starting the Instance\n\n### Creating the Database\n\n### Creating a Database Using OMF\n\n### After Database Creation\n\nThe database contains:\n\n*   Datafiles, control files, and redo log files\n*   User SYS with the password change_on_install\n*   User SYSTEM with the password manager\n*   Internal tables (but no data dictionary views)\n\n# Data Dictionary Contents and Usage\n\np110\n\n## Data Dictionary\n\nDuring database creation, the Oracle server creates additional object structures within the data files. \n\n*   Data dictionary tables\n*   Dynamic performance tables\n\nThe data dictionary is a set of read-only tables and views that record, verify, and provide information about its associated database.\n\n*   Describes the database and its objects\n*   Includes two types of objects:\n    *   Base tables\n        *   Store description of database\n        *   Created with CREATE DATABASE\n    *   Data Dictionary views\n        *   Summarize base table information\n        *   Created using catalog.sql script\n\n##  Contents\n\np114\n\n## Usage\n\n## Data Dictionary View Categories\n\n## Dynamic Performance Tables\n\n# Maintaining the Control File\n\np122\n\nThe control file is a binary file that defines the current state of the physical database.\n\n*   Loss of the control file requires recovery\n*   Is read at MOUNT stage\n*   Is required to operate\n*   Is linked to a single database\n*   Should be multiplexed\n*   Maintains integrity of database\n*   Sized initially by CREATE DATABASE\n\n## Contents\n\nP125\n\nA control file contains the following entries:\n\n*   Database name and identifier\n*   Time stamp of database creation\n*   Tablespace names\n*   Names and locations of data files and redo log files\n*   Current redo log file sequence number\n*   Checkpoint information\n*   Begin and end of undo segments\n*   Redo log archive information • Backup information\n\n# Maintaining Redo Log Files\n\np132\n\n## Managing Online Redo Logs with OMF\n\np144\n\n## Archived Redo Log Files\n\n# Managing Tablespaces and Data files\n\np150\n\n## Database Storage Hierarchy\n\np153\n\n![image-20200628012952676](oracle_review/image-20200628012952676.png)\n\n## SYSTEM and Non-SYSTEM Tablespaces\n\np154\n\n# Storage Structure and Relationships\n\np179\n\n## Extent Allocation and Deallocation\n\np185\n\n## Database Block\n\n## Database Block Contents\n\n## Data Dictionary Views\n\np196\n\n![image-20200628013426264](oracle_review/image-20200628013426264.png)\n\n## Obtaining Storage Information\n\n# Managing Undo Data\n\n\n\n\n\n\n\n---\n\n\n\n# Oracle数据库结构\n\n它由至少一个表空间和数据库模式对象组成。这里，模式是对象的集合，而模式对象是直接引用数据库数据的逻辑结构。模式对象包括这样一些结构:表、视图、序列、存储过程、同义词、索引、簇和数据库链等。逻辑存储结构包括表空间、段和范围，用于描述怎样使用数据库的物理空间。\n\n总之,逻辑结构由逻辑存储结构(表空间,段,范围,块)和逻辑数据结构(表、视图、序列、存储过程、同义词、索引、簇和数据库链等)组成,而其中的模式对象(逻辑数据结构)和关系形成了数据库的关系设计。\n\n段(Segment):\n\n是表空间中一个指定类型的逻辑存储结构，它由一个或多个范围组成，段将占用并增长存储空间。\n\n数据库的物理存储结构是由一些多种物理文件组成，主要有数据文件、控制文件、重做日志文件、归档日志文件、参数文件、口令文件、警告文件等。\n\n控制文件:存储实例、数据文件及日志文件等信息的二进制文件。alter system set control_files='路径'。V$CONTROLFILE。\n\n数据文件:存储数据，以.dbf做后缀。一句话:一个表空间对多个数据文件，一个数据文件只对一个表空间。dba_data_files/v$datafile。\n\n# Oracle 的 oracle sql*plus常用命令\n\n一、sys用户和system用户\nOracle安装会自动的生成sys用户和system用户\n(1)、sys用户是超级用户，具有最高权限，具有sysdba角色，有create database的权限，该用户默认的密码是change_on_install\n(2)、system用户是管理操作员，权限也很大。具有sysoper角色，没有create database的权限，默认的密码是manager\n(3)、一般讲，对数据库维护，使用system用户登录就可以拉\n注意：也就是说sys和system这两个用户最大的区别是在于有没有create database的权限。\n          \n二、sql\\*plus工具简介\nsql\\*plus是oracle自带的工具软件，主要用于执行sql语句，pl\\sql块。\n操作如下：\n(1)、在D:\\dev\\oracle\\product\\10.2.0\\db_1\\bin\\目录下的sqlplusw.exe。(D:\\dev\\oracle\\为oracle安装目录)\n(2)、在运行栏中输入“sqlplusw”即可\n\n三、sqlplus dos工具简介\n(1)、概述：sqlplus是在dos下操作oracle的工具，其功能和sql*plus相似。\n(2)、操作如下：在运行栏中输入“sqlplus”即可\n\n四、PLSQL Developer工具，需要自己安装，推荐大家使用\n\n五、sql\\*plus常用命令\n1)、连接命令\n1.conn[ect]\n用法：conn 用户名/密码@网络服务名 [as sysdba/sysoper]\n说明：当用特权用户身份连接时，必须带上as sysdba或是as sysoper\neg、\nSQL&gt; show user\nUSER 为 &quot;SCOTT&quot;\nSQL&gt; conn system/oracle@orcl\n已连接。\nSQL&gt; show user\nUSER 为 &quot;SYSTEM&quot;\nSQL&gt;\n以上命令实现类似切换用户的效果\n2.disc/disconn/disconnect\n说明: 该命令用来断开与当前数据库的连接\n3.pssw[ord]\n说明: 该命令用于修改用户的密码，如果要想修改其它用户的密码，需要用sys/system登录。\neg、\nSQL&gt; conn scott/oracle\n已连接。\nSQL&gt; passw\n更改 SCOTT 的口令\n旧口令:\n新口令:\n重新键入新口令:\n口令已更改\nSQL&gt;\n4.show user\n说明: 显示当前用户名\n5.exit\n说明: 该命令会断开与数据库的连接，同时会退出sql*plus\n5.clear screen\n清空屏幕\n\n2)、文件操作命令\n1.start和@\n说明: 运行sql脚本\n案例: sql&gt;@ d:\\a.sql或是sql&gt;start d:\\a.sql\n2.edit\n说明: 该命令可以编辑指定的sql脚本\n案例: sql&gt;edit d:\\a.sql,这样会把d:\\a.sql 这个文件打开\n3.spool\n说明: 该命令可以将sql*plus屏幕上的内容输出到指定文件中去。\n案例: sql&gt;spool d:\\b.sql并输入sql&gt;spool off\neg、\nsql&gt;spool d:\\b.sql;\nsql&gt;select * from emp;\nsql&gt;spool off;\n\n3)、交互式命令\n1.&amp;\n说明：可以替代变量，而该变量在执行时，需要用户输入。\nselect * from emp where job='&amp;job'；\n\n4)、显示和设置环境变量\n概述：可以用来控制输出的各种格式，set show 如果希望永久的保存相关的设\n置，可以去修改glogin.sql 脚本\n1.linesize\n说明：设置显示行的宽度，默认是80个字符\nshow linesize\nset linesize 90\n2.pagesize说明：设置每页显示的行数目，默认是14\n用法和linesize 一样\n至于其它环境参数的使用也是大同小异\n","plink":"hanyuulu.github.io/oracle_review/"},{"title":"传感器复习提纲","date":"2020-06-15T00:00:00.000Z","updated":"2021-03-12T08:22:58.574Z","content":"[toc]\n Chapter 0 绪论\n 传感器定义\n\n能感受规定的被测量并按照一定的规律转换成可用性好的器件或装置\n\n 传感器组成\n\n敏感元件\n转换元件i\n测量电路\n\n 结构框图\n\n 典型传感器构成方法\n\n自源型\n辅助能源型\n外源型\n相同敏感元件的补偿型\n差动结构补偿型\n不同敏感元件的补偿型\n反馈型\n\n\n 传感器实现信息转换的基本要求\np5\n\n足够的容量\n灵敏度高，精度适当\n响应速度快，工作稳定，可靠性好\n适用性和适应性强\n使用经济\n\n 传感器发展的趋势\n\n发现新效应，开发新材料，新功能\n传感器的多功能集成化和微型化\n传感器的数字化、智能化和网络化\n研究生物感官，开发仿生传感器\n\n Chapter 1 传感器技术基础\n 传感器的一般数学模型\np13\n\n\n最小二乘法\n\n\n对于函数y=k⋅x+by = k\\cdot x+by=k⋅x+b拟合有\n\n\nk=nΣxiyi−ΣxiΣyinΣxi2−(Σxi)2b=Σxi2Σyi−ΣxiΣxiyinΣxi2−(Σxi)2k = \\frac{n\\Sigma x_iy_i-\\Sigma x_i \\Sigma y_i}{n\\Sigma x_i^2-(\\Sigma x_i)^2}\\\\\nb = \\frac{\\Sigma x_i^2\\Sigma y_i-\\Sigma x_i\\Sigma x_iy_i}{n\\Sigma x_i^2-(\\Sigma x_i)^2}\nk=nΣxi2​−(Σxi​)2nΣxi​yi​−Σxi​Σyi​​b=nΣxi2​−(Σxi​)2Σxi2​Σyi​−Σxi​Σxi​yi​​\n\n\n\n\n 静态特性\np12\n\n\n线性度\n\n相对误差\n\n\n\neL=±ΔLmaxyF.S×100%e_L = \\pm \\frac{\\Delta L_{max}}{y_{F.S}}\\times 100\\%\neL​=±yF.S​ΔLmax​​×100%\n*   $\\Delta L_{max}$输出平均值与拟合直线间的最大偏差\n    *   $y_{F.S}$理论满量程输出值\n\n\n\n拟合方法*\n\n理论直线法\n2.  端点直线法\n3.  最佳直线法\n4.  最小二乘法\n\n\n\n回差\n\n正反行程输出的最大差值eH=ΔHmaxyF.S×100e_H = \\frac{\\Delta H_max}{y_{F.S}}\\times 100%eH​=yF.S​ΔHm​ax​×100\n\n\n\n重复性\n\n\n灵敏度\n\n传感器输出量增量与被测输入量增量之比K=ΔyΔxK = \\frac{\\Delta y}{\\Delta x}K=ΔxΔy​\n\n\n\n分辨力\n\n\n阈值\n\n\n稳定性\n\n\n漂移\n\n零点漂移\n灵敏度漂移\n\n时间漂移\n温度漂移\n\n\n\n\n\n静态误差（精度）\n\n三种算法\n\n将非线性、回差、重复性误差按几何法或代数法综合eS=±eL2+eH2+eR2e_S=\\pm \\sqrt{e_L^2+e_H^2+e_R^2}eS​=±eL2​+eH2​+eR2​​、eS=±(eL2+eH2+eR2)e_S=\\pm (e_L^2+e_H^2+e_R^2)eS​=±(eL2​+eH2​+eR2​)\n将全部标准数据相对拟合直线的残差看成随机分布，求出标准偏差σ\\sigmaσ，取2σ2\\sigma2σ或者3σ3\\sigma3σ作为静态误差σ=∑i=1P(Δyi)2p−1\\sigma = \\sqrt{\\frac{\\sum^P_{i=1}(\\Delta y_i)^2}{p-1}}σ=p−1∑i=1P​(Δyi​)2​​\n将系统误差和随机误差分开考虑eS=±∣(Δy)max∣+aσyF.Se_S = \\pm \\frac{|(\\Delta y)_{max}|+a\\sigma}{y_{F.S}}eS​=±yF.S​∣(Δy)max​∣+aσ​\n\n\n\n\n\n 动态特性\np16\n线性常系数微分方程\n∑i=1naidiydti=∑j=0mbjdjxdtj\\sum^n_{i=1} a_i \\frac{d^iy}{dt^i}=\\sum^m_{j=0} b_j \\frac{d^jx}{dt^j}\ni=1∑n​ai​dtidiy​=j=0∑m​bj​dtjdjx​\n(一般传感器bj=0b_j=0bj​=0(除b0b_0b0​))\n传递函数\nH(s)=Y(s)X(s)=∑i=0mbisi∑j=0najsjH(s)=\\frac{Y(s)}{X(s)} = \\frac{\\sum_{i=0}^m b_is^i}{\\sum_{j=0}^n  a_js^j}\nH(s)=X(s)Y(s)​=∑j=0n​aj​sj∑i=0m​bi​si​\n串联相乘、并联相加\ns=σ+jωs =\\sigma +j \\omegas=σ+jω\n “标准”信号函数\n\n正弦函数\n阶跃函数\n\n 频率响应特性\n\n\n正弦信号\n\n输入信号x=Xsin⁡ωtx = X\\sin\\omega tx=Xsinωt 幅值XXX、角频率ω\\omegaω\n输出信号y=Ysin⁡(ωt+φ)y = Y\\sin(\\omega t+\\varphi)y=Ysin(ωt+φ) 幅值YYY、初相角φ\\varphiφ\n幅频特性、动态灵敏度、增益\n\nA(ω)=∣Y(jω)X(jω)∣=YXA(\\omega) = |\\frac{Y(j\\omega)}{X(j\\omega)}|=\\frac{Y}{X}A(ω)=∣X(jω)Y(jω)​∣=XY​\n\n\n相频特性\n\nφ(ω)=arctan⁡{Im[Y(jω)X(jω)]Re[Y(jω)X(jω)]}\\varphi(\\omega)=\\arctan\\{\\frac{Im[\\frac{Y(j\\omega)}{X(j\\omega)}]}{Re[\\frac{Y(j\\omega)}{X(j\\omega)}]}\\}φ(ω)=arctan{Re[X(jω)Y(jω)​]Im[X(jω)Y(jω)​]​}\n\n\n\n\n\n阶跃响应特性\n\n\n阶跃信号 u(t)=0,(t&lt;0) 1,(t&gt;0)u(t) = 0,(t\\lt0)\\ 1,(t\\gt0)u(t)=0,(t&lt;0) 1,(t&gt;0)\n\n\nTODO\n\n\n 传感器典型环节的动态响应\np18\n 零阶环节\n\nKKK静态灵敏度\n微分方程y=b0a0x=Kry = \\frac{b_0}{a_0}x = Kry=a0​b0​​x=Kr\n传递函数Y(s)X(s)=b0a0=K\\frac{Y(s)}{X(s)}=\\frac{b_0}{a_0}=KX(s)Y(s)​=a0​b0​​=K\n\n 一阶环节\n\na1dydt+a0y=b0xa_1\\frac{dy}{dt}+a_0y = b_0xa1​dtdy​+a0​y=b0​x\n时间常数τ=a1/a0\\tau=a_1/a_0τ=a1​/a0​\n静态灵敏度K=b0/a0K = b_0/a_0K=b0​/a0​\nKx=(τs+1)yKx = (\\tau s+1)yKx=(τs+1)y\n传递函数Y(s)X(s)=Kτs+1\\frac{Y(s)}{X(s)}=\\frac{K}{\\tau s+1}X(s)Y(s)​=τs+1K​\n频率特性Y(jω)X(jω)=Kjωτ+1\\frac{Y(j\\omega)}{X(j\\omega)}=\\frac{K}{j\\omega \\tau+1}X(jω)Y(jω)​=jωτ+1K​\n\n 二阶环节\n\n微分方程a2d2ydt2+a1dydt+a0y=b0xa_2\\frac{d^2y}{dt^2}+a_1\\frac{dy}{dt}+a_0y=b_0xa2​dt2d2y​+a1​dtdy​+a0​y=b0​x\n静态灵敏度K=b0a0K = \\frac{b_0}{a_0}K=a0​b0​​\n固有频率ωn=a0/a2\\omega_n=\\sqrt{a_0/a_2}ωn​=a0​/a2​​\n阻尼比ξ=a12a0a2\\xi = \\frac{a_1}{2\\sqrt{a_0a_2}}ξ=2a0​a2​​a1​​\n(1ωn2s2+2ξωns+1)y=Kr(\\frac{1}{\\omega_n^2}s^2+\\frac{2\\xi}{\\omega_n}s+1)y = Kr(ωn2​1​s2+ωn​2ξ​s+1)y=Kr\n传递函数H(s)=Y(s)X(s)=Ks2ωn2+2ξωns+1H(s) = \\frac{Y(s)}{X(s)}=\\frac{K}{\\frac{s^2}{\\omega_n^2}+\\frac{2\\xi}{\\omega_n}s+1}H(s)=X(s)Y(s)​=ωn2​s2​+ωn​2ξ​s+1K​\n频率响应Y(jω)X(jω)=K1−(ωωn2)+j2ξωωn2\\frac{Y(j\\omega)}{X(j\\omega)}=\\frac{K}{1-(\\frac{\\omega}{\\omega_n^2})+j2\\xi\\frac{\\omega}{\\omega_n^2}}X(jω)Y(jω)​=1−(ωn2​ω​)+j2ξωn2​ω​K​\n\n 传感器性能指标一览\np22\n\n\n\n基本参数指标\n环境参数指标\n可靠性指标\n其他指标\n\n\n\n\n量程指标\n温度指标\n工作寿命等\n使用方面\n\n\n灵敏度指标\n抗冲振指标\n\n结构方面\n\n\n精度方面的指标\n其他环境参数\n\n安装连接方面\n\n\n动态性能的指标\n\n\n\n\n\n\n 改善传感器性能的技术途径\np23\n\n结构材料与参数的合理选择\n差动技术\n\n举例一两种差动传感器，举例优点\nTODO\n\n\n平均技术\n稳定性处理\n屏蔽隔离与干扰抑制\n零示法、微差法与闭环技术\n补偿、校正和“有源化”\n集成化、智能化\n\n 合理选择传感器的基本原则与方法\np27\n\n依据测量对象和使用条件确定传感器的类型\n线性范围与量程\n灵敏度\n精度\n频率响应特性\n稳定性\n\n 传感器的标定和校准\np29\n\n静态标定\n动态标定\n\n Chapter 2 电阻式传感器\n 电阻式传感器定义\np34\n\n通过电阻值参数的变化来实现电测非电量的目的的传感器\n类型\n\n电位计式\n应变计式\n压阻式\n磁电阻式\n光电阻式\n热电阻式\n\n\n\n 电阻应变计的基本类型和结构\n\n\n金属材料和非金属材料的应变电阻效应\np34\n\n约定有一长为lll，截面积为AAA，电阻率为ρ\\rhoρ的固态导体，有电阻R=ρlAR =\\rho \\frac{l}{A}R=ρAl​，对变化量有dRR=dll−dAA+dρρ\\frac{dR}{R} = \\frac{dl}{l}-\\frac{dA}{A}+\\frac{d\\rho}{\\rho}RdR​=ldl​−AdA​+ρdρ​，记(dl/l)=ϵ(dl/l)=\\epsilon(dl/l)=ϵ材料的轴向线应变，常用单位μϵ (1μϵ=1×10−6 mm/mm)\\mu\\epsilon\\ (1\\mu\\epsilon = 1\\times10^{-6}\\ ^{mm}/_{mm})μϵ (1μϵ=1×10−6 mm/mm​)，有(dA/A)=2(dr/r)=−2μϵ(dA/A) = 2(dr/r) = -2\\mu\\epsilon(dA/A)=2(dr/r)=−2μϵ，rrr导体半径，μ\\muμ导体材料的泊松比，代入得dR/R=(1+2μ)ϵ+dρ/ρdR/R=(1+2\\mu)\\epsilon+d\\rho/\\rhodR/R=(1+2μ)ϵ+dρ/ρ\n\n\n异同点\n\n\n金属材料的应变电阻效应\ndρρ=CdVV\\frac{d\\rho}{\\rho}=C\\frac{dV}{V}\nρdρ​=CVdV​\nCCC由一定材料加工方式决定的常数\n(dV/V)=(dl/l)+dS/S=(1−2μ)ϵ，(ΔR≪R)ΔRR=[(1+2μ)+C(1−2μ)]ϵ=KmϵKm=(1+2μ)+C(1−2μ)(dV/V)=(dl/l)+dS/S=(1-2\\mu)\\epsilon，(\\Delta R \\ll R)\\\\\n\\frac{\\Delta R}{R}=[(1+2\\mu)+C(1-2\\mu)]\\epsilon = K_m\\epsilon\\\\\nK_m=(1+2\\mu)+C(1-2\\mu)\n(dV/V)=(dl/l)+dS/S=(1−2μ)ϵ，(ΔR≪R)RΔR​=[(1+2μ)+C(1−2μ)]ϵ=Km​ϵKm​=(1+2μ)+C(1−2μ)\n金属材料的电阻相对变化与其线应变成正比。\n\n\n半导体材料的应变电阻效应\ndρρ=πσ=πEϵ\\frac{d\\rho}{\\rho}=\\pi\\sigma=\\pi E\\epsilon\nρdρ​=πσ=πEϵ\n\nσ\\sigmaσ作用于材料的轴向应力\nπ\\piπ半导体材料在受力方向的压阻系数\nEEE半导体材料的弹性模量\n\nΔRR=[(1+2μ)+πE]ϵ=Ksϵ\\frac{\\Delta R}{R}=[(1+2\\mu)+\\pi E]\\epsilon=K_s\\epsilon\nRΔR​=[(1+2μ)+πE]ϵ=Ks​ϵ\n\nKs=1+2μ+πEK_s=1+2\\mu+\\pi EKs​=1+2μ+πE导电丝材的灵敏系数\n\n\n\n\n\n分析\n\n金属材料\n\nK0=Km=(1+2μ)+C(1−2μ)K_0 = K_m =(1+2\\mu)+C(1-2\\mu)K0​=Km​=(1+2μ)+C(1−2μ) 前部分为受力导致几何尺寸的变化，后部分是电阻率的变化\n\n\n非金属材料\n\nK0=Ks=(1+2μ)+πEK_0=K_s=(1+2\\mu)+\\pi EK0​=Ks​=(1+2μ)+πE前部分为尺寸变化、后部分为压阻效应\n\n\n\n\n\n\n\n 静态特性\np38\n\n\n灵敏系数 K\n\nΔRR=Kϵs\\frac{\\Delta R}{R}=K\\epsilon_sRΔR​=Kϵs​\nϵs\\epsilon_sϵs​轴向应变\n\n\n\n横向效应及横向效应系数 H\n\n\n试件收到单向应力σ\\sigmaσ，纵栅和横栅各自敏感ϵx、ϵy，ΔRR=Kxϵx+Kyϵy=K(1+αH)ϵ\\epsilon_x、\\epsilon_y，\\frac{\\Delta R}{R}=K_x\\epsilon_x+K_y\\epsilon_y=K(1+\\alpha H)\\epsilonϵx​、ϵy​，RΔR​=Kx​ϵx​+Ky​ϵy​=K(1+αH)ϵ\n\nKx KyK_x\\ K_yKx​ Ky​纵向、横向灵敏系数\nα=ϵx/ϵy\\alpha=\\epsilon_x/\\epsilon_yα=ϵx​/ϵy​双向应变比\nH=Ky/KxH=K_y/K_xH=Ky​/Kx​双向灵敏系数比\n\n\n\n\n\n机械滞后 ZjZ_jZj​\n\n\n蠕变 θ\\thetaθ  零漂 PθP_\\thetaPθ​\n\n\n极限应变 ϵlim⁡\\epsilon_{\\lim}ϵlim​\n\n\n 动态特性\np40\n\n对正弦应变波的响应\n对阶跃应变波的响应\n疲劳寿命 N\n\n 电阻应变计的温度效应及补偿\np42\n\n\n温度效应\n\n\n设工作温度变化Δt∘C\\Delta t ^\\circ CΔt∘C，有\n(DeltaRR)=αtΔt+K(βs−βt)Δt(\\frac{DeltaR}{R})=\\alpha_t\\Delta t+K(\\beta_s-\\beta_t)\\Delta t(RDeltaR​)=αt​Δt+K(βs​−βt​)Δt\n\nαt\\alpha_tαt​敏感栅材料的电阻温度系数\nKKK应变计的灵敏系数\nβs,βt\\beta_s,\\beta_tβs​,βt​试件和敏感栅材料的线膨胀系数\n\n\n\n热输出\nϵt=(ΔR/R)tK=1KαtΔt+(βs−βt)Δt\\epsilon_t=\\frac{(\\Delta R/R)_t}{K}=\\frac{1}{K}\\alpha_t \\Delta t+(\\beta_s-\\beta_t)\\Delta tϵt​=K(ΔR/R)t​​=K1​αt​Δt+(βs​−βt​)Δt\n\n\n\n\n补偿方法\n\n\n温度自补偿法\n\n单丝\n\n选配敏感栅材料使ϵt=0\\epsilon_t=0ϵt​=0即αt=−K(βs−βt)\\alpha_t=-K(\\beta_s-\\beta_t)αt​=−K(βs​−βt​)\n\n\n双丝\n\n选取电阻温度系数一正一负的两种合金丝−ϵbtϵat≈RaR/RbR=RaRb\\frac{-\\epsilon_{bt}}{\\epsilon_{at}}\\approx\\frac{R_a}{R}/\\frac{R_b}{R}=\\frac{R_a}{R_b}ϵat​−ϵbt​​≈RRa​​/RRb​​=Rb​Ra​​\n\n\n\n\n\n桥路补偿法\n\n\n双丝半桥式\n\n\n\n补偿块半桥法\n\n\n\n\n\n\n\n为什么要补偿\n\n消除对ϵ\\epsilonϵ对测量应变的干扰\n\n\n\n 最广泛应用于电阻应变计的测量电路和特点\np47\n\n\n应变电桥\n\n\n灵敏度高、精度高、测量范围宽，结构电路简单、易于实现温度补偿\n\n\nTODO\n\n\n\n\n\n 电阻应变计\np55\n\n测力传感器\n压力传感器\n位移传感器\n其他应变式传感器\n\n 压阻式传感器\np59\n\n\n压阻效应\nΔRR≈Δρρ=πσ\\frac{\\Delta R}{R}\\approx\\frac{\\Delta \\rho}{\\rho}=\\pi\\sigmaRΔR​≈ρΔρ​=πσ\n\n\nπ\\piπ压阻系数（可能各向异性）\n\n\nσ\\sigmaσ全应力（注意区分横向和纵向）\n\n\n 应用\np61\n\n压阻压力式传感器\n压阻加速度式传感器\n\n Chapter 3 变磁阻式传感器\n 定义\np65\n\n利用磁路磁阻变化引起传感器线圈的电感变化来检测非电量的机电转换装置\n\n 电气参数分析\n\n\n等效电路\n\n线圈电感L=W2/RmL=W^2/R_mL=W2/Rm​，WWW匝数，RmR_mRm​磁路总磁阻\n\n\n闭合磁路\n\nL=W2/RFL = W^2/R_FL=W2/RF​ 导磁体总磁阻\n\n\n\n小气隙\n\nL≈W2/RσL\\approx W^2/R_\\sigmaL≈W2/Rσ​\n\n\n\n统一形式\nL=W2/Rm=W2⋅μ0μeS/lL=W^2/R_m=W^2\\cdot\\mu_0\\mu_eS/l\nL=W2/Rm​=W2⋅μ0​μe​S/l\n\nLLL电感\nμe\\mu_eμe​等效磁导率\nSSS横截面积\nlll磁路长度\nμ0=\\mu_0=μ0​=真空磁导率\n\n\n\n\n\n 品质因素\np68\n​\tQC=无功功率有功功率=ωL/RcQ_C=\\frac{无功功率}{有功功率}=\\omega L/R_cQC​=有功功率无功功率​=ωL/Rc​\n\nTODO\n\n 自感式传感器\np69\n\n变气隙式\n\n输出非线性\n\n\n变面积式\n\n输出可视为线性、线性范围较大\n灵敏度相比变气隙式低\n\n\n螺管式\n\n空气隙大，磁路磁阻大\n灵敏度较低\n线性范围较大\n\n\n差动式自感传感器\n\np71\n\n\n\n 互感式传感器（差动变压器）\np79\n工作原理和类型\n\n变气隙式\n变面积式\n螺管式\n互感传感器和自感传感器的异同点\n\n相同点\n\n都是通过改变衔铁的位置实现被测量的测量，且均有单一结构和对称组成的差动式以改善非线性提高灵敏度\n\n\n差动式自感传感器\n\n改变衔铁位置，改变初、次级线圈间的互感系数来改变相关的物理量\n\n\n自感传感器\n\n改变磁路磁阻来改变自感系数实现被测量的变化\n\n\n\n\n\n 电涡流式传感器\np86\n\n\n基本原理\n\n利用电涡流效应\n\n\n\n\n\n应用 p92\n\n测位移\n测厚度\n测温度\n\n\n\n磁致伸缩效应 p94\n\n铁磁材料在磁场中变化时，在磁场方向伸长或缩短的现象\nλs=(Δl/l)s\\lambda_s=(\\Delta l/l)_sλs​=(Δl/l)s​\n(Δl/l)(\\Delta l/l)(Δl/l)伸缩比\nλ\\lambdaλ磁致伸缩系数\n\n\n\n Chapter 4 电容式传感器\n 定义\np99\n\n将被测非电量的变化转换为电容量变化的传感器\n\n 工作原理\n\n变级距\n变面积\n变介质\n\n 问题和改进措施\np103\n\n等效电路\n边缘效应\n\n保护环\n\n\n静电引力\n寄生电容\n\n 电容式传感器和应用\np109\n\n位移传感器\n加速度\n力和压力\n物位\n\n Chapter 5 磁电式传感器\np115\n 定义\n将输入运动速度或磁量的变化变换成感应电势输出的传感器\n 基本原理与结构形式\ne=−WdΦdte = -W\\frac{d\\Phi}{dt}\ne=−WdtdΦ​\n\neee感应电势\nΦ\\PhiΦ穿过线圈的磁通量\nWWW线圈匝数\n\n\n\n\n变磁通式\n\n旋转型\n平移型\n\n\n恒磁通式\n\n动圈式\n动铁式\n\n\n\n 霍尔元件和霍尔效应\np123\n\n\nUH=1en⋅IBd=RHIBdU_H = \\frac{1}{en}\\cdot\\frac{IB}{d}=R_H\\frac{IB}{d}UH​=en1​⋅dIB​=RH​dIB​\n\nRHR_HRH​霍尔系数\n\n\nKH=RHd=UHIB (V/A⋅T)K_H=\\frac{R_H}{d}=\\frac{U_H}{IB}\\ (V/A\\cdot T)KH​=dRH​​=IBUH​​ (V/A⋅T)\n应用\n\n微位移以及机械振动测量\nTODO\n\n\n\n Chapter 6 压电式传感器\np135\n 定义\n\n具有压电效应的压电器件为核心组成的传感器，有自发电和可逆性，是典型的双向无源传感器件。\n\n （正）压电效应、极化作用\n\n\nD=dT or σ=dTD:电位移/σ:电荷密度;d:压电常数矩阵;T:外应力张量D=dT\\ or\\ \\sigma=dT\\\\\nD:电位移/\\sigma:电荷密度;d:压电常数矩阵;T:外应力张量\nD=dT or σ=dTD:电位移/σ:电荷密度;d:压电常数矩阵;T:外应力张量\n\n\n 逆压电效应、电致伸缩\n\n\nS=dtES:应变;dt:d的逆矩阵;E:外电场强度S = d_tE\\\\\nS:应变;d_t:d的逆矩阵;E:外电场强度\nS=dt​ES:应变;dt​:d的逆矩阵;E:外电场强度\n\n\n\n\n\n 压电材料\n\n压电晶体\n\n石英晶体\n\nx:电轴\ny:机械轴\nz:光轴\n\n\n压电陶瓷\n新型压电材料\n\n 切型和符号\np139\n\n光轴\n电轴\n机轴\n\n 压电陶瓷极化处理\n\n\n\n 石英晶体的压电方程\n\np139\nTODO\n\n 压电式加速度传感器类型\np150\n\n压缩型\n剪切型\n复合型\n\n 逆压电效应的应用\np158\n\n基于逆压电效应的超声波发生器（换能器）和声表面波谐振器是超声检测和声表面检查的关键器件\n\n Chapter 7 热电式传感器\n 热电阻传感器\np163\n\n利用转换原件电磁参量随温度变化的特性，对温度和温度有关的参量进行检测的装置\n\n 热电效应\np167\n\n\n\n 接触电势\nEAB(T)=kTeln⁡NANBEAB(T):AB两种金属在温度T时的接触电势;k=1.38×10−23(J/K):玻尔兹曼常数;e=1.6×10−19(C):电子电荷T:结点处的绝对温度E_{AB}(T)=\\frac{kT}{e}\\ln \\frac{N_A}{N_B}\\\\\nE_{AB}(T):AB两种金属在温度T时的接触电势;\\\\k=1.38\\times10^{-23}(J/K):玻尔兹曼常数;\\\\e=1.6\\times10^{-19}(C):电子电荷\\\\T:结点处的绝对温度\nEAB​(T)=ekT​lnNB​NA​​EAB​(T):AB两种金属在温度T时的接触电势;k=1.38×10−23(J/K):玻尔兹曼常数;e=1.6×10−19(C):电子电荷T:结点处的绝对温度\n 温差电势\nE_A(T,T_0)=\\begin{equation*}\\int_{T_0}^{T}\\sigma_AdT \\end{equation*}\\\\\nE_A(T,T_0):金属A两端温度分别为T与T_0时的温差电势\\\\\n\\sigma_A:温差系数\\\\\nT、T_0:高低温端的绝对温度\n\n 两个结论\n\np168\n\n 热电效应\n 工作定律\n\n中间导体定律\n连接导体定律、中间温度定律\n参考电阻定律\n\n热电偶和热电阻的区别\n热电偶 测量温度原理\n Chapter 8 光电式传感器\np177\n 定义\n以光为测量媒介、以光电器件为转换元件的传感器\n 一般组成\n\n 常用光源\np179\n\n热辐射光源\n气体放电光源\n发光二极管\n激光器\n\n 外光电效应\n在光的照射下，电子逸出物体表面产生光电子发射的现象\n 内光电效应\np180\n 光电导效应\n\n光照射在半导体材料上，材料中处于价带的电子吸收光子能量，通过禁带跃入导带，使导带内电子浓度和价带内空穴增多，激发出光生电子-空穴对，从而使半导体材料产生光电效应。\n\n光敏电阻\n光敏二极管\n光敏三极管\n\n 光生伏特效应\n光照引起PN结两端产生电动势的效应\n\n Chapter 9 光纤传感器\np201\n 光纤波导原理\n\nnisin⁡θi=njsin⁡θj全反射条件：sin⁡θ1&gt;n2n1全反射临界角:sin⁡θc=sin⁡θ0=1n0n12−n22=NANA:数值孔径n_i\\sin\\theta_i=n_j\\sin\\theta_j\\\\\n全反射条件：\\sin\\theta_1\\gt\\frac{n_2}{n_1}\\\\\n全反射临界角: \\sin\\theta_c=\\sin\\theta_0=\\frac{1}{n_0}\\sqrt{n_1^2-n_2^2}=NA\\\\\nNA:数值孔径\nni​sinθi​=nj​sinθj​全反射条件：sinθ1​&gt;n1​n2​​全反射临界角:sinθc​=sinθ0​=n0​1​n12​−n22​​=NANA:数值孔径\n 数值孔径的物理意义\n衡量光纤集光性能的主要参数\n 分类\np204\n 调制解调方式\np205\n\n强度调制与解调\n偏振调制与解调\n相位调制与解调\n频率调制与解调\n\n Chapter 10 数字式传感器\np221\n 定义\n\n能把被测量转换成数字量输出的传感器\n\n 编码器\np233\n\n\n旋转式广电编码器\n\n绝对编码器\n增量编码器\n\n\n频率式传感器\n数字集成式传感器\n\n","plink":"hanyuulu.github.io/review_sensor/"},{"title":"wsl安装桌面环境","date":"2020-05-24T00:00:00.000Z","updated":"2021-03-12T08:22:58.614Z","content":" 准备工作\n\n\n运行有wsl（笔者使用wsl2）的Windows 10电脑一台（必备）\n\n安装wsl和wsl1升级到wsl2微软官方教程:\n\n\n\nwsl里的文本编辑器（vim,nano等）（强烈推荐，笔者此处使用vim）\n\ne.g. (apt作为包管理器，Ubuntu等)\n  12&gt;   sudo apt install vim&gt;\n\n\n\n身居中国大陆并且没给wsl换源或者不知道换源的小伙伴请参阅tuna镜像站进行换源（非必须，但是可以大大加快安装速度）\n\ne.g. Ubuntu请参阅Ubuntu 镜像使用帮助\n\n\n\n 安装Xfce4和xrdp\n 简介\n\nXfce4是一个轻量可高度定制的类-unix桌面环境，与wsl相性十分相符\nxrdp支持rdp，是Windows原生支持的远程桌面协议，使用“远程桌面连接”即可连接到wsl桌面环境\n\n 安装步骤（此处以Ubuntu 18.04 on Windows 10为例）\n\n\n更新包管理器\n1sudo apt update\n\n\n安装Xfce4和xrdp\n1sudo apt install xfce4 xrdp\n\n\n更改xrdp配置\n\n123echo xfce4-session &gt;~/.xsessionsudo vim /etc/xrdp/startwm.sh#/etc/X11/Xsession 前一行插入 xfce4-session\n\n\n更改xrdp侦听端口\nrdp默认侦听端口为3389，Windows 10本身已经占用（如果开启远程桌面的话），此处为了避免冲突我们更换一下监听端口\n\n12sudo vim /etc/xrdp/xdrp.ini#将port=3389更改为3388或者其他可用端口\n\n\n重启以使配置生效\n1sudo service xrdp restart\n\n\n锵锵！安装完成了。\n\n\n 使用步骤\n\n\n打开Windows的“远程桌面连接”\n\n\n\n地址填写localhost:3388，（显示选项中可以选择更多显示选项，分辨率，大小等）\n\n\n![image-20200524220431099](wslDesktop/image-20200524220431099.png)\n\n\n\nxrdp此时提示输入账户密码（wsl的）\n\n\n\n锵锵！你现在拥有了一个新的桌面环境！\n\n\n\n 后续可选内容\n\n高分屏调整分辨率\n安装中文字体\n各种美化（\n看心情更\n\n","plink":"hanyuulu.github.io/wslDesktop/"},{"title":"《疾病的群体现象及其测量》笔记","date":"2020-05-16T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":"\n 声明\n本笔记非医学专业收录，仅供统计参考之用，相关疑问请寻求具有相关资质的医师帮助\n\n\n 约定\n下述所有kkk表示归一化因子，可取100%100\\%100%、1000‰1000‰1000‰等，因为人群研究往往用更大的量级所以很少写100%100\\%100%\n\n[toc]\n 概述\n 疾病的个体表现\n\n症状、体征、功能变化等\n\n 群体现象和分布（三间分布）\n\n时间聚集性\n\n季节性\n\n\n空间聚集性\n\n国家、地区、城乡等\n\n\n人间聚集性\n\n年龄、性别等\n\n\n\n 疾病频率的测量\n概率论特征\n 相对数（率、比、构成比）\n 率（rate）\n\n单位时间（周、月、年）内某现象发生的频率与强度\n分子可以是分母\n描述疾病在人群中发生有多快\n\n 构成比（proportion）\n\n事物内部某一部分单位与事物内部各部分观察单位的综述之比\n分子包含在分母中\n描述受疾病影响的或某特征人群占总人群的比例\n\n 暴露因素的测量\n 疾病频率测量\n 发病频率指标\n 发病率 incidence rate\n反映一定时期、特定人群中某病新病例出现频率\n发病率=一定时期内某人群中某病新病例数同时期暴露人口数发病率=\\frac{一定时期内某人群中某病新病例数}{同时期暴露人口数}\n发病率=同时期暴露人口数一定时期内某人群中某病新病例数​\n\n\nAttention\n\n分子为新发病例数\n分母为可能患病的人群、不同疾病的暴露人口数互有不同\n可以计算发病专率（年龄、性别）\n应进行标准化比较，标准化的率只进行比较，不反映真实水平\n\n\n\nApplication\n\n描述疾病的分布，反映疾病流行强度，评估疾病对人群健康的影响\n探讨发病因素，提出病因假说\n评价防制（治）措施的效果\n\n 累积发病率 cumulative incidence rate, CI\n适用条件：样本大，人口稳定，资料整齐（固定队列）\n 发病密度 incidence density, ID\n适用条件：观察时间长，人口不稳定、存在失访，资料不整齐（动态队列）\n\n\n 罹患率 attrack rate\n\n\n同样为测量新发病例的指标\n\n\n某一局限范围内短时发病率（小时，日，周）\n\n\n局部地区疾病的暴发，食物中毒、传染病及职业中毒等暴发流行情况\n\n\n续发率=潜伏期内易感染者中发病人数易感接触者总人数×k续发率=\\frac{潜伏期内易感染者中发病人数}{易感接触者总人数}\\times k\n续发率=易感接触者总人数潜伏期内易感染者中发病人数​×k\n\n也称二代发病率，是指某些传染病在最短潜伏期到最长潜伏期之间，易感接触者中发病人数占所有易感接触者总数的百分比\n\n 续发率 second attrack rate\n续发率=潜伏期内易接触者中发病人数易接触者总人数×k续发率=\\frac{潜伏期内易接触者中发病人数}{易接触者总人数}\\times k\n续发率=易接触者总人数潜伏期内易接触者中发病人数​×k\n也称二代发病率，是指某些传染病在最短潜伏期到最长潜伏期之间，易感接触者中发病人数占所有易感接触者总数的百分比。\n\nAttention\n\n分子为二代病例，即在一个潜伏期内（最短潜伏期和最长潜伏期之间）易感接触者中发病人数\n将原发病例从分子分母中去除\n集体外感染，短于最短潜伏期或长于最长潜伏期者均不计入\n\n\nApplication\n\n反应传染病传染力强弱的指标\n分析传染病流行的因素\n评价传染病防治措施效果\n\n\n\n 死亡频率指标\n 死亡率 mortality rate\n死亡率=某人群某期死亡总数同期平均人口数×k死亡率=\\frac{某人群某期死亡总数}{同期平均人口数}\\times k\n死亡率=同期平均人口数某人群某期死亡总数​×k\n某时间内某人群中总死亡人数在该人群中所占的比例\n\nAttention\n\n粗死亡率：未经调整的死于所有原因的死亡率，反应一个人群总的死亡水平\n可计算死亡专率（病种，年龄，性别等）\n标化死亡率\n\n婴儿死亡率=某年未满一周岁婴儿死亡数同年活产总数婴儿死亡率=\\frac{某年未满一周岁婴儿死亡数}{同年活产总数}婴儿死亡率=同年活产总数某年未满一周岁婴儿死亡数​\n新生儿死亡率=某年未满28天新生儿死亡总数同年活产总数新生儿死亡率=\\frac{某年未满28天新生儿死亡总数}{同年活产总数}新生儿死亡率=同年活产总数某年未满28天新生儿死亡总数​\n5岁以下儿童死亡率=某年5岁以下儿童死亡总数同年活产总数5岁以下儿童死亡率=\\frac{某年5岁以下儿童死亡总数}{同年活产总数}5岁以下儿童死亡率=同年活产总数某年5岁以下儿童死亡总数​\n孕妇死亡率=某年孕产妇死亡数同年活产总数孕妇死亡率=\\frac{某年孕产妇死亡数}{同年活产总数}孕妇死亡率=同年活产总数某年孕产妇死亡数​\n\n\n\n\nApplication\n\n衡量一个地区人群某一时期的死亡危险性大小，反映一个地区不同时期人群的健康状况和卫生保健工作水平；为卫生保健工作的需求和规划提供科学依据。\n探讨病因和评价防治措施效果\n某些病死率高的疾病（恶性肿瘤、狂犬病）死亡率≈发病率，可用死亡率代替发病率\n\n\n\n 病死率 case fatality rate\n病死率=某时期内因某病死亡人数同期某病病人数×k病死率=\\frac{某时期内因某病死亡人数}{同期某病病人数}\\times k\n病死率=同期某病病人数某时期内因某病死亡人数​×k\n\nAttention &amp; Application\n\n表示某种疾病的死亡概率，可表明疾病的严重程度\n可反映诊治能力等医疗水平\n多用于急性传染病，较少用于慢性病\n用病死率作为评价不同医院的医疗水平时，要注意可比性\n\n\n\n 生存率 survival rate\nn年存活率=随访满n年尚存活的病例随访满n年的病例数×kn年存活率=\\frac{随访满n年尚存活的病例}{随访满n年的病例数}\\times k\nn年存活率=随访满n年的病例数随访满n年尚存活的病例​×k\n接受某种治疗的病人，或患某病的病人经 n 年随访（通常为1、3、5年）后存活的概率\n反映疾病对生命的危害程度，可用于评价某些病程较长疾病的远期疗效（癌症、心血管疾病等）\n 疾病负担指标\n 患病率 prevalence\n某特定数间内、总人口某病新旧病例所占的病例\n期间患病率=某时期特定人群中某病现患（新、旧）病例同期平均人口数期间患病率=\\frac{某时期特定人群中某病现患（新、旧）病例}{同期平均人口数}\n期间患病率=同期平均人口数某时期特定人群中某病现患（新、旧）病例​\n时点患病率=某一时点特定人群中某病现患（新、旧）病例该时点人口数时点患病率=\\frac{某一时点特定人群中某病现患（新、旧）病例}{该时点人口数}\n时点患病率=该时点人口数某一时点特定人群中某病现患（新、旧）病例​\n\n\n发病率增加，则患病率提高\n死亡、痊愈数增加，则患病率下降\n患病率取决于发病率和病程\n\n影响患病率的因素\n\n\n\n患病率升高因素\n患病率降低因素\n\n\n\n\n病程延长\n病程缩短\n\n\n发病率升高\n发病率下降\n\n\n病例迁入\n病例迁出\n\n\n健康者迁出\n健康者迁入\n\n\n诊断水平提高\n治愈率提高\n\n\n报告率提高\n-\n\n\n未治愈者寿命延长\n-\n\n\n易感者迁入\n-\n\n\n\n\n\n当某地某病的发病率和病程在相当长时间内保持稳定时，同时假设人口稳定\n患病率(P)=发病率(I)×病程(T)患病率(P)=发病率(I)\\times病程(T)\n患病率(P)=发病率(I)×病程(T)\n\n\nApplication\n\n反映病程较长的慢性病的流行情况及对人群健康的影响\n可为医疗设施规划，估计医院床位周转、卫生设施及人力的需要量，医疗费用的投入等提供科学依据\n可用来检测慢性病控制效果\n\n\n\n患病率与发病率的比较\n\n\n\n比较内容\n患病率\n发病率\n\n\n\n\n资料来源\n现况调查、筛检等\n疾病报告、疾病监测、队列研究\n\n\n计算分子\n观察期间新发病例和现患病例数之和\n观察期间新发病例数\n\n\n计算分母\n调查人数（时点患病率）平均人口数（期间患病率）\n暴露人口数或平均人口数\n\n\n观察时间\n较短、一般为1个月或者几个月\n一般为一年或者更长时间\n\n\n适用疾病种类\n慢性病或病程较长的疾病\n各种疾病\n\n\n用途\n慢性病或病程较长疾病\n各种疾病\n\n\n影响因素\n较多、影响发病率的因素、病后结局及病人病程等\n相对较少、疾病流行情况，诊断水平、疾病报告质量等\n\n\n\n 感染率 infection rate\n感染率=受检者中阳性人数受检人数×k感染率=\\frac{受检者中阳性人数}{受检人数}\\times k\n感染率=受检人数受检者中阳性人数​×k\n\n某时间内被检人群中某病原体现有感染者（显性/隐性）所占比例\nApplication\n\n评价人群健康状况的常用指标，常用于描述某些传染病或寄生虫病的感染情况、流行态势\n可为制定防治措施以及评价防疫措施的效果提供依据\n\n\n\n 潜在减寿年数 potential years of life lost, PYLL\n某病某年龄组人群死亡者的实际死亡年龄与期望寿命之差的总和；以期望寿命为基准，进一步衡量死亡造成的寿命损失，强调早亡对健康的影响。\nPYLL=∑i=1eaidiPYLL=\\sum^e_{i=1}a_id_i\nPYLL=i=1∑e​ai​di​\n\neee：预期寿命\niii：年龄组（通常计算年龄组中值）\naia_iai​：剩余年龄，ai=e−(i+0.5)a_i=e-(i+0.5)ai​=e−(i+0.5)\ndid_idi​：某年龄组的死亡人数\n\n\nApplication\n\n人群中疾病负担的直接指标\n通过计算和比较各种不同原因所致的寿命减少年数，可反映出各种危险因素、死亡原因等对人群的危害程度\n可用于地区间比较\n可用于筛选确定重点卫生问题或重点疾病，同时也适用于防治措施效果的评价和卫生政策的分析\n\n\n\n 伤残调整寿命年 disability adjusted life year,DALY\n从发病到死亡所损失的全部健康寿命年，包括因早死所致的寿命损失年（years of life lost, YLL）和疾病所致伤残引起的健康寿命损失年（years lived with disability，YLD）两部分\nDALY=YLL+YLDDALY=YLL+YLD\nDALY=YLL+YLD\n\nAppliation\n\n计算各种疾病造成的早死与残疾对健康寿命面损失的综合指标，疾病负担的主要指标之一\n比较和评价地区间卫生状况，跟踪疾病负担的动态变化\n确定危害严重病种、重点人群等，为防治重点提供依据\n成本效益分析\n\n\n\n 其他生命质量指标\n\n病残率 disability rate\n健康寿命年 health life years，HeaLY\n健康期望寿命 active life expectancy\n质量调整生命年 quality-adjusted life year, QALY\n\n 疾病的群体现象\n 疾病的流行强度\n一定时期内疾病在某地区人群中发病率变化及其病例间的联系程度；用以描述某种疾病在某地区人群单位时间内新发病例数量的变化特征\n 流行强度\n 散发（sporadic）\n\n发病率呈历年一般水平，病例间无明显联系，表现为散在发生。\n多与当地近三年该病的发病率进行比较，如果当年发病率未明显超过既往平均水平称为散发。\n\n涉及地域：在范围较大的地区内\n发病数量：发病数量呈历年一般水平\n病例间联系程度：病例间在发病时间和地区间无明显联系\n\n原因\n\n人群维持一定的免疫水平（常年流行或预防接种）\n以隐性感染为主的疾病\n传播机制不易实现的疾病\n长潜伏期传染病\n\n\nAttention\n\n用以描述较大范围（区、县以上），不能用于小范围人口较少的居民区等。小范围少数病例成为散发病例。\n历年的一般发病水平意味着情况相同的年代。\n不能在不同地区或国家间衡量某病是否散发。\n\n\n\n 暴发（outbreak）\n局部地区或集体单位，短时间内突然发生很多症状相同的病人，往往有共同的传染源\n\n原因\n\n传染病：多有共同的传染源和传播途径，多数病人出现在该病的最短和最长潜伏期之间。\n非传染病：食物中毒\n\n\n判断\n\n涉及地域：在一个局部地区或集体单位\n发病数量：短时间出现很多相同的病人\n病例间联系：有流行病学相关性\n\n\n\n 流行（epidemic）\n某地区某病发病率显著超过历年发病率水平（散发）\n\n判断\n\n涉及地域：某地区或某国家\n发病数量：显著超过历年水平\n病例间联系：往往有流行病学相关性\n\n\n\n 大流行（pandemic）\n某地区某病发病率显著超过历年发病率水平，疾病蔓延迅速，涉及面广，短时间内跨越省界、国界形成世界性流行\n\n判定\n\n涉及地域：广\n发病数量：显著超过历年水平\n病例间联系：往往有流行病学相关性\n\n\n\n能够发生大流行的疾病具有传播途径容易实现、传播迅速、人群普遍易感等特点，如流感、霍乱\n 疾病的分布\n 人群分布\n\n年龄、性别、职业、种族/民族、婚姻与家庭、行为生活方式、流动人口、宗教信仰……\n\n 年龄\n年龄与疾病之间的关联比其他因素的作用都强\n随着年龄的增长，几乎大部分疾病的发生频率都会发生变化\n\n年龄分布出现差异的原因\n\n免疫水平和易感性不同\n预防接种改变某些疾病固有的发病特征\n暴露病原因子的机会不同\n暴露的积累\n\n\n\n\n疾病的死亡率存在着明显的性别差异\n各年龄别死亡率男性高于女性\n不同地区或不同疾病有所不同\n男女发病率存在明显差别\n\n男女暴露或接触致病因素的机会不同\n遗传、内分泌、生理解剖等生物性差异\n男女职业的差异\n生活方式、嗜好不同导致性别分布差异\n\n\n不同的物理、化学、生物因素及职业精神紧张，均可导致疾病分布不同\n分析职业与疾病的关系时应当考虑\n\n不同种族、民族的遗传因素不同\n不同民族风俗、饮食和生活习惯不同\n不同民族社会经济状况、医疗保健水平不同\n不同民族定居的自然环境、社会环境不同\n\n\n婚姻与家庭\n\n对健康的影响\n\n对女性健康的影响\n\n性生活、妊娠、分娩、哺乳等\n\n\n近亲婚配\n\n先天畸形\n遗传性疾病\n\n\n家族聚集性\n\n遗传因素+共同生活环境和生活方式\n\n\n\n\n\n\n行为生活方式\n\n有益健康行为\n\n体育锻炼\n合理膳食\n\n\n有害健康行为\n\n吸烟酗酒\n不良性行为\n\n\n\n\n\n\n流动人口\n\n传染病暴发流行的高危人群\n疫区与非疫区间传染病传播纽带\n对性传播疾病的传播起起重要作用\n给儿童计划免疫工作的开展增加难度\n\n\n\n 时间分布\n\n国家间及国内不同地区的分布\n疾病的城乡分布\n疾病的地区聚集性\n地方性疾病（endemic disease）\n\n 地区分布\n\n国家间及国内不同地区的分布\n疾病的城乡分布\n疾病的地区聚集性\n地方性疾病（endemic disease）\n\n有些疾病仅发生在某些地区\n有些疾病虽在全世界均可发生，但不同地区的分布各有特点\n\n日本的胃癌及脑血管病的调整死亡率或年龄死专率居首\n恶性肿瘤已澳大利亚和新西兰最高\n肝癌多见于亚洲、非洲\n乳腺癌多见于欧洲、非洲\n血吸虫：仅限于南方省份\nHIV感染：云南\n鼻咽癌：广东\n食管癌：河南林县\n肝癌：江苏启东\n原发性高血压：北方＞南方\n\n城乡分布\n\n\n\n城市\n农村\n\n\n\n\n人口多、密度大\n人口密度低\n\n\n交通拥挤、人口流动性大\n交通不便，外界交往较少\n\n\n呼吸道传染病易传播\n呼吸道传染病易流行\n\n\n肠道传染病较少\n肠道传染病易流行\n\n\n慢性病及肿瘤发病率较高\n某些地方病发病率较高\n\n\n出现职业性损害\n虫媒传染病发病率较高\n\n\n\n地区聚集性\n\n某地区发病及患病等疾病频率高于周围地区的情况，且不是随机导致。常见于职业暴露、环境污染、疾病暴发等\n\n提示一个感染因子的作用\n提示局部环境污染的存在\n\n\n地方性\n\n统计地方性：与生活条件和卫生习惯有关\n自然地方性：与自然环境有关（病原体、微量元素）\n自然疫源性：疾病的传播不依赖人\n\n\n输入性\n\n本地区不存在或已消灭的疾病从国外或其他地区传入\n\n\n地方性疾病（endemic disease）\n\n局限于某些特定地区内相对稳定并经常发生的疾病\n判断依据\n\n该地区各类居民、各民族发病率高\n其他地区居住的相似人群中发病率低，甚至不发病\n迁入该地区一段时间后，其发病率和当地居民一致\n人群迁出该地区后，发病率下降，患者症状减轻或自愈\n当地易感动物也可发生同样疾病\n\n\n\n\n\n 时间分布\n\n疾病的时间分布是疾病发生发展过程的重要表现形式，它是致病因子、宿主、环境共同作用的结果。\n描述疾病的时间分布常采用二维线图或直方图表示，横坐标为时间，纵坐标为率或病例数。\n\n 短期波动\n以日、周、月计数的疾病流行或疫情暴发，含义与暴发相近\n\n区别\n\n爆发\n\n少量人群、小范围\n\n\n短期波动\n\n较大数量人群、范围较大\n\n\n\n\n类型\n\n传染病\n非传染病\n自然灾害和人为污染\n\n\n\n 季节性\n疾病在一定季节呈现发病率增高的现象\n\n严格季节性\n\n虫媒传染病（如乙脑）\n\n\n季节性升高\n\n呼吸道、肠道传染病\n\n\n\n季节性升高的原因\n\n病原体的生长繁殖受气候影响\n媒介昆虫季节消长均受到温度、湿度、雨量等影响\n与野生动物的生活习性及家畜的生长繁殖有关\n受人们的生活方式、生产劳动条件及医疗卫生水平变化的影响\n与人们暴露病原因子的机会及人群易感性有关\n\n 周期性\n疾病频率按照一定的时间间隔，有规律地起伏波动，每隔若干年出现一个流行高峰的现象\n有关因素\n\n前一次流行病所遗留的易感者数量\n新的易感者补充累计的速度\n人群免疫时间的长短\n病原自身变异速度\n\n有效的预防措施可以改变疾病的周期性规律\n 长期趋势\n对疾病动态的连续数年乃至数十年的观察，在这个长时间内观察探讨疾病的病原体、临床表现、发病率、死亡率等方面所发生的变化\n\n长期编译的原因\n\n病因或致病因素发生了变化\n病原体抗原型别、毒力、致病力发生变异\n诊治条件、药物疗效及新的治疗方法的进化和预防措施的采取等\n等级报告制度完善，疾病的诊断标准、分类发生改变\n人口学资料的变化\n\n\n\n 疾病三间分布的综合描述\n在疾病流行病学研究实践中，常常需要综合地描述和分析疾病在人群、地区和时间上的分布情况，只有这样才能全面获取有关病因线索和流行因素的资料。\n移民流行病学，是进行这种综合描述的一个典型\n\n移民流行病学\n\n通过观察疾病在移民、移居地当地居民及原居地人群间的发病率或死亡率的差异，从而探讨疾病的发生与遗传因素或环境因素的关系，常用于肿瘤、慢性病及某些遗传病的病因和流行因素的探讨。\n当环境是主要因素\n\n移民指移居地当地居民\n\n\n当遗传时主要因素\n\n移民指原居住地人群\n\n\n\n\n\n 疾病预后评价指标\n 疾病的群体发病现象\n","plink":"hanyuulu.github.io/Epidemiology/"},{"title":"Windows家庭版升级指南","date":"2020-05-11T00:00:00.000Z","updated":"2021-03-12T08:22:58.614Z","content":" Windows家庭版升级指南\n阅读前必知：本文不提供任何破解或者绕过Windows激活的方案，请通过依法依规的形式获得Windows正版授权，请支持正版以维护您和相关公司的利益，敬请知悉，谢谢\n\n\n情景概述\n目前，许多高校为学生购买了Windows kms正版授权，但是很多OEM给电脑预装的是家庭版授权，导致无法直接使用学校的kms激活。为了避免重装浪费时间，在此给出一些无需重装而升级到专业版/企业版的解决方案。\n\n\n\n若您所在的学校没有购买kms，请参考微软官方帮助文档，利用数字许可或者密钥进行升级\n\n\n\n在 设置&gt;激活 中，选择 更改产品密钥，使用以下key将版本转换为企业版/企业版\n\n\n\n升级为不可逆过程，如有必要请事先进行系统备份以便于失败时快速回滚\n\n\n此处key不提供激活功能，仅仅为转版本使用，使用前请先确认您有合法Windows专业版/企业版许可\n\n\n\n\n\n\n家庭版升专业版key\n\nVK7JG-NPHTM-C97JM-9MPGT-3V66T\n4N7JM-CV98F-WY9XX-9D8CF-369TT \nFMPND-XFTD4-67FJC-HDR8C-3YH26 \nVK7JG-NPHTM-C97JM-9MPGT-3V66T\nNPPR9-FWDCX-D2C8J-H872K-2YT43\nW269N-WFGWX-YVC9B-4J6C9-T83GX\nNYW94-47Q7H-7X9TT-W7TXD-JTYPM\nNJ4MX-VQQ7Q-FP3DB-VDGHX-7XM87\nMH37W-N47XK-V7XM9-C7227-GCQG9\nVK7JG-NPHTM-C97JM-9MPGT-3V66T\n\n\n\n家庭版升企业版key\n\nNPPR9-FWDCX-D2C8J-H872K-2YT43\n\n\n![image-20200511181943914](windows-10-upgrading-home-to-pro/image-20200511181943914.png)\n\n\n\n\n升级完成后，系统已经变更为专业版/企业版，此时可以使用学校/组织提供的kms服务器进行激活。您可以参照学校或组织提供的kms激活方案继续完成激活。\n\n东南大学kms许可操作说明：https://nic.seu.edu.cn\n\n\n\n\n 遇到其他问题\n许可问题请请参阅微软支持，关于本文操作问题请致函并说明问题以便笔者补充常见问题以帮助更多人。\n","plink":"hanyuulu.github.io/windows-10-upgrading-home-to-pro/"},{"title":"Java反射机制备忘","date":"2020-03-29T17:14:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" 概述\n\n反射的概念是由Smith在1982年首次提出的，主要是指程序可以访问、检测和修改它本身状态或行为的一种能力，通过反射可以调用私有方法和私有属性，大部分框架也都是运用反射原理的。java通常是先有类再有对象，有对象就可以调用方法或者属性，java中的反射其实是通过Class对象来调用类里面的方法。\n主要是指程序可以访问，检测和修改它本身状态或行为的一种能力，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。\n一个类有多个组成部分，例如：成员变量、方法、构造方法等，反射就是加载类,并解剖出类的各个组成部分。\n\n\n\n反射主要提供的功能\n\n在运行时判断任意一个对象所属的类\n在运行时构造任意一个类的对象\n在运行时判断任意一个类所具有的成员变量和方法\n在运行时调用任意一个对象的方法\n生成动态代理\n\n\n\n优点\n\n能够运行时动态获取类的实例，大大提高系统的灵活性和扩展性\n与Java动态编译相结合，可以更多功能\n\n\n\n缺点\n\n性能较低\n不安全\n破坏了类的封装性\n\n\n\n相关类\n12345java.lang.Class;java.lang.reflect.Constructor;java.lang.reflect.Field;java.lang.reflect.Method;java.lang.reflect.Modifier;\n\n\n 通过对象获取保证的包名和类名\n文件结构\n123C:.└─Hanyuu        Demo.java\nDemo.java\n1234567package Hanyuu;class Demo&#123;    public static void main(String[] args) &#123;        Demo demo = new Demo();        System.out.println(demo.getClass().getName());    &#125;&#125;\n输出\n1Hanyuu.Demo\n 实例化类对象\nDemo.java\n12345678910111213141516package Hanyuu;class Demo&#123;    public static void main(String[] args) throws ClassNotFoundException &#123;        Demo demo = new Demo();        Class&lt;?&gt; fornameClass = null;        Class&lt;?&gt; getClass = null;        Class&lt;?&gt; dotClass = null;        // throws ClassNotFoundException        fornameClass = Class.forName(\"Hanyuu.Demo\");        getClass = new Demo().getClass();        dotClass = Demo.class;        System.out.println(fornameClass.getName());        System.out.println(getClass.getName());        System.out.println(dotClass.getName());    &#125;&#125;\n输出\n123Hanyuu.DemoHanyuu.DemoHanyuu.Demo\n 获取父类对象\n Reference\n\nJAVA反射\njava反射机制深入理解剖析\n\n","plink":"hanyuulu.github.io/java_reflection/"},{"title":"Java GC 机制备忘","date":"2020-03-26T12:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" GC\n\n垃圾回收(Garbage Collection)是Java虚拟机(JVM)垃圾回收器提供的一种用于在空闲时间不定时回收无任何对象引用的对象占据的内存空间的一种机制。\n垃圾回收回收的是无任何引用的对象占据的内存空间而不是对象本身。换言之，垃圾回收只会负责释放那些对象占有的内存。对象是个抽象的词，包括引用和其占据的内存空间。当对象没有任何引用时其占据的内存空间随即被收回备用，此时对象也就被销毁。\n\n 对象引用\n\n\n强引用\n\n\n软引用\nSoftReference:内存不够时被回收\n\n\n弱引用\nWeakReference:下一次GC时被回收\n\nReferenceQuene\n\n\n\n虚引用\nPhantomReference:目的是在被GC时获得通知\n\n\n 垃圾回收算法\n\n\n找到所有存活对象\n回收被无用对象占用的内存空间\n\n\n 判断对象是否是垃圾\n 引用计数 (Reference Counting Collector)\n\n堆中的每个对象都有引用计数器\n当对象被创建并被初始化赋值后，计数设置为1\n每多一个引用计数，加一，引用失效（超过生命周期，被设置了一个新值），减一\n回收所有引用计数为0的对象，并对其引用的所有对象计数减一\n优点\n\n简单高效\n对程序不被长时间打断的实时环境比较有利\n\n\n缺点\n\n难以检测循环引用\n增加程序执行开销\n\n\nJVM\n\n早期JVM使用引用计数\n目前大多数JVM使用对象引用遍历（根搜索算法）\n\n\n\n 根搜索算法 (Tracing Collector)\n\n\n\n根集 (Root Set)\n​\t正在执行的Java程序可以访问的引用变量(不是对象)的集合（包括局部变量、参数和类变量）\n​\t程序可以使用引用变量访问对象的属性和调用对象的方法\n\n\n\n\n\n通过一系列名为“GC Roots”的对象作为起始点，寻找对应的引用节点\n\n\n递归从这些引用节点向下寻找引用节点\n\n\n生成的链称为引用链，当一个对象没有被任何引用链上的引用节点引用时，证明对象不可用\n\n\nJava和C#目前采用Tracing Collector方法\n\n\n 标记可达对象\n\n\nGC Root\n\n虚拟机栈中引用的对象（栈帧中的本地变量表）\n方法区中的常量引用的对象\n方法区中的类静态属性引用的对象\n本地方法栈中JNI (Native方法) 的引用对象\n活跃线程\n\n\n标记步骤\n\n以GC Root对象开始，对内存中整个对象图进行遍历并标记所有访问到的对象为存活\n未被标记的对象将在后面被清除\n\n\n\n\n\n\n开始进行标记前，需要先暂停应用线程，否则如果对象图一直在变化的话是无法真正去遍历它的。暂停应用线程以便JVM可以尽情地收拾家务的这种情况又被称之为安全点（Safe Point），这会触发一次Stop The World(STW)暂停。触发安全点的原因有许多，但最常见的应该就是垃圾回收了。\n\n\n暂停时间的长短并不取决于堆内对象的多少也不是堆的大小，而是存活对象的多少。因此，调高堆的大小并不会影响到标记阶段的时间长短。\n\n\n在根搜索算法中，要真正宣告一个对象死亡，至少要经历两次标记过程\n\n如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它会被第一次标记并且进行一次筛选。筛选的条件是此对象是否有必要执行 finalize()方法。当对象没有覆盖finalize()方法，或finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为没有必要执行。\n如果该对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue队列中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行finalize()方法。finalize()方法是对象逃脱死亡命运的最后一次机会（因为一个对象的finalize()方法最多只会被系统自动调用一次），稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果要在finalize()方法中成功拯救自己，只要在finalize()方法中让该对象重新引用链上的任何一个对象建立关联即可。而如果对象这时还没有关联到任何链上的引用，那它就会被回收掉。\n\n\n\nGC判断对象是否可达看的是强引用。\n\n\n\n 回收垃圾对象内存算法\n 标记-清除算法(Tracing Collector)\n\n优点\n\n不需要进行对象移动\n仅仅对不存活的对象进行处理\n\n\n缺点\n\n标记和清除过程的效率都不高，占用额外空间以用于标记空闲区域和大小\n会产生大量不连续的内存碎片\n\n\n\n\n\n 标记-整理算法(Compacting Collect)\n\n让所有对象向一端移动\n清理掉端边界以外的内存\n使用句柄和句柄表\n优点\n\n经过整理之后，新对象的分配只需要通过指针碰撞便能完成 (Pointer Bumping)\n空闲区域的位置可知，碎片化程度低\n\n\n缺点\n\ngc暂停时间变长（复制所有对象+更新引用地址）\n\n\n\n\n\n Copying算法(Copying Collector)\n\n将内存按容量分为大小相等的两块，每次使用其中一块（对象面），当内存用完时，将存活的对象复制到另一块内存上（空闲面），并一次性清理使用过的内存空间\n优点\n\n克服了句柄开销\n解决了堆碎片的垃圾回收\n标记和复制可以同时进行\n每次只对一块内存进行回收，运行高效\n只需移动栈顶指针，按顺序分配内存，实现简单\ngc时无需考虑碎片问题\n\n\n缺点\n\n空间利用率低下\n\n\n\n\n复制算法比较适合于新生代（短生存期的对象），在老年代（长生存期的对象）中，对象存活率比较高，如果执行较多的复制操作，效率将会变低，所以老年代一般会选用其他算法，如标记—整理算法。一种典型的基于Coping算法的垃圾回收是stop-and-copy算法，它将堆分成对象区和空闲区，在对象区与空闲区的切换过程中，程序暂停执行。\n\n\n\n Adaptive Collector\n监控当前堆的使用情况，选择适当算法的GC(综合)\n Java内存空间\n\n\n\n程序计数器：是一块较小内存，可以看作是当前线程所执行的字节码的行号指示器。每条线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响。\n\n\nJava虚拟机栈：Java虚拟机栈也是线程私有，他的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量、操作数、操作数栈、动态链接、方法出口等信息。每一个方法的调用过程直至执行完成的过成，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。\n\n\n局部变量表:存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型。如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常;如果虚拟机可以动态扩展，如扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。\n\n\n本地方法栈：与虚拟机栈类似，他们之间的区别是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。\n\n\nJava堆：Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域。在此内存区域中唯一目的就是存放对象实例，几乎所有的对象都在这里分配内存。\nJava堆是垃圾收集器管理的主要区域。也叫“GC堆”。从内存回收的角度来看，由于现在的收集器基本都采用分代收集算法，所以Java堆还可以细分为：新生代和老年代;在细致一点的有Eden空间、From Survivor空间、To Survivor空间等。从内存分配的家读来看，线程共享的Java堆中可能划分出多个线程私有分配缓冲区（Thread Local Allocation Buffer，TLAB）。不过无论如何划分，都与存放内容无关，无论那个区域，存储的都是对象实例，进一步划分的目的是为了更好地回收内存，或者更快的分配内存。Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。\n\n\n方法区（Method Area）：和Java堆一样也是各个线程共享的内存区域，他用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。使用永久代实现方法区。\n\n\n Java的堆内存\n\nJava的堆内存基于Generation算法（Generational Collector）划分为新生代、年老代和持久代。新生代又被进一步划分为Eden和Survivor区，最后Survivor由FromSpace（Survivor0）和ToSpace（Survivor1）组成。所有通过new创建的对象的内存都在堆中分配，其大小可以通过-Xmx和-Xms来控制。\n分代收集，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，可以将不同生命周期的对象分代，不同的代采取不同的回收算法（4.1-4.3）进行垃圾回收（GC），以便提高回收效率。\n\n\n\n\n年轻代(Young Generation)\n几乎所有新生成的对象首先都是放在年轻代的。新生代内存按照8:1:1的比例分为一个Eden区和两个Survivor(Survivor0,Survivor1)区。大部分对象在Eden区中生成。当新对象生成，Eden Space申请失败（因为空间不足等），则会发起一次GC(Scavenge GC)。回收时先将Eden区存活对象复制到一个Survivor0区，然后清空Eden区，当这个Survivor0区也存放满了时，则将Eden区和Survivor0区存活对象复制到另一个Survivor1区，然后清空Eden和这个Survivor0区，此时Survivor0区是空的，然后将Survivor0区和Survivor1区交换，即保持Survivor1区为空， 如此往复。当Survivor1区不足以存放 Eden和Survivor0的存活对象时，就将存活对象直接存放到老年代。当对象在Survivor区躲过一次GC的话，其对象年龄便会加1，默认情况下，如果对象年龄达到15岁，就会移动到老年代中。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收。新生代大小可以由-Xmn来控制，也可以用-XX:SurvivorRatio来控制Eden和Survivor的比例。\n\n\n年老代(Old Generation)\n在年轻代中经历了若干次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。一般来说，大对象会被直接分配到老年代。所谓的大对象是指需要大量连续存储空间的对象，最常见的一种大对象就是大数组。\n\n\n持久代(Permanent Generation)\n用于存放静态文件（class类、方法）和常量等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。对永久代的回收主要回收两部分内容：废弃常量和无用的类。\n永久代空间在Java SE8特性中已经被移除。取而代之的是元空间（MetaSpace）。因此不会再出现“java.lang.OutOfMemoryError: PermGen error”错误。\n\n\n特征\n\n对象优先在Eden分配\n大对象直接进入老年代\n长期存活的对象进入老年代\n\n\n\n\n新生代GC（Minor GC/Scavenge GC）：发生在新生代的垃圾收集动作。因为Java对象大多都具有朝生夕灭的特性，因此Minor GC非常频繁(不一定等Eden区满了才触发)，一般回收速度也比较快。在新生代中，每次垃圾收集时都会发现有大量对象死去，只有少量存活，因此可选用复制算法来完成收集。\n老年代GC（Major GC/Full GC）：发生在老年代的垃圾回收动作。Major GC，经常会伴随至少一次Minor GC。由于老年代中的对象生命周期比较长，因此Major GC并不频繁，一般都是等待老年代满了后才进行Full GC，而且其速度一般会比Minor GC慢10倍以上。另外，如果分配了Direct Memory，在老年代中进行Full GC时，会顺便清理掉Direct Memory中的废弃对象。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记—清除算法或标记—整理算法来进行回收。\n新生代采用空闲指针的方式来控制GC触发，指针保持最后一个分配的对象在新生代区间的位置，当有新的对象要分配内存时，用于检查空间是否足够，不够就触发GC。当连续分配对象时，对象会逐渐从Eden到Survivor，最后到老年代。\n\n 垃圾回收器(GC)\n\n串行垃圾回收器（Serial Garbage Collector）\n并行垃圾回收器（Parallel Garbage Collector）\n并发标记扫描垃圾回收器（CMS Garbage Collector）\nG1垃圾回收器（G1 Garbage Collector）\n\n\n\n\n串行垃圾回收器\n串行垃圾回收器通过持有应用程序所有的线程进行工作。它为单线程环境设计，只使用一个单独的线程进行垃圾回收，通过冻结所有应用程序线程进行工作，所以可能不适合服务器环境。它最适合的是简单的命令行程序（单CPU、新生代空间较小及对暂停时间要求不是非常高的应用）。是client级别默认的GC方式。\n\n通过JVM参数-XX:+UseSerialGC可以使用串行垃圾回收器。\n\n\n\n2、并行垃圾回收器\n并行垃圾回收器也叫做 throughput collector 。它是JVM的默认垃圾回收器。与串行垃圾回收器不同，它使用多线程进行垃圾回收。相似的是，当执行垃圾回收的时候它也会冻结所有的应用程序线程。\n适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式。可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。\n3、并发标记扫描垃圾回收器\n并发标记垃圾回收使用多线程扫描堆内存，标记需要清理的实例并且清理被标记过的实例。并发标记垃圾回收器只会在下面两种情况持有应用程序所有线程。\n（1）当标记的引用对象在Tenured区域；\n（2）在进行垃圾回收的时候，堆内存的数据被并发的改变。\n相比并行垃圾回收器，并发标记扫描垃圾回收器使用更多的CPU来确保程序的吞吐量。如果我们可以为了更好的程序性能分配更多的CPU，那么并发标记上扫描垃圾回收器是更好的选择相比并发垃圾回收器。\n JVM实现情况\nHotSpot（JDK 7)虚拟机提供的几种垃圾收集器\n垃圾收集算法是内存回收的理论基础，而垃圾收集器就是内存回收的具体实现。用户可以根据自己的需求组合出各个年代使用的收集器。\n1.Serial（SerialMSC）（Copying算法）\nSerial收集器是最基本最古老的收集器，它是一个单线程收集器，并且在它进行垃圾收集时，必须暂停所有用户线程。Serial收集器是针对新生代的收集器，采用的是Copying算法。\n2.Serial Old （标记—整理算法）\nSerial Old收集器是针对老年代的收集器，采用的是Mark-Compact算法。它的优点是实现简单高效，但是缺点是会给用户带来停顿。\n2.ParNew （Copying算法）\nParNew收集器是新生代收集器，Serial收集器的多线程版本。使用多个线程进行垃圾收集，在多核CPU环境下有着比Serial更好的表现。\n3.Parallel Scavenge （Copying算法）\nParallel Scavenge收集器是一个新生代的多线程收集器（并行收集器），它在回收期间不需要暂停其他用户线程，其采用的是Copying算法，该收集器与前两个收集器有所不同，它主要是为了达到一个可控的吞吐量。追求高吞吐量，高效利用CPU。吞吐量一般为99%。 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。\n4.Parallel Old（ParallelMSC）（标记—整理算法）\nParallel Old是Parallel Scavenge收集器的老年代版本（并行收集器），使用多线程和Mark-Compact算法。吞吐量优先。\n5.CMS  （标记—整理算法）\nCMS（Current Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它是一种并发收集器，采用的是Mark-Sweep算法。高并发、低停顿，追求最短GC回收停顿时间，CPU占用比较高。响应时间快，停顿时间短，多核CPU 追求高响应时间的选择。\n6.G1\nG1收集器是当今收集器技术发展最前沿的成果，它是一款面向服务端应用的收集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发收集器，并且它能建立可预测的停顿时间模型。\nG1垃圾回收器适用于堆内存很大的情况，他将堆内存分割成不同的区域，并且并发的对其进行垃圾回收。G1也可以在回收内存之后对剩余的堆内存空间进行压缩。并发扫描标记垃圾回收器在STW情况下压缩内存。G1垃圾回收会优先选择第一块垃圾最多的区域。\n通过JVM参数 –XX:+UseG1GC 使用G1垃圾回收器。\nJava 8 的新特性：\n在使用G1垃圾回收器的时候，通过 JVM参数 -XX:+UseStringDeduplication 。 我们可以通过删除重复的字符串，只保留一个char[]来优化堆内存。这个选择在Java 8 u 20被引入。\n我们给出了全部的几种Java垃圾回收器，需要根据应用场景，硬件性能和吞吐量需求来决定使用哪一种。\n新生代收集器使用的收集器：Serial、PraNew、Parallel Scavenge。\n老年代收集器使用的收集器：Serial Old、Parallel Old、CMS。\n 垃圾回收执行时间和注意事项\nGC分为Scavenge GC和Full GC。\nScavenge GC ：发生在Eden区的垃圾回收。\nFull GC :对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。\n有如下原因可能导致Full GC：\n1.年老代（Tenured）被写满;\n2.持久代（Perm）被写满;\n3.System.gc()被显示调用;\n4.上一次GC之后Heap的各域分配策略动态变化.\n 与垃圾回收时间有关的两个函数\n\n\nSystem.gc()方法\n命令行参数监视垃圾收集器的运行：\n使用System.gc()可以不管JVM使用的是哪一种垃圾回收的算法，都可以请求Java的垃圾回收。在命令行中有一个参数-verbosegc可以查看Java使用的堆内存的情况，它的格式如下：\njava -verbosegc classfile\n需要注意的是，调用System.gc()也仅仅是一个请求(建议)。JVM接受这个消息后，并不是立即做垃圾回收，而只是对几个垃圾回收算法做了加权，使垃圾回收操作容易发生，或提早发生，或回收较多而已。\n\n\nfinalize()方法\n概述：在JVM垃圾回收器收集一个对象之前，一般要求程序调用适当的方法释放资源。但在没有明确释放资源的情况下，Java提供了缺省机制来终止该对象以释放资源，这个方法就是finalize（）。它的原型为：\nprotected void finalize() throws Throwable\n在finalize()方法返回之后，对象消失，垃圾收集开始执行。原型中的throws Throwable表示它可以抛出任何类型的异常。\n意义：之所以要使用finalize()，是存在着垃圾回收器不能处理的特殊情况。假定你的对象（并非使用new方法）获得了一块“特殊”的内存区域，由于垃圾回收器只知道那些显示地经由new分配的内存空间，所以它不知道该如何释放这块“特殊”的内存区域，那么这个时候Java允许在类中定义一个finalize()方法。\n特殊的区域例如：1）由于在分配内存的时候可能采用了类似 C语言的做法，而非JAVA的通常new做法。这种情况主要发生在native method中，比如native method调用了C/C方法malloc()函数系列来分配存储空间，但是除非调用free()函数，否则这些内存空间将不会得到释放，那么这个时候就可能造成内存泄漏。但是由于free()方法是在C/C中的函数，所以finalize()中可以用本地方法来调用它。以释放这些“特殊”的内存空间。2）又或者打开的文件资源，这些资源不属于垃圾回收器的回收范围。\n换言之，finalize()的主要用途是释放一些其他做法开辟的内存空间，以及做一些清理工作。因为在Java中并没有提够像“析构”函数或者类似概念的函数，要做一些类似清理工作的时候，必须自己动手创建一个执行清理工作的普通方法，也就是override Object这个类中的finalize()方法。比如：销毁通知。\n一旦垃圾回收器准备好释放对象占用的存储空间，首先会去调用finalize()方法进行一些必要的清理工作。只有到下一次再进行垃圾回收动作的时候，才会真正释放这个对象所占用的内存空间。\nJAVA里的对象并非总会被垃圾回收器回收。1 对象可能不被垃圾回收，2 垃圾回收并不等于“析构”，3 垃圾回收只与内存有关。也就是说，并不是如果一个对象不再被使用，是不是要在finalize()中释放这个对象中含有的其它对象呢？不是的。因为无论对象是如何创建的，垃圾回收器都会负责释放那些对象占有的内存。\n当 finalize() 方法被调用时，JVM 会释放该线程上的所有同步锁。\n\n\n 触发主GC的条件\n\n当应用程序空闲时,即没有应用线程在运行时,GC会被调用。因为GC在优先级最低的线程中进行,所以当应用忙时,GC线程就不会被调用,但以下条件除外。\nJava堆内存不足时,GC会被调用。当应用线程在运行,并在运行过程中创建新对象,若这时内存空间不足,JVM就会强制地调用GC线程,以便回收内存用于新的分配。若GC一次之后仍不能满足内存分配的要求,JVM会再进行两次GC作进一步的尝试,若仍无法满足要求,则 JVM将报“out of memory”的错误,Java应用将停止。\n在编译过程中作为一种优化技术，Java 编译器能选择给实例赋 null 值，从而标记实例为可回收。\n由于是否进行主GC由JVM根据系统环境决定,而系统环境在不断的变化当中,所以主GC的运行具有不确定性,无法预计它何时必然出现,但可以确定的是对一个长期运行的应用来说,其主GC是反复进行的。\n\n 少GC开销的措施\n\n\n根据上述GC的机制,程序的运行会直接影响系统环境的变化,从而影响GC的触发。若不针对GC的特点进行设计和编码,就会出现内存驻留等一系列负面影响。为了避免这些影响,基本的原则就是尽可能地减少垃圾和减少GC过程中的开销。具体措施包括以下几个方面:\n\n\n不要显式调用System.gc()\n此函数建议JVM进行主GC,虽然只是建议而非一定,但很多情况下它会触发主GC,从而增加主GC的频率,也即增加了间歇性停顿的次数。\n\n\n尽量减少临时对象的使用\n临时对象在跳出函数调用后,会成为垃圾,少用临时变量就相当于减少了垃圾的产生,从而延长了出现上述第二个触发条件出现的时间,减少了主GC的机会。\n\n\n对象不用时最好显式置为Null\n一般而言,为Null的对象都会被作为垃圾处理,所以将不用的对象显式地设为Null,有利于GC收集器判定垃圾,从而提高了GC的效率。\n\n\n尽量使用StringBuffer,而不用String来累加字符串\n\n\n由于String是固定长的字符串对象,累加String对象时,并非在一个String对象中扩增,而是重新创建新的String对象,如Str5=Str1+Str2+Str3+Str4,这条语句执行过程中会产生多个垃圾对象,因为对次作“+”操作时都必须创建新的String对象,但这些过渡对象对系统来说是没有实际意义的,只会增加更多的垃圾。避免这种情况可以改用StringBuffer来累加字符串,因StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象。\n\n\n能用基本类型如Int,Long,就不用Integer,Long对象\n基本类型变量占用的内存资源比相应对象占用的少得多,如果没有必要,最好使用基本变量。\n\n\n尽量少用静态对象变量\n静态变量属于全局变量,不会被GC回收,它们会一直占用内存。\n\n\n分散对象创建或删除的时间\n集中在短时间内大量创建新对象,特别是大对象,会导致突然需要大量内存,JVM在面临这种情况时,只能进行主GC,以回收内存或整合内存碎片,从而增加主GC的频率。集中删除对象,道理也是一样的。它使得突然出现了大量的垃圾对象,空闲空间必然减少,从而大大增加了下一次创建新对象时强制主GC的机会。\n\n\n 关于垃圾回收的几点补充\n经过上述的说明，可以发现垃圾回收有以下的几个特点：\n（1）垃圾收集发生的不可预知性：由于实现了不同的垃圾回收算法和采用了不同的收集机制，所以它有可能是定时发生，有可能是当出现系统空闲CPU资源时发生，也有可能是和原始的垃圾收集一样，等到内存消耗出现极限时发生，这与垃圾收集器的选择和具体的设置都有关系。\n（2）垃圾收集的精确性：主要包括2 个方面：（a）垃圾收集器能够精确标记活着的对象；（b）垃圾收集器能够精确地定位对象之间的引用关系。前者是完全地回收所有废弃对象的前提，否则就可能造成内存泄漏。而后者则是实现归并和复制等算法的必要条件。所有不可达对象都能够可靠地得到回收，所有对象都能够重新分配，允许对象的复制和对象内存的缩并，这样就有效地防止内存的支离破碎。\n（3）现在有许多种不同的垃圾收集器，每种有其算法且其表现各异，既有当垃圾收集开始时就停止应用程序的运行，又有当垃圾收集开始时也允许应用程序的线程运行，还有在同一时间垃圾收集多线程运行。\n（4）垃圾收集的实现和具体的JVM 以及JVM的内存模型有非常紧密的关系。不同的JVM 可能采用不同的垃圾收集，而JVM 的内存模型决定着该JVM可以采用哪些类型垃圾收集。现在，HotSpot 系列JVM中的内存系统都采用先进的面向对象的框架设计，这使得该系列JVM都可以采用最先进的垃圾收集。\n（5）随着技术的发展，现代垃圾收集技术提供许多可选的垃圾收集器，而且在配置每种收集器的时候又可以设置不同的参数，这就使得根据不同的应用环境获得最优的应用性能成为可能。\n针对以上特点，我们在使用的时候要注意：\n（1）不要试图去假定垃圾收集发生的时间，这一切都是未知的。比如，方法中的一个临时对象在方法调用完毕后就变成了无用对象，这个时候它的内存就可以被释放。\n（2）Java中提供了一些和垃圾收集打交道的类，而且提供了一种强行执行垃圾收集的方法–调用System.gc()，但这同样是个不确定的方法。Java 中并不保证每次调用该方法就一定能够启动垃圾收集，它只不过会向JVM发出这样一个申请，到底是否真正执行垃圾收集，一切都是个未知数。\n（3）挑选适合自己的垃圾收集器。一般来说，如果系统没有特殊和苛刻的性能要求，可以采用JVM的缺省选项。否则可以考虑使用有针对性的垃圾收集器，比如增量收集器就比较适合实时性要求较高的系统之中。系统具有较高的配置，有比较多的闲置资源，可以考虑使用并行标记/清除收集器。\n（4）关键的也是难把握的问题是内存泄漏。良好的编程习惯和严谨的编程态度永远是最重要的，不要让自己的一个小错误导致内存出现大漏洞。\n（5）尽早释放无用对象的引用。大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域(scope)后，自动设置为null，暗示垃圾收集器来收集该对象，还必须注意该引用的对象是否被监听，如果有，则要去掉监听器，然后再赋空值。\n 补充\n Java内存泄露\n（1）静态集合类像HashMap、Vector等的使用最容易出现内存泄露，这些静态变量的生命周期和应用程序一致，所有的对象Object也不能被释放，因为他们也将一直被Vector等应用着。\n123456Static Vector v = new Vector();for (int i = 1; i&lt;100; i++)&#123;\tObject o = new Object();\tv.add(o);\to = null;&#125;\n在这个例子中，代码栈中存在Vector 对象的引用 v 和 Object 对象的引用 o 。在 For 循环中，我们不断的生成新的对象，然后将其添加到 Vector 对象中，之后将 o 引用置空。问题是当 o 引用被置空后，如果发生 GC，我们创建的 Object 对象是否能够被 GC 回收呢？答案是否定的。因为， GC 在跟踪代码栈中的引用时，会发现 v 引用，而继续往下跟踪，就会发现 v 引用指向的内存空间中又存在指向 Object 对象的引用。也就是说尽管o 引用已经被置空，但是 Object 对象仍然存在其他的引用，是可以被访问到的，所以 GC 无法将其释放掉。如果在此循环之后， Object 对象对程序已经没有任何作用，那么我们就认为此 Java 程序发生了内存泄漏。\n（2）各种连接，数据库连接，网络连接，IO连接等没有显示调用close关闭，不被GC回收导致内存泄露。\n（3）监听器的使用，在释放对象的同时没有相应删除监听器的时候也可能导致内存泄露。\n GC性能调优\nJava虚拟机的内存管理与垃圾收集是虚拟机结构体系中最重要的组成部分，对程序（尤其服务器端）的性能和稳定性有着非常重要的影响。性能调优需要具体情况具体分析，而且实际分析时可能需要考虑的方面很多，这里仅就一些简单常用的情况作简要介绍。\n我们可以通过给Java虚拟机分配超大堆（前提是物理机的内存足够大）来提升服务器的响应速度，但分配超大堆的前提是有把握把应用程序的Full GC频率控制得足够低，因为一次Full GC的时间造成比较长时间的停顿。控制Full GC频率的关键是保证应用中绝大多数对象的生存周期不应太长，尤其不能产生批量的、生命周期长的大对象，这样才能保证老年代的稳定。\nDirect Memory在堆内存外分配，而且二者均受限于物理机内存，且成负相关关系。因此分配超大堆时，如果用到了NIO机制分配使用了很多的Direct Memory，则有可能导致Direct Memory的OutOfMemoryError异常，这时可以通过-XX:MaxDirectMemorySize参数调整Direct Memory的大小。\n除了Java堆和永久代以及直接内存外，还要注意下面这些区域也会占用较多的内存，这些内存的总和会受到操作系统进程最大内存的限制：1、线程堆栈：可通过-Xss调整大小，内存不足时抛出StackOverflowError（纵向无法分配，即无法分配新的栈帧）或OutOfMemoryError（横向无法分配，即无法建立新的线程）。\nSocket缓冲区：每个Socket连接都有Receive和Send两个缓冲区，分别占用大约37KB和25KB的内存。如果无法分配，可能会抛出IOException：Too many open files异常。关于Socket缓冲区的详细介绍参见我的Java网络编程系列中深入剖析Socket的几篇文章。\nJNI代码：如果代码中使用了JNI调用本地库，那本地库使用的内存也不在堆中。\n虚拟机和GC：虚拟机和GC的代码执行也要消耗一定的内存。\n 代码分析垃圾回收过程\n123456public class SlotGc&#123;        public static void main(String[] args)&#123;             byte[] holder = new byte[32*1024*1024];              System.gc();        &#125;&#125;\n代码很简单，就是向内存中填充了32MB的数据，然后通过虚拟机进行垃圾收集。在Javac编译后，在终端执行如下指令：java -verbose:gc SlotGc来查看垃圾收集的结果，得到如下输出信息：\n[GC 208K-&gt;134K(5056K), 0.0017306 secs]\n[Full GC 134K-&gt;134K(5056K), 0.0121194 secs]\n[Full GC 32902K-&gt;32902K(37828K), 0.0094149 sec]\n注意第三行，“-&gt;”之前的数据表示垃圾回收前堆中存活对象所占用的内存大小，“-&gt;”之后的数据表示垃圾回收堆中存活对象所占用的内存大小，括号中的数据表示堆内存的总容量，0.0094149 sec 表示垃圾回收所用的时间。\n从结果中可以看出，System.gc(（）运行后并没有回收掉这32MB的内存，这应该是意料之中的结果，因为变量holder还处在作用域内，虚拟机自然不会回收掉holder引用的对象所占用的内存。\n修改代码如下：\n1234567public class SlotGc&#123;          public static void main(String[] args)&#123;      &#123;          byte[] holder = new byte[32*1024*1024];          &#125;          System.gc();      &#125;&#125;\n加入花括号后，holder的作用域被限制在了花括号之内，因此，在执行System.gc（）时，holder引用已经不能再被访问，逻辑上来讲，这次应该会回收掉holder引用的对象所占的内存。但查看垃圾回收情况时，输出信息如下：\n[GC 208K-&gt;134K(5056K), 0.0017100 secs]\n[Full GC 134K-&gt;134K(5056K), 0.0125887 secs]\n[Full GC 32902K-&gt;32902K(37828K), 0.0089226 secs]\n很明显，这32MB的数据并没有被回收。下面我们再做如下修改：\n123456789public class SlotGc&#123;        public static void main(String[] args)&#123;    &#123;               byte[] holder = new byte[32*1024*1024];               holder = null;             &#125;         System.gc();    &#125;&#125;\n这次得到的垃圾回收信息如下：\n[GC 208K-&gt;134K(5056K), 0.0017194 secs]\n[Full GC 134K-&gt;134K(5056K), 0.0124656 secs]\n[Full GC 32902K-&gt;134K(37828K), 0.0091637 secs]\n说明这次holder引用的对象所占的内存被回收了。\n首先明确一点：holder能否被回收的根本原因是局部变量表中的Slot是否还存有关于holder数组对象的引用。\n在第一次修改中，虽然在holder作用域之外进行回收，但是在此之后，没有对局部变量表的读写操作，holder所占用的Slot还没有被其他变量所复用。所以作为GC Roots一部分的局部变量表仍保持者对它的关联。这种关联没有被及时打断，因此GC收集器不会将holder引用的对象内存回收掉。 在第二次修改中，在GC收集器工作前，手动将holder设置为null值，就把holder所占用的局部变量表中的Slot清空了，因此，这次GC收集器工作时将holder之前引用的对象内存回收掉了。\n当然，我们也可以用其他方法来将holder引用的对象内存回收掉，只要复用holder所占用的slot即可，比如在holder作用域之外执行一次读写操作。\n为对象赋null值并不是控制变量回收的最好方法，以恰当的变量作用域来控制变量回收时间才是最优雅的解决办法。另外，赋null值的操作在经过虚拟机JIT编译器优化后会被消除掉，经过JIT编译后，System.gc（）执行时就可以正确地回收掉内存，而无需赋null值。\n Reference\n\n浅谈Java的垃圾回收机制（GC）\n\n","plink":"hanyuulu.github.io/java_gc/"},{"title":"使用OpenSSL生成SSL数字认证以用于Nginx的HTTPS通信","date":"2020-03-22T00:00:00.000Z","updated":"2021-03-12T08:22:58.566Z","content":"\n\n生成私钥\nopenssl genrsa -out private.pem 2048\n\n\n利用生成的私钥生成公钥\nopenssl req -x500 -key private.pem -out cert.pem -days 3650\n\n\n修改配置文件\n123456789101112131415161718server &#123;\tlisten 443;    \tssl on;    \tssl_certificate /etc/ssl/cacert.pem;        \t# path to your cacert.pem    \tssl_certificate_key /etc/ssl/privkey.pem;      # path to your privkey.pem      server_name seafile.example.com;      server_tokens off;      # ......      proxy_pass http://127.0.0.1:8000;      proxy_set_header   Host $host;      proxy_set_header   X-Real-IP $remote_addr;      proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;      proxy_set_header   X-Forwarded-Host $server_name;      proxy_set_header   X-Forwarded-Proto https;  proxy_read_timeout  1200s;&#125;\n\n\n强制将http请求转为https请求\n123456server &#123;        listen  80;        listen  [::]:80;        rewrite ^ https://$http_host$request_uri? permanent;        server_tokens off;&#125;\n\n\n","plink":"hanyuulu.github.io/openssl/"},{"title":"数据库实践复习提纲","date":"2020-03-17T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" PL/SQL\n\n\nDDL\n\n\nDML\n\n\nDCL\n\n\nTCL\n\n\n\n\n创建同义词\n\n\ncreate synonym A for B;\n\n同一用户的同一名称空间内对象名不得重复\n伪列\n数据字典\n\n View\n","plink":"hanyuulu.github.io/database/"},{"title":"传感器导论","date":"2020-03-11T23:03:06.000Z","updated":"2021-03-12T08:22:58.442Z","content":" Chapter 1\n 传感器\n\n\n传感器\n\n\n将被测信号转换为电/光信号\n\n\n组成\n\n\n敏感元件\n\n\n转换元件\n\n\n转换（测量）电路\n\n\ne.g.\n\n\n\n测量分类\n\n被测量\n\n热工量\n\n温度、热量、比热；压力、压差、真空度；流量、流速、风速\n\n\n机械量\n\n位移（线、角）、尺寸、形状；力、力矩、应力、；重量、质量；转速、线速度、震动幅度、频率、加速度、噪声；\n\n\n物性和成份量\n\n气体、液体化学成分；酸碱度、盐度等\n\n\n状态量\n\netc\n\n\n\n\n原理\n\n电阻式\n光电式\n电感式\n谐振式\n电容式\n霍尔式\n阻抗式\n超声式\netc……\n\n\n\n\n\n分类目的\n\n\n一般要求\n\n足够的容量（量程）\n灵敏度高，精度适当\n响应速度快，工作稳定，可靠性好\n使用性和适应性强使用经济\n\n\n\n\n\n\n数据丢失\n\n 传感器的选择标准\n\n依据测量对象和使用条件选定传感器类型\n了解使用条件\n线性范围与量程\n灵敏度\n精度\n频率响应特性\n稳定性\n\n 传感器的标定和校准\n\n静态标定\n动态标定\n\n Chapter 2 电阻式传感器\n 基本结构\n 应变电阻效应\n设有一段长为lll，截面积为AAA，电阻率为ρ\\rhoρ的固态导体，有\nR=ρlAR=\\rho\\frac{l}{A}\nR=ρAl​\n\n有(μ\\muμ:导体材料的泊松比)\ndRR=(1+2μ)ϵ+dρρ\\frac{dR}{R}=(1+2\\mu)\\epsilon+\\frac{d\\rho}{\\rho}\nRdR​=(1+2μ)ϵ+ρdρ​\n 金属材料的应变电阻效应\n金属材料电阻率相对变化与体积相对变化的关系\ndρρ=CdVV\\frac{d\\rho}{\\rho}=C\\frac{dV}{V}\nρdρ​=CVdV​\nΔRR=[(1+2μ)=C(1−2μ)]ϵ=KmϵKm=(1+2μ)=C(1−2μ)\\frac{\\Delta R}{R}=[(1+2\\mu)=C(1-2\\mu)]\\epsilon=K_m\\epsilon\\\\\nK_m=(1+2\\mu)=C(1-2\\mu)\nRΔR​=[(1+2μ)=C(1−2μ)]ϵ=Km​ϵKm​=(1+2μ)=C(1−2μ)\n 半导体材料的应变电阻效应\n 压阻效应\ndρρ=πσ=πEϵ\\frac{d\\rho}{\\rho}=\\pi\\sigma=\\pi E\\epsilon\nρdρ​=πσ=πEϵ\nσ\\sigmaσ:作用于材料的轴向盈利，π\\piπ：半导体材料在受力方向的亚族系数，EEE:半导体材料的弹性模量\nΔRR=[(1+2μ)+πE]ϵ=KsϵKm=(1+2μ)+πE\\frac{\\Delta R}{R}=[(1+2\\mu)+\\pi E]\\epsilon = K_s\\epsilon\\\\\nK_m=(1+2\\mu)+\\pi E\nRΔR​=[(1+2μ)+πE]ϵ=Ks​ϵKm​=(1+2μ)+πE\n 导电丝材料的应变电阻效应\nΔRR=K0ϵK0:导电丝材料的灵敏系数\\frac{\\Delta R}{R}=K_0\\epsilon\\\\\nK_0:导电丝材料的灵敏系数\nRΔR​=K0​ϵK0​:导电丝材料的灵敏系数\n 电阻式应变计的材料和类型\n\n 电阻应变计的主要特性\n 静态特性\n 灵敏系数\n在一定应变范围内有\nΔRR=Kϵxϵx:应变计轴向应变\\frac{\\Delta R}{R}=K\\epsilon_x\\\\\n\\epsilon_x:应变计轴向应变\nRΔR​=Kϵx​ϵx​:应变计轴向应变\n 横向效应\n\nΔRR=Kxϵx+Kyϵy=Kx(1+αH)ϵxKx:纵向灵敏系数Ky:横向灵敏系数\\frac{\\Delta R}{R}=K_x\\epsilon_x+K_y\\epsilon_y=K_x(1+\\alpha H)\\epsilon_x\\\\\nK_x:纵向灵敏系数\nK_y:横向灵敏系数\nRΔR​=Kx​ϵx​+Ky​ϵy​=Kx​(1+αH)ϵx​Kx​:纵向灵敏系数Ky​:横向灵敏系数\n横向效应减小灵敏系数和相对电阻比\n 机械滞后\n 蠕变与零漂\n反应长期稳定性\n 应变极限\n 动态特性\n\n正弦应变波\n阶跃应变波\n疲劳寿命\n\n 评定应变计主要特性的精度指标\n 电阻应变计的温度效应及其补偿\n 温度效应\n(ΔRR)=αtΔt+K(βs−β−t)Δtαt:敏感栅材料的电阻温度系数K:应变计的灵敏系数βs、βt:试件和敏感栅材料的线膨胀系数(\\frac{\\Delta R}{R})=\\alpha_t\\Delta t+K(\\beta_s-\\beta-t)\\Delta t\\\\\n\\alpha_t:敏感栅材料的电阻温度系数\\\\\nK:应变计的灵敏系数\\\\\n\\beta_s、\\beta_t:试件和敏感栅材料的线膨胀系数\n(RΔR​)=αt​Δt+K(βs​−β−t)Δtαt​:敏感栅材料的电阻温度系数K:应变计的灵敏系数βs​、βt​:试件和敏感栅材料的线膨胀系数\n有相对热输出：\nϵt=ΔRRtK=1tαtΔt+(βs−βt)Δt\\epsilon_t=\\frac{\\frac{\\Delta R}{R}_t}{K}=\\frac{1}{t}\\alpha_t\\Delta_t+(\\beta_s-\\beta_t)\\Delta_t\nϵt​=KRΔR​t​​=t1​αt​Δt​+(βs​−βt​)Δt​\n 热输出补偿\n\n\n温度自补偿法\n\n\n单丝自补偿\n\n\n双丝自补偿\n\n使αt=−K(βs−βt)\\alpha_t=-K(\\beta_s-\\beta_t)αt​=−K(βs​−βt​)\n\n\n\n\n\n桥路补偿法\n\n\n双丝半桥式\n\n\n\n补偿块法\n\n\n\n\n\n粘结剂选用\n\n\n 测量电路\n 应变电桥\n\n\n\n电桥结构\n\n\n\n电源\n\n直流电桥\n\n只能接入电阻\n\n\n交流电桥\n\n可以接入电阻电容电感\n\n\n\n\n\n工作方式\n\n平衡桥式电路\n不平衡桥式电路\n\n\n\n桥臂关系\n\n对输出端对称\n对电源端对称\n半等臂\n全等臂\n\n\n\n电压输出桥的输出特性\n\nU0=R1R3−R2R4(R1+R2)(R3+R4)⋅UU_0 = \\frac{R_1R_3-R_2R_4}{(R_1+R_2)(R_3+R_4)}\\cdot U\nU0​=(R1​+R2​)(R3​+R4​)R1​R3​−R2​R4​​⋅U\n\n\n电压灵敏度\nSu=(ΔU0ΔR1R1)=U4S_u = (\\frac{\\Delta U_0}{\\frac{\\Delta R_1}{R_1}})=\\frac{U}{4}\nSu​=(R1​ΔR1​​ΔU0​​)=4U​\n\n\n功率输出桥\nRL=R1R2R1+R2+R3R4R3+R4=RrR_L = \\frac{R_1R_2}{R_1+R_2}+\\frac{R_3R_4}{R_3+R_4} = R_r\nRL​=R1​+R2​R1​R2​​+R3​+R4​R3​R4​​=Rr​\n\n\n非线性误差和补偿\n\n\n应变计式传感器\n\n应用和测量范围广\n分辨率和灵敏度高\n结构轻小，对试件影响小，对复杂环境适应性强，etc…\n\n\n\n调平\n\n\n 变磁阻式传感器\n\n\n\n线圈电感\nL=W2RmRm:磁路总磁阻L = \\frac{W^2}{R_m}\\\\\nR_m:磁路总磁阻\nL=Rm​W2​Rm​:磁路总磁阻\n\n\n铜损电阻\n\n\n涡流损耗电阻\n\n\n磁滞损耗电阻\n\n\n总耗散因数和品质因数\n\n\n\n","plink":"hanyuulu.github.io/SensorTechnology/"},{"title":"DevOps CICD 零基础简介和实践","date":"2020-03-01T00:00:00.000Z","updated":"2021-03-12T08:22:58.534Z","content":" \n 关于DevOps和CICD\n 一些前置名词介绍\n\n\n敏捷开发：(Agile software development)是一种应对快速变化的需求的一种软件开发能力。相对于『非敏捷』，更强调程序猿团队和产品设计团队的紧密协作、面对面的沟通、频繁交付新的软件版本、紧凑而自我组织型的团队、能够更好的适应需求变化的代码编写和团队组织方法。\n\n\n持续集成：(Continuous Integration) 是一种软件开发实践，即团队开发人员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次的集成都通过自动化的构建（包括编译、发布、自动化测试）来验证\n\n\n持续部署：(Continuous Deployment) 通过自动化的构建、测试和部署循环来快速交付高质量的产品。某种程度上代表了一个开发团队工程化的程度。\n\n\n持续交付：(Continuous Delivery:CD) 让软件的产出过程在一个短周期内完成，以保证软件可以稳定、持续的保持在随时可以释出的状态。它的目标在于让软件的建制、测试与释放变的更快以及更频繁。这种方式可以减少软件开发的成本与时间，减少风险。\n\n\n 为什么需要DevOps?\n\n\n传统软件开发流程：\n\n规划→编码→构建→测试→发布→部署→维护\n开发\n\n规划、编码和构建\n\n\n测试\n\n测试\n\n\n运维\n\n发布、部署和维护\n\n\n早期的软件交付模型：瀑布模型（Waterfall）模型\n\n缺点\n\n反应迟缓、流程越往后走更改需求带来的额外成本急速上升\n\n\n\n\n\nDevOps\n\n\n\nDevelopment &amp; Operations\n\n\nDevOps是一组过程、方法与系统的统称，用于促进开发、技术运营和**质量保障（QA）**部门之间的沟通、协作与整合。\n\n\n\n\n\n从目标来看，DevOps就是让开发人员和运维人员更好地沟通合作，通过自动化流程来使得软件整体过程更加快捷和可靠。\n\n\n在DevOps的流程下，运维人员会在项目开发期间就介入到开发过程中，了解开发人员使用的系统架构和技术路线，从而制定适当的运维方案。而开发人员也会在运维的初期参与到系统部署中，并提供系统部署的优化建议。\n\n\nDevOps的实施，促进开发和运维人员的沟通，增进彼此的理解。\n\n\n\n\n\n\n\n CICD实践：以GitHub action平台为例\n UI\n\n Creating a workflow file\nAt a high level, these are the steps to add a workflow file. You can  find specific configuration examples in the sections that follow.\n\nAt the root of your repository, create a directory named .github/workflows to store your workflow files.\nIn .github/workflows, add a .yml or .yaml file for your workflow. For example, .github/workflows/continuous-integration-workflow.yml.\nUse the “Workflow syntax for GitHub Actions” reference documentation to choose events to trigger an action, add actions, and customize your workflow.\nCommit your changes in the workflow file to the branch where you want your workflow to run.\n\n Sample\n1234567891011121314151617181920name: Greet Everyone# This workflow is triggered on pushes to the repository.on: [push]jobs:  build:    # Job name is Greeting    name: Greeting    # This job runs on Linux    runs-on: ubuntu-latest    steps:      # This step uses GitHub's hello-world-javascript-action: https://github.com/actions/hello-world-javascript-action      - name: Hello world        uses: actions/hello-world-javascript-action@v1        with:          who-to-greet: 'Mona the Octocat'        id: hello      # This step prints an output (time) from the previous step's action.      - name: Echo the greeting's time        run: echo 'The time was $&#123;&#123; steps.hello.outputs.time &#125;&#125;.'\n Triggering a workflow with events\nYou can configure a workflow to start once:\n\nAn event on GitHub occurs, such as when someone pushes a commit to a repository or when an issue or pull request is created.\nA scheduled event begins.\nAn external event occurs.\n\n Getting started with a workflow\nTo help you get started, this guide shows you some basic examples. For the full GitHub Actions documentation on workflows, see “Configuring workflows.”\n\n Customizing when workflow runs are triggered\n\n\nSet your workflow to run on push events to the master and release/* branches\n12345on:  push:    branches:    - master    - release/*\n\n\nSet your workflow to run on pull_request events that target the master branch\n1234on:  pull_request:    branches:    - master\n\n\nSet your workflow to run every day of the week from Monday to Friday at 2:00 UTC\n123on:  schedule:  - cron: &quot;0 2 * * 1-5&quot;\n\n\nFor more information, see “Events that trigger workflows.”\n Running your jobs on different operating systems\nGitHub Actions provides hosted runners for Linux, Windows, and macOS.\nTo set the operating system for your job, specify the operating system using runs-on:\n1234jobs:  my_job:    name: deploy to staging    runs-on: ubuntu-18.04\nThe available virtual machine types are:\n\nubuntu-latest, ubuntu-18.04, or ubuntu-16.04\nwindows-latest, windows-2019, or windows-2016\nmacOS-latest or macOS-10.14\n\nFor more information, see “Virtual environments for GitHub Actions.”\n Using an action\nActions are reusable units of code that can be built and distributed by anyone on GitHub. You can find a variety of actions in GitHub Marketplace, and also in the official Actions repository.\nTo use an action, you must specify the repository that contains the action. We also recommend that you specify a Git tag to ensure you are using a released version of the action.\n1234- name: Setup Node  uses: actions/setup-node@v1  with:    node-version: &apos;10.x&apos;\nFor more information, see “Workflow syntax for GitHub Actions.”\n Running a command\nYou can run commands on the job’s virtual machine.\n12- name: Install Dependencies  run: npm install\nFor more information, see “Workflow syntax for GitHub Actions.”\n Running a job across a matrix of operating systems and runtime versions\nYou can automatically run a job across a set of different values, such as different versions of code libraries or operating systems.\nFor example, this job uses a matrix strategy to run across 3 versions of Node and 3 operating systems:\n123456789101112131415161718192021jobs:  test:    name: Test on node $&#123;&#123; matrix.node_version &#125;&#125; and $&#123;&#123; matrix.os &#125;&#125;    runs-on: $&#123;&#123; matrix.os &#125;&#125;    strategy:      matrix:        node_version: [&apos;8&apos;, &apos;10&apos;, &apos;12&apos;]        os: [ubuntu-latest, windows-latest, macOS-latest]    steps:    - uses: actions/checkout@v1    - name: Use Node.js $&#123;&#123; matrix.node_version &#125;&#125;      uses: actions/setup-node@v1      with:        node-version: $&#123;&#123; matrix.node_version &#125;&#125;    - name: npm install, build and test      run: |        npm install        npm run build --if-present        npm test\nFor more information, see “Workflow syntax for GitHub Actions.”\n Running steps or jobs conditionally\nGitHub Actions supports conditions on steps and jobs using data present in your workflow context.\nFor example, to run a step only as part of a push and not in a pull_request, you can specify a condition in the if: property based on the event name:\n123steps:- run: npm publish  if: github.event == &apos;push&apos;\n Reference\n\nhttps://help.github.com/en/actions/\nhttps://zhuanlan.zhihu.com/p/34291715\nhttps://zhuanlan.zhihu.com/p/91371659\n\n\n非商业用途，不当引用导致利益纠纷与本人无关\n\n","plink":"hanyuulu.github.io/cicd/"},{"title":"低成本个人NAS搭建解决方案（带内网穿透）","date":"2019-12-10T00:00:00.000Z","updated":"2021-03-12T08:22:58.574Z","content":" Hardware\n\nPC 或者 Raspberrypi 3b+ 一台\n周边设备（键盘、鼠标、树莓派的储存卡之类）\n可用的网络链接（内网有内网穿透方案）\n\n Software\n\n操作系统下载\n\nx86/x86_64\n\nwindows\ndeepin\nubuntu\n\n\narmv7 (Raspberry 3b(+)/4b)\n\nraspbian\n\n\n\n\n\n\n搭建NAS可以使用server版本，机子有其他用途也可以使用其他版本\n\n Step\n\n以Raspberry 3b+、Raspbian Buster with desktop、Nignx、Seafile Community组合为例。\n\n\n安装操作系统，安装流程参见各下载链接的官方安装文档\n测试网络连接\n国内用户使用Luiux系统请替换源以加速后续安装。\n\ntuna\n\n\n找到对应的发行版然后戳右边问号小圆圈即可跳转到换源页面,比如raspbian的换源页面为https://mirrors.tuna.tsinghua.edu.cn/help/raspbian/\n\n\n安装seafile服务\n\n跳转到下载页面选择对应的服务器端程序，raspberry服务器端链接，下载最新的release的.tar.gz文件（无gui环境可以使用wget下载）\n参照seafile的官方教程:部署Seafile 服务器（使用SQLite）进行安装，我们假定你并未更改默认的端口号（file端口8082,hub端口8000,若更改了请自行在后续说明中自行对应即可)\n启动seafile测试能在localhost上访问到seafile服务\n`http://localhost:8000’\n\n\n安装Nginx服务\nsudo apt install nginx安装完后启动Nginx(apt装完后直接启动) http://localhost能访问到Nginx的默认页面\n将Nginx服务请求转接到seafile上\n编辑/etc/nginx/site-enabled/default或者Nginx目录下的nginx.conf文件(windows)，建立服务器配置，将根节点转接到hub端口(8000)，将/server节点转接到file端口(8082)，参考如下\n\n123456789101112  server &#123;        listen 80 default_server;\t# 监听在80端口，ipv4        listen [::]:80 default_server;\t# 监听在80端口, ipv6        location / &#123;\t# 节点                proxy_pass http://127.0.0.1:8000/;\t# 转发端口                client_max_body_size 8000m;\t# 请求体大小限制（决定上传下载文件大小上限）        &#125;        location /server/ &#123;                proxy_pass http://127.0.0.1:8082/;                client_max_body_size 8000m;        &#125;&#125;\n\n在seafile上进行设置\n\n管理员账户登陆，选择系统设置，设置，URL\n设置SERVICE_URL和FILE_SERVER_ROOT为http://[计算机名]和http://[计算机名]/server（树莓派计算机名默认为raspberrypi）\n\n\n做内网穿透（可选）\n\n使用zerotier，新建一个账号并创建一个网络\n在服务器上安装zerotier，下载并安装客户端\n加入网络（gui直接戳戳按钮，zerotier-cli请参阅zerotier-cli）\n\n\n\n Finish\n[](￣▽￣)*\n使用设备只需要安装zerotier并加入对应网络即可通过访问http://[服务器计算机名]即可\n","plink":"hanyuulu.github.io/privateNas/"},{"title":"软件测试小结","date":"2019-12-02T00:00:00.000Z","updated":"2021-03-12T08:22:58.522Z","content":"[toc]\n 概述\n 软件测试产生背景\n\n\n软件危机*\n软件的可靠性没有保障、维护费用不断上升、进度无法预测、成本增长无法控制、程序员无限增加等，形成软件开发局面失控的状态。\n\n\n缺陷累计放大\n\n\n缺陷出现原因\n\n产品说明书（主要原因）\n\n随意、易变、沟通不足\n\n\n设计（次要原因）\n\n随意、易变、沟通不足\n\n\n编码\n\n软件复杂度、进度压力、低级错误\n\n\n其他\n\n理解错误、测试错误\n\n\n\n缺乏规范化工程约束→缺陷的不断累积与放大效应\n\n\n\n阶段\n正确需求\n需求缺陷\n设计缺陷\n编码缺陷\n未发现缺陷\n\n\n\n\n需求阶段\n√\n√\n-\n-\n-\n\n\n设计阶段\n√\n√\n√\n-\n-\n\n\n编码阶段\n√\n√\n√\n√\n-\n\n\n测试阶段\n√\n√\n√\n√\n√\n\n\n\n\n\n有关测试观点的正确理解\n\n\n软件工程\n将系统化的、严格约束的、可量化的方法应用于软件的开发、运行和维护，即将工程化应用于软件\n\n\n\n\n 软件测试基本概念\n\n\n测试定义\n\nBill Hetzelt  定义\n\n测试就是建立一种信心，认为程序能够按照预期设想运行\n核心思想：测试是试图验证软件是可工作的\n\n\nGlenford J. Myers 定义\n\n测试是为发现错误而执行一个程序或系统的过程\n核心思想：测试是尽可能多地发现软件错误\n三个重要观点\n\n测试是为了证明程序有错，而不是证明程序无错误\n一个好的测试用例是在于他能发现至今未发现的错误\n一个成功的测试时发现了至今未发现的错误的测试\n\n\n\n\nIEEE Std 729-1983\n\n使用人工或是自动手段来运行或测定某个系统的过程，其目的在于检验它是否满足规定的需求或是弄清预期结果与实际结果之间的差别\n\n\nIEEE Std 610.12-1990\n1. 在特定的条件下运行系统或构建，观察或记录结果，对系统的某些方面做出评价\n2. 分析某个软件项已发现现存和要求的条件之差别并评价此软件项的特性\n\n\n\n测试与调试\n\n\n测试目的\n\n\n确保软件质量\n找出软件错误和缺陷，降低软件发布后潜在错误和缺陷造成的损失；验证软件是否能满足用户需求，树立对软件的信心。\n\n\n确保软件开发过程方向的正确性\n通过分析错误产生的原因帮助发现当前开发工作所采用的软件过程的缺陷，促进软件过程改进；为风险评估提供信息\n\n\n\n\n测试原理/原则\n\n\n用户至上\n所有测试都应追溯到用户需求。最严重的错误是导致软件是导致软件无法满足的需求。测试的目标是在用户发现缺陷前找到它们。\n\n\n测试是有计划的活动\n测试计划制定先于测试的执行；测试贯穿于全部软件生存周期。\n\n\n缺陷出现的集群性\n80%的错误可能源于20%的模块。\n\n\n测试应从“小规模”走向“大规模”\n最初测试单个程序模块，然后在集成的模块中找缺陷，最后在整个系统中找缺陷，最后在整个系统中找缺陷\n\n\n穷尽测试（完全测试）不可能\n\n输入量太大\n输出结果太多\n执行路径太多\netc\n\n\n\n有效的测试应由第三方独立进行\n有些测试应避免有开发人员进行\n\n\n测试无法揭示所有缺陷\n测试可以报告说有缺陷存在，但没有缺陷的话却不能说明软件没有缺陷\n\n\n测试的杀虫剂悖论\n潜在缺陷对已进行的测试具有免疫力\n\n\n测试是有风险的行为\n\n\n并非所有的缺陷都需要修复\n\n没有足够的时间\n不算真正的代码缺陷\n修复风险太大\n不值得修复\netc\n\n\n\n\n\n\n\n测试过程*\n\n拟定软件的测试计划\n编制软件测试大纲\n设计和生成测试用例\n\n测试用例定义\n\n一组输入即运行前提条件，和为某特定目标而生成的预期结果（测试用例的实质）\n一个文档，详细说明输入、期望输出，和为一测试项所准备的一组执行条件（测试用例的一种存在方式）\n\n\n测试用例设计准则\n\n代表性\n\n合理与不合理\n合法与非法\n边界和越界\n极限数据\n各种操作环境\netc\n\n\n可判定性\n可再现性\n\n\n\n\n实施测试\n分析测试结果（测试报告）\n\n收集测试结果\n生成测试报告\n\n\n\n\n\n测试用例（三要素）\n\n输入\n执行条件\n期望输出\n\n\n\n软件测试类型\n\n\nv模型\n\n需求分析↘概要设计↘详细设计↘编码V单元测试↗集成测试↗系统测试↗验收测试\n\n\n\nw模型\n\n\n\nx模型\n\n\n\n前置测试模型\n\n\n\nh模型\n\n\n\n\n\n软件测试w模型\n\n\n 软件测试现状和趋势\n\n\n软件测试的地位（工作量百分比）*\n\n\n\n阶段\n需求分析\n设计\n编码\n测试\n运行和维护\n\n\n\n\n\n20%\n15%\n20%\n45%\n-\n\n\n\n\n\n 白盒测试\n\n静态白盒测试\n\n\n在不执行代码的条件下有条理地仔细审查软件设计、体系结构和代码，从而找出软件缺陷的过程，有时被称为结构化分析\n\n\n尽早发现软件缺陷\n\n\n为后继测试中设计测试用例提供思路\n\n\ndesk checking\n\n\nPeer preview\n\n\nwalk through\n\n\nInspection\n\n\n动态白盒测试方法\n\n\n定义\n一种基于源程序或代码的测试方法。依据原程序或代码逻辑结构，生成测试用例以尽可能多地发现并修改源程序错误。\n白盒分为静态白盒测试和动态白盒测试\n\n\n实施者\n\n\n单元测试\n\n一般由开发人员进行\n\n\n\n集成测试\n\n\n测试人员和开发人员共同完成\n\n\n步骤\n\n\n动态\n\n程序图\n生成测试用例\n执行测试\n分析覆盖标准\n判定测试结果\n\n\n\n\n\n静态\n\n桌面检查\n代码走查\n代码审查\n\n\n\n优点\n\n检测代码中的判断和路径\n解释隐藏在代码中的错误\n对代码的测试比较彻底\n\n\n\n缺点\n\n无法检测代码中的不可达路径\n不验证需求规格\n\n\n\n\n\n基于控制流覆盖的测试\n\n语句覆盖测试\n\n语句覆盖\n\n程序中每条语句都执行一次\n\n处理错误的代码片段\n小概率事件（恶作剧）\n不可达代码\n较为脆弱，某些严重问题\n\n\n\n\n\n\n条件测试\n\n判定覆盖（分支覆盖）\n\n每个判断取值True和False各一次\n优点\n\n简单，包含语句覆盖并避免了语句覆盖覆盖的问题\n\n\n缺点\n\n忽略了表达式内的条件，不能发现每个条件的错误\n\n\n\n\n条件覆盖\n\n每个判断中的条件的取值至少满足一次\n不能保证程序所有分支都被执行\n\n\n判定条件覆盖\n每个条件和由条件组成的判断的取值至少满足一次\n\n错误屏蔽\n\n指原子条件取值改变不会影响判定结果，因此该条件上的取值错误是不可见的。\n\n\n注意短路\n\n\n\n\n条件组合覆盖\n\n每个条件的取值组合至少出现一次\n2n2^n2n（n为原子条件数），代价昂贵\n测试用例的约简\n\n利用短路效应寻找最小测试用例集\n\n\n\n\n路径测试\n\n路径覆盖\n\n优点\n\n相对彻底的测试\n\n\n缺点\n\n路径分支可能以指数级增加(2n2^n2n)\n存在不可达路径\n并未测试各个分支中的条件\n\n\n考虑了各种判定结果的所有可能组合但是不能覆盖判定条件中结果的各种情况\n覆盖能力较强但是不能替代条件覆盖和条件组合覆盖标准\n覆盖程序中的所有路径\n\n\n\n\n\n\n\n\n基于控制流的测试\n\n\n基本路径测试\n\n\n流程图→流图→（环复杂度）→基本路径→测试用例\n\n\n流图用来描述程序中的逻辑控制流\n\n\n节点\n\n\n表示一个或多个语句\n\n\n边\n\n\n表示控制流\n\n\n域\n\n\n由边和节点限定的区间\n\n\n基本路径\n\n\n任何贯穿程序 、至少引入一组新的处理语句或一个新判断的程序通道\n\n\n环复杂度是所有语句被执行一次所需测试用例数的上限\n\n\n\n环复杂度\n含义\n\n\n\n\n1-10\n良好\n\n\n11-20\n中等\n\n\n21-50\n复杂\n\n\n&gt;50\n无法理解\n\n\n\n\n\n\n\n\n\n\n基本路径集寻找算法\n\n确认从入口到出口的最短基本路径\n从入口到第一个未被先后评估为真和假两种结果的条件语句\n改变该条件语句的赋值\n重复步骤2-5直至所有基本路径都被找到\n\n\n\n循环测试\n\n嵌套循环\n先测试最内层循环\n*  按照简单循环测试\n\n由里向外，测试上层循环\n\n此层以外的所有外层循环变量取最小值\n此层以内所有嵌套内层循环变量取典型值\n\n\n重复上一条规则直至所有各层循环测试完毕\n对全部各层循环同时取最小循环次数或者同时取最大循环次数\n\n\n串接循环\n\n若串接循环的各个循环相互独立\n\n分别用简单循环测试\n\n\n若两个循环不独立\n\n把第一个循环看作外循环，第二个循环看作内循环，用测试嵌套循环的办法来处理\n\n\n\n\n非结构循环\n\n结构化再处理\n\n\n\n\n\n\n\n数据流测试\n\n\n数据流测试\n\n\n基本定义\n\n\nP——程序\n\n\nG§——程序图（流图）\n\n\nV——变量集合\n\n\nPATH§——P的所有路径集合\n\n\nDEF(v,n)——在节点n定义了变量v(变量赋值语句)\n\ne.g. input x; x = 2;\n\n\n\nUSE(v,n)——在节点n使用了变量v\n\ne.g. print x; a = 2 + x;\n\n\n\nP-use——USE(v,n)，谓词使用，即条件判断语句中\n\ne.g. if b &gt; 6\n\n\n\nC-use——USE(v,n)，运算使用，位于运算中\n\n\ne.g. x = 3 + b\n\n\nO-use——输出使用\nL-use——定位使用（数组）\nI-use——迭代使用（循环）\n\n\n\n\n\n\ndu-path——定义-使用路径\n\n给定PATH§中的某条路径，如果定义节点DEF(v,m)为该路径的起始节点，使用节点USE(v,n)为该路径的终止节点，则该路径是v的一条du-path\n\n\n\ndc-path——定义-清除路径\n\n如果变量v的某个定义-使用路径，除起始节点外没有其他定义节点，则该变量路径是变量v的定义-清除路径\n\n\n\n\n\n数据流覆盖测试\n\n对于给定的程序，构造相应的程序图\n\n\n\n\n找出所有变量的du-path（可以约简）\n3.  考察测试用例对这些路径的覆盖程度\n\n\n\n常用覆盖标准\n\nRapps和Weyuker标准\n\nAll-Paths\n\n路径覆盖\n\n\nAll-Edges\n\n分支覆盖\n\n\nAll-Nodes\n\n语句覆盖\n\n\nAll-Defs\n\n每个定义节点都有一条dc-path\n\n\nAll-P-Use\n\n每个定义节点都有一条dc-path\n\n\nAll-P-Uses/some-C-Uses\nAll-C-Uses/Some-P-Uses\nAll-Users\n\n每个变量的定义节点都有一条dc-path到达该变量的使用节点\n\n\nAll-du-path\n\n\nNtafos标准\nUral标准\nLaski和Korel标准\n\n\n\n\n\n\n\n\n\n 白盒测试工具\n\n测试工具分类*\n\n静态分析工具\n动态分析工具\n\n\n测试工具的作用*\n\n提高代码效率\n降低测试成本\n\n\n\n 控制流覆盖的测试\n\n短路问题\n使用尽可能少的测试用例\n测试用例要体现控制流覆盖的特点\n对各个控制流覆盖标准有明确认识\n\n语句\n判定\n条件\n判定条件\n条件组合\n路径\n\n\n\n\n控制流覆盖不使用程序流图\n\n 基本路径测试\n\n正确画出流程图，出自组合条件的判定\n使用多种方法计算圈（环）复杂度\n正确得出基本路径（顺序）\n不是所有基本路径都能写出测试用例\n\n 数据流测试\n\n不考虑数据流覆盖的各种标准\n能够找出定义节点和使用节点\n列举出所有可能的DU路径\n进行DU路径约简\n\n 黑盒测试\n 黑盒测试基本概念\n\n定义*\n\n一种基于规格说明，不要求考察代码，以用户视角进行的测试\n\n\n意义*\n\n黑盒测试有助于软件产品的总体功能验证\n\n检查明确需求和隐含需求\n采用有效输入和无效输入\n包含用户视角\n\n\n\n\n目的\n\n有时无法获取程序代码\n尽早进行黑盒测试可以尽早发现软件功能缺陷\n弥补遗漏的逻辑缺陷\n适用于测试的各个阶段\n\n单元测试\n集成测试\n系统测试\n回归测试\n\n\n\n\n实施者\n\n专门的软件测试部门：有经验的测试人员\n\n\n步骤*\n\n规格说明书\n生成测试用例\n执行测试\n判定测试结果\n\n\n进入退出条件\n\n 黑盒测试方法基础\n\n\n基于需求的测试（RTM）*\n\n\n目的\n\n确认软件需求规格说明书列出的需求\n\n\n\n前提\n\n需求规格已经经过仔细评审\n隐含需求明确化\n\n\n\n需求规格说明样本\n\n需求规格说明\n\n\n\n\n序号\n需求标识\n需求描述\n优先级\n\n\n\n\n\n\n\n\n\n\n\n\n需求跟踪矩阵样本\n\n\n\n\n需求标识\n需求描述\n优先级\n测试条件\n用例标识\n测试阶段\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n需求跟踪矩阵(RTM)\n\n作用\n\n可跟踪每个需求的测试状态而不会遗漏任何需求\n优先执行优先级高的测试用例，尽早发现高优先级区域内缺陷\n可导出特定需求对应的测试用例清单\n评估测试工作量和测试进度的重要数据\n\n\n\n\n测试执行数据样本\n\n\n\n\n序号\n需求标识\n优先级\n测试用例\n用例总数\n通过用例\n未通过用例\n通过率\n缺陷数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n需求跟踪矩阵\n\n\n\n需求标识\n需求描述\n优先级\n测试条件\n用例标识\n测试阶段\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n作用\n\n可跟踪每个需求的测试状态而不会遗漏任何需求\n优先执行优先级高的测试用例，尽早发现高优先级区域内缺陷\n可导出特定需求对应的测试用例清单\n评估测试工作量和测试进度的重要数据\n\n\n\n\n\n正面测试*\n\n测试用例通过一组预期输出验证产品需求\n证明软件对于每条规格说明和期望都能通过\n\n\n\n负面测试*\n\n展示当输入非预期输入时产品没有失败\n使用产品没有设计和预想到的场景，尝试使系统垮掉\n负面测试不能映射到需求\n\n\n\n 黑盒测试方法\n\n\n等价划分\n\n原理\n\n将程序的输入域划分为数据类，以便导出测试用例\n他试图定义一个测试用例以发现各类错误，从而减少测试用例数目，降低测试工作量\n\n\n等价类（划分）\n\n如果软件行为对一组值来说是相同的，则称这组值为等价类\n产生同一个预期输出的一组输入值叫一个划分\n有效等价类\n\n完全满足产品规格说明的输入数据构成的集合\n\n\n无效等价类\n\n不满足程序输入要求或者无效的输入数据构成的集合\n\n\n划分类型\n\n布尔表达式\n\n一个有效等价类True\n一个无效等价类False\n\n\n范围\n\n一个有效等价类，范围内\n两个无效等价类，大于小于\n\n\n数据个数\n\n一个有效等价类，正确个数\n两个无效等价类，大于小于\n\n\n集合的某个子集\n\n一个有效等价类，正确集合\n若干无效等价类\n\n\n一组列表形式的数据\n\n多个有效等价类，每个输入数据为一个等价类\n1个无效等价类\n\n\n要求符合几个规则\n\n多个有效等价类\n若干无效等价类\n\n\n\n\n步骤\n\n划分准则\n确定有效等价类和无效等价类\n从等价类中选取样本数据\n根据需求写预期结果\n加入特殊值\n执行测试\n\n\n\n\n\n\n\n边界值分析\n\n\n软件的两个主要缺陷源\n\n条件\n边界\n\n\n\n边界值分析\n\n\n原因\n\n使用比较操作符时未仔细分析\n多种循环和条件检查方法引起的困惑\n对边界附近需求的理解不够\n\n\n\n测试边界\n\n第一个-1/最后一个+1\n开始-1/完成+1\n最小值-1/最大值+1\n\n\n\n界定边界值\n\nn存在边界值的参数个数\nm边界值条件个数\n\n\n\nPaul Jorgensen公式\n\n\n4n+1 基本边界测试\n\n\nmin\n\n\nmin+1\n\n\nmax-1\n\n\nmax\n\n\n一个典型值\n\n\n\n\n\n6n+1 健壮性边界测试\n\n\nmin-1\n\n\nmin\n\n\nmin+1\n\n\nmax-1\n\n\nmax\n\n\nmax+1\n\n\n一个典型值\n\n\n\n\n\n3m 边界条件测试\n\nself-1\nself\nself+1\n\n\n\n\n\n\n\n\n\n因果分析法\n\n因果图\n（需求规格说明书）→生成因果列表→（起因结果列表）→建立决策表→（决策表）→生成测试用例\n表示\n\n原因 CiC_iCi​\n结果 EiE_iEi​\n\n\n因果4种关系\n\n\n\n\n\n\n\n输入约束4种\n\n\n\n\n\n输出约束1种\n\n\n\n\n决策表\n\n\n\n\n-\n1\n2\n3\n4\n…\n\n\n\n\n条件C1\n\n\n\n\n\n\n\n条件C2\n\n\n\n\n\n\n\n条件Cn\n\n\n\n\n\n\n\n行动A1\n\n\n\n\n\n\n\n行动A2\n\n\n\n\n\n\n\n行动An\n\n\n\n\n\n\n\n测试用例（输出）\n\n\n\n\n\n\n\n\n\nStep\n\n分析规格说明书，识别原因和结果\n在因果图之间连接原因和结果\n表明原因之间以及结果之间的约束条件\n因果图转换为因果图列表进而生成决策表\n决策表的规则转换为测试用例\n\n\n\n\n\n决策表\n\n\n组成\n\n\n条件桩\n\n列出所有可能问题\n\n\n\n条件项\n\n解除条件所有可能取值\n\n\n\n动作桩\n\n列出可能采取的操作\n\n\n\n动作项\n\n在条件项的各种取值情况下应采取的动作\n\n\n\n决策规则，贯穿条件项和动作项的一列\n\n\n\n构造决策表\n\n列出所有的条件桩和条件项\n填入条件项\n填入动作项，得到初始决策表\n简化决策表，合并相似规则\n\n\n\n化简\n\n\n合并相似规则\n\n\n\n\n\n\n基于模型的测试*\n* 原理\n  * 软件执行过程可分解为若干对象和连接对象之间的关系\n    * 测试序列可视为验证对象间所期望的关系是否满足\n  \n* 适用领域\n  * 有限状态建模\n    * 工作流建模\n  * 数据流建模\n    * 时间建模\n\n\n模型化软件\n\n\n\n正交数组测试\n\n\n利用真叫测试再加上特殊用例测试，基本上可以均匀分散地覆盖到各种情况，又能大大减少测试用例个数\n\n\n正交表\n\n\n构成\n\n因子：输入参数\n水平：输入取值\n因子数：正交表中列的个数\n水平数：单个因子的取值个数\n行数：正交表行数\n记法：L行数(水平数因子数)L{行数}(水平数^{因子数})L行数(水平数因子数)\n\n\n\n正交表的正交性\n\n整齐可比\n\n每个因子的每个水平出现的次数完全相同\n\n\n均匀分散\n\n任意两列的水平搭配是完全相同的\n\n\n\n\n\n\ne.g.\n\n\nL4(23)L4(2^3)L4(23)\n\n\n\n\n1\n2\n3\n\n\n\n\n1\n1\n1\n1\n\n\n2\n1\n2\n2\n\n\n3\n2\n1\n2\n\n\n4\n2\n2\n1\n\n\n\n\n\n\n\n\n\n\n\nStep\n\n确定因子和水平\n判断是否能使用正交数组（因子少于2则不适用）\n选择合适的正交表\n把变量值映射到表中\n正交测试用例制作\n补充测试用例\n\n\n\n正交表选择\n\n正交表因子个数≥实际因子数\n正交表每个因子书的水平个数≥实际每个因子数的水平个数\n正交表的行数\n\n选择最少的正交表\n\n\n\n\n\n把变量值映射到表中\n\n正交测试用例制作\n补充测试用例\n\n\n\n\n\n蜕变测试\n\n\n随机测试\n 黑盒测试工具\n\n测试工具原理\n\n以GUI自动化测试工具为例\n\n运行北侧软件的同时，捕获过程中的键鼠操作，生成脚本文件，这个脚本文件可以被修改和回放\n\n\n\n\n作用\n\n\n\n 等价划分和边界值分析\n\n等价类划分一定要考虑全面，分为有效等价类和 无效等价类，并统一编号\n写测试用例时，每个等价类至少有一个测试用例\n边界值分析可考虑边界值和条件值\n边界值要考虑需求的限制、数据类型的限制、系统的限制等多种限制条件\n\n 因果图和决策表\n\n能够列出原因和结果列表\n因果图的画法\n根据因果图得出因果列表，进一步得出决策表\n决策表约简\n\n 单元测试和集成测试\n 软件测试\n\n基本概念*\n\n软件单元\n\n一个应用程序中的最小可测部分\n\n\n定义\n\n单元测试\n\n对最小的软件设计单元的验证工作\n\n\n模块测试\n\n对最小的软件设计模块的验证工作\n\n\n\n\n意义\n\n消除软件单元本身的不确定性\n其他测试阶段的必要的基础环节\n\n\n目标\n\n单元体现了预期的功能\n单元的运行能够覆盖预先设定的各种逻辑\n单元工作中：内部数据能够保持完整性\n可以接受正确数据，也能处理非法数据\n在数据边界上，单元能正常工作\n单元算法合理，性能良好\n扫描单元代码没有发现任何安全性问题\netc\n\n\n实施者\n\n软件开发人员\n\n\n关注点\n\n模块功能\n内部逻辑处理\n数据结构\n性能\n安全\n\n\n\n\n单元测试流程\n\n技术和步骤\n\n先设计测试用例，然后执行测试\n进入条件\n\n编码开始：设计测试数据并执行测试\n\n\n退出条件\n\n完成测试计划\n发现并修正错误\n预算和开发时间\n\n\n\n\n模块或构件接口\n\n目标\n\n进出模块/构件的数据流正确\n\n\n关注点\n\n接口名称、参数个数、类型、顺序的匹配\n输出或返回值的及其类型是否正确\n\n\n\n\n局部数据结构\n\n目标\n\n数据在模块执行中都维持完整性和正确性\n\n\n关注点\n\n局部数据定义和使用过程的正确性\n局部数据结构对全局数据机构的影响\n\n\n\n\n边界条件\n\n目标\n\n保证模块在边界条件上能够正确执行\n\n\n关注点\n\n数据机构中的边界\n控制流中的边界\n\n\n\n\n独立路径\n\n目标\n\n保证模块中的每条独立（基本）路径都要走一遍，使得所有语句都被执行过一次\n\n\n关注点\n\n对路径的选择性测试（基本路径测试+循环测试）\n\n\n\n\n处理错误的路径\n\n保证错误处理的正确性，软件的健壮性\n\n\n\n\n驱动器和程序桩\n\n驱动器\n\n对底层或子层模块进行测试时所编制的调用被测模块的程序，用以模拟被测模块的上级模块。\n\n\n程序桩\n\n对上层模块进行测试时，所编制的替代下层模块的程序，用以模拟被测模块工作过程中所调用的模块。\n\n\n高内聚低耦合可以让驱动器和测试桩编写更加简单并已于发现错误\n\n\n\n 集成测试\n\n概念*\n\n把单独的软件模块结合在一起作为整体接受测试\n\n\n接口*\n\n内部接口\n外部接口\n接口提供方法\n\nAPI\nSDK\n\n\n桩程序\n\n\n实施者\n\n软件测试人员\n软件开发人员\n\n\n瞬时集成测试\n\n当所有构建都通过单元测试，就把他们组合成一个最终系统，并观察它能够正常运转\n缺陷\n\n无休止的错误，修复困难\n一次性结合，难以找出错误原因\n容易和其他错误混淆\n\n\n\n\n增量集成测试\n\n特点\n\n将程序分成小的部分进行构造和测试\n\n\n优点\n\n错误容易分离和修正\n接口容易彻底测试\n\n\n缺点\n\n会有额外开销\n\n\n自顶向下\n\n深度优先\n广度优先\n优点\n\n尽早发现高层控制和决策错误\n最多只需要一个驱动器\n每步只增加一个模块\n\n\n缺点\n\n对底层模块的行为验证比较晚\n需要编写额外程序模拟未测试的模块\n部分测试用例由于依赖其他层次的模块，在该模块未测试之前，这些测试用例的输入输出很难确定\n\n\n\n\n自底向上\n\n从原子模块构造并集成测试\n优点\n\n尽早确认底层行为\n无需编写程序桩\n对实现特定功能的树容易表示输入输出\n\n\n缺点\n\n推迟确认高层行为\n需编写驱动器\n组合子树时，有许多元素要集成\n\n\n\n\n混合式集成\n\n综合\n\n\n\n\n\n 测试插装\n\n黑盒插装*\n\n随机数据生成器（随机测试）\n作用\n\n避免只测试所知道的将奏效的场景\n\n\n\n\n白盒插装*\n\n语句覆盖插桩\n分支覆盖插桩\n条件覆盖插桩\n插桩\n\n生成特定状态，检验状态的可达性\n显示或读取内部数据的私有数据\n检测不变数据\n检测前提条件\n人为触发事件时间\n检测事件时间\n\n\n\n\n\n 系统测试、确认测试和回归测试\n 系统测试\n\n\n概念\n\n定义\n\n对完整集成后的产品和解决方案的测试，用来评价系统对具体需求规格说明的功能和非功能的符合性的测试\n\n\n意义（特点）\n\n既是测试产品功能也是测试产品非功能的唯一测试阶段\n\n\n目的\n\n发现可能难以直接与模块或接口关联的缺陷\n发现产品设计、体系和代码的基础问题（产品级缺陷）\n\n\n实施者\n\n独立测试团队（引入独立视角，有助于发现遗漏缺陷）\n\n\n引入时机\n\n集成测试之后（基础的程序逻辑错误和缺陷已更正后）\n\n\n实施原因\n\n在测试中引入独立视角\n在测试中引入客户视角\n在测试用模拟用户的使用环境\n测试产品功能和非功能的问题\n建立对产品的信心\n分析和降低产品发布的风险\n保证满足所有需求，产品具备交付确认测试条件\n\n\n\n\n\n功能测试\n\n\n设计/体系结构测试\n\n\n原理\n\n对照设计和体系结构开发和测试用例，从而整理出产品级测试用例\n集成测试用例关注模块或组件间交互，而系统功能测试用例关注整个产品的行为\n\n\n\n方法\n\n\n体系结构静态测试\n\n体系结构分析\n对体系机构的特征进行建模、分析\n\ne.g.\n\n对类定义的一致性分析\n\n\n\n\n\n\n\n体系结构的动态测试\n\n\n\n测试用例特征\n建议\n\n\n\n\n测试用例关注代码逻辑、数据结构和产品单元\n单元测试\n\n\n测试用例关注组件接口\n集成测试\n\n\n测试用例关注的是不能为用户所看到的产品实现\n单元测试\\集成测试\n\n\n测试用例综合了客户使用和产品实现\n系统测试\n\n\n\n\n\n\n\n\n\n业务垂直测试\n\n\n原理\n\n针对不同业务纵深的产品，根据业务定制测试用例，验证业务运作和使用\n\n\n\n应用范围\n\n通用的工作流自动化系统在不同商业领域的应用\n\n\n\n方法\n\n\n模拟\n\n测试需求和业务流\n\n\n\n复制\n\n\n获取客户数据流和过程，针对特殊业务进行定制\n\n定制：改变系统的一般工作流，以适用于不同业务纵深\n术语：尽量使用各个业务领域的专属名词\n\n\n\n\n\n\n\n\n\n部署测试\n\n验证系统能够满足客户的部署需求\n目的\n\n特定产品版本短期内是否能够成功使用\n\n\n离场部署\n\n在产品开发组织内运行，以确保客户部署需求的（模拟）部署测试\n\n\n现场部署（离场部署的扩展）\n\n现场部署是指在客户场地中的资源和环境都发布后，实施的一种部署方案\n\n采集系统的采集系统真实数据，建立镜像测试环境，重新执行用户操作\n引入新产品，进行新业务操作，同实对比事务处理情况，以确定新系统能否能够替代老系统\n\n\n\n\n\n\n\nAlpha/Beta测试\n\nAlpha测试\n\n用户在开发环境下进行的受控测试\n特点\n\n不由程序员或测试员完成，但开发者会在现场\n\n\n\n\n在Alpha测试达到一定程度后进行Beta测试\nBeta测试\n\n用户在实际使用环境下进行测试，一种可以把待测产品交给客户收集反馈意见的机制\n特点\n\n开发者通常不在现场\n\n\n挑战\n\n客户数量\n\n客户充分了解产品\n\n\n\n\n\n\n\n\n\n符合性的认证、标准和测试\n\n产品需要通过主流硬件、操作系统、数据库和其他基础设施构建上进行的验证，并符合相关法规和行规\n主流基础设施\n\n操作系统\n硬件\n数据库\netc\n\n\n约定和法律要求\n\n质量行业标准\n法规\n技术领域标准\n\n\n\n\n\n\n\n非功能测试\n\n非功能测试用于验证系统的质量因素\n\n理解产品行为、设计体系和体系结构\n针对不同配置和资源对产品进行测试\n手机和分析响应数据\n评判产品质量\n\n\n非功能测试的最大挑战：设置配置\n原因\n\n难以预测用户的使用环境\n对配置进行组合测试的代价太高\n建立测试环境成本高\n很难准确预测客户使用的数据\n\n\n配置环境\n\n模拟环境\n真实客户环境\n\n\n可伸缩性测试/容量测试\n可靠性测试\n压力测试\n互操作性测试/兼容性测试\n可使用性与易获得性测试\n国际化测试\n性能测试\n安全性测试\n\n\n\n 确认测试\n\n概念*\n\n定义\n\n检查产品是满足在项目的需求阶段定义的确认规则，或者说是否具备在真实环境中使用的条件\n\n\n引入时机\n\n系统测试之后\n\n\n测试用例\n\n测试用例数量较少，目的不是为了发现缺陷\n\n\n测试环境\n\n近似实际场景下进行\n\n\n\n\n实施者\n\n客户或客户代表\n\n\n目的*\n\n验证和接受产品\n\n\n产品确认\n\n对现有测试用例进行分类形成确认准则\n\n\n规程确认\n\n根据交付规程进行定义\n\n\n确认准则\n\n服务约定等级\n\n\n执行\n\n开发组织\n\n辅助客户完成确认测试\n\n\n确认测试团队\n\n产品管理层+支持团队+咨询团队\n\n90%成员具有产品业务过程知识\n10%成员属于技术测试团队\n\n\n\n\n开发组织的测试团队应当与确认测试团队不断沟通，提供采集测试数据和分析测试结果的帮助\n\n\n\n 回归测试\n\n概念*\n\n回归测试是对之前已修改过、经过修改的程序进行的重新测试，以保证该修改没有引入新的错误或者由于更改而发现之前未发现的错误\n回归测试要保证增强型或改正型修改使软件正常进行并且不影响已有的功能\n\n\n意义\n\n保证软件维护时未更改的代码功能不会收到影响\n保证软件模块区域和持续维护过程与回归测试的协作关系，是回归测试成为一个每月/每周/每日的常规活动\n实现软件整个生命周期的测试\n\n\n引入时机\n\n单元测试\n集成测试\n系统测试\n引入原则\n\n开发过程中发生修改或维护，就有必要进行回归测试\n\n\n\n\n特点\n\n测试计划\n\n常规测试\n\n已有的带有测试用例的测试计划\n\n\n回归测试\n\n更改的规格说明书、修改过的程序和需要更新的旧测试计划\n\n\n\n\n测试范围\n\n常规测试\n\n整个程序\n\n\n回归测试\n\n被修改部分的正确性以及它与原有功能的整合\n\n\n\n\n时间分配\n\n常规测试\n\n测试时间实现有预算\n\n\n回归测试\n\n测试时间不包含在进度表中\n\n\n\n\n开发信息\n\n常规测试\n\n随时可获得开发信息\n\n\n回归测试\n\n只需保留开发信息保证回归测试正确\n\n\n\n\n完成时间\n\n常规测试\n\n所需时间长\n\n\n回归测试\n\n只需测试软件的一部分，测试时间短\n\n\n\n\n执行频率\n\n常规测试\n\n高频率的活动\n\n\n回归测试\n\n由系统被修改而触发的周期性活动、\n\n\n\n\n\n\n过程\n\n提出软件测试修改需求\n进行软件修改\n选择测试用例（选择正确的测试用例集）\n执行测试\n识别失败结果\n识别错误\n排除错误\n\n\n策略\n\n全部重新测试\n\n不用进行测试用例选择\n\n\n有选择地重新测试\n\n灵活、适用于测试用例较多的情形\n\n\n\n\n重新确认测试用例\n组测试*\n\n多模块集成工作差错\n\n\n波及效应\n\n保证软件修改后仍然保持一致性与完整性\n需求的波及效应\n设计的波及效应\n代码的波及效应\n测试用例的波及效应\n步骤\n\n开始\n实施初始修改\n识别收到潜在影响的区域\n需要进一步修改一保持一致性？\n\ny:\n\n决定如何修改\ngo to 1\n\n\nn:\n\ncontinue\n\n\n\n\n结束\n\n\n\n\n\n","plink":"hanyuulu.github.io/SoftwareTest/"},{"title":"Hackathon 华东 @2019 赛事主办回顾与反思","date":"2019-11-30T00:00:00.000Z","updated":"2021-03-12T08:22:58.574Z","content":" 引言\n2019年11月23、24日，Hackathon 华东 @ 2019 赛事在东大九龙湖校区顺利举行，作为主办方负责人，我在组织这场大型赛事的活动中有一点经验和反思，望可以作为自己日后举办类似赛事的经验也可以供读者们参考。\n 先决条件\n要顺利举办一场赛事，离不开资金和行政的支持；\n\n\n财政\n在前期规划过程中，hackathon拉的赞助时间一开始定在赛事前一个月，事实上作为赛事主办方去寻找赞助这个本身就是一种不可靠（指不能保证资金筹集）的行为，当我把策划书时间表提供给公司审阅时，公司负责人立即指出赞助安排过迟的问题，恰好当时时间也比较充裕，我们调整了拉赞助的时间。事实证明这个选择是对的。因为各种问题，我们没有拉到额外的赞助。最终我们的活动经费来源全部依靠了微软中国和微软亚洲研究院。\n\n\n行政\n由于赛事在东南大学九龙湖校区内举行，选手的比赛场地、入门许可和饭食等问题都要依托于校方的支持，所以提前一定时间向学校提出赛事和申请，由于学校机构较多，我们一开始为了寻找应该向哪个单位租借机房也耗费了很久的时间（等相关部门回复需要一定的时间，辗转了几次累计的时间会在半个月左右）。\n\n\n基于以上问题，我建议此类赛事的财政和行政准备一般不低于一个半月为佳，并制定周密的计划书和完成清单，这能帮助负责人理清各项事宜的细节和追踪进度。\n 准备工作\n\n\n邀请\n\n\n参赛选手邀请\n报名窗口期建议在15-20天为以宜，报名结束到赛事开始建议在半个月左右，所以请至少在赛事开始前一个半月准备报名站点搭建和报名文案，传媒渠道，选手（答疑）群等事项的准备\n建站建议\n\n\n赛事宣传页\n\n我们使用了Hexo静态网页、托管于GitHub（国内也可以试试腾讯云）。这样免去了服务器和运维方面的成本。markdown也可以轻松胜任简易编写、快速上线、功能丰富的需求，Hexo的自带丰富模板也足够方便美观。这个我为Hackathon赛事搭建的主页 https://hackathon2019eastchina.github.io/ \n\n\n\n报名信息采集\n\n静态网页本身并不支持表单提交功能，为此我们可以嵌入Microsoft form的iframe组件，（markdown支持一部分Html语法，可以直接嵌入iframe）（处于兼容性问题考虑，可以再给个指向Microsoft form的链接）\n\n这样，建站服务就完成啦\n\n\n\n\n评委和导师邀请\n​\t由于老师往往都有一定的排课和出差等安排，建议提前一个月邀请。\n\n\n\n\n物资准备\n\n建议列出采购清单并分派购买任务（注意提醒自己和经手人索要发票），提前一个月准备为宜（考虑到丢件的可能）\n预算不足的组织可以考虑协商后续通过发票报销\n\n\n\n\n","plink":"hanyuulu.github.io/reviewOfHackathon/"},{"title":"编译原理小结","date":"2019-10-07T00:00:00.000Z","updated":"2021-03-12T08:22:58.382Z","content":"[TOC]\n Chapter 1\n\nNone\n\n Chapter 2 Language &amp; Syntax Description\n Language &amp; syntax description\n\n\nAlphabet\n\nNon-empty set of symbols，usually expressed in $\\Sigma$、$V$ or Other Upper-case Greece Letter\n\n\nSymbol (Character)\n\nElements in alphabet, finest elements in a language\n\n\nString\n\nFinite sequence of symbols in the Alphabet.\n\nNotes: Null-string is string without any symbol, written as e。\n\n\n\n\nA = {α1\\alpha_1α1​,α2\\alpha_2α2​,…} B ={β1\\beta_1β1​,β2\\beta_2β2​}\nAB = {αβ∣α∈A and β∈B}\\{\\alpha\\beta|\\alpha\\in A\\ and\\ \\beta \\in B\\}{αβ∣α∈A and β∈B}\nA0={ε}A^0=\\{\\varepsilon\\}A0={ε}\n\n\nClosure\nA∗=A0∪A1∪A2...A^*=A^0\\cup A^1\\cup A^2...A∗=A0∪A1∪A2...\n\n\nPositive closure\nA+=A1∪A2∪A3...A^+=A^1\\cup A^2 \\cup A^3...A+=A1∪A2∪A3...\n\n\n\n\nSentence\n\n A set of strings based on symbols in the Alphabet in  certain construction rules\n\n\nLanguage\n\n Sets of sentences in the Alphabet.\n\n Notes: By convention, a symbol is expressed as a,b,c,…；a string is expressed as $\\alpha$,$\\beta$,$\\gamma$…；a set of strings is expressed in A,B,C….\n\n\n\nGrammar\n\nGrammar(G)\nNone-terminal symbol(VNV_NVN​)\nTerminal symbol(VTV_TVT​)\nStart symbol(S)\nProduction§\n\n→\nA→αA\\rightarrow \\alphaA→α\n\n\nDerivation(Leftmost &amp; Rightmost)\nReduction\nSentential form,  Sentence &amp; Language\nRecursive definition of grammar rules\nExtended notations of grammar rules\n\n\nFormal definition\n\nGrammar\n\nquadruple (VN,VT,P,SV_N,V_T,P,SVN​,VT​,P,S)\n\n\nCatalog of grammars\n\n0-type grammar (Phrase grammar or grammar without limitation)\n\nto any production α→β\\alpha\\rightarrow\\betaα→β in P (α∈V+,β∈V∗)(\\alpha\\in V^+,\\beta\\in V^*)(α∈V+,β∈V∗) ,there is at least  a non-terminal symbol in α\\alphaα\n\n\n1-type grammar (context-sensitive grammar or length-added grammar)\n\nto any production α→β\\alpha\\rightarrow\\betaα→β in P, there is the limitation of ∣β∣≥∣α∣|\\beta|\\ge|\\alpha|∣β∣≥∣α∣ **expect for S→εS\\rightarrow\\varepsilonS→ε,if S→εS\\rightarrow\\varepsilonS→ε, S can not appear in the right side for any production.\nfor any production α→β\\alpha\\rightarrow\\betaα→β in P, αAβ→αγβ (α,β∈V∗)\\alpha A\\beta\\rightarrow\\alpha\\gamma\\beta\\ (\\alpha,\\beta\\in V^*)αAβ→αγβ (α,β∈V∗) expect for S→εS\\rightarrow\\varepsilonS→ε\n\n\n2-type grammar (context-free grammar)\n\nEvery production in P is of the form A→βA\\rightarrow\\betaA→β where A∈VN,β∈V∗A\\in V_N,\\beta\\in V^*A∈VN​,β∈V∗\n\n\n3-type grammar (Regular grammar, right-linear grammar or left-linear grammar)\n\nEvery production in P is of the form A→αB,A→αA\\rightarrow\\alpha B,A\\rightarrow\\alphaA→αB,A→α, or A→BαA\\rightarrow B\\alphaA→Bα,A→αA\\rightarrow\\alphaA→α,where AAA,B∈VN,α∈VT∗B\\in V_N,\\alpha\\in V_T^*B∈VN​,α∈VT∗​\n\n\n\n\n\n\nGrammar Simplification\n\ndelete productions like P→PP\\rightarrow PP→P\ndelete productions who can not be used in the derivations\ndelete productions who can not derive a terminal string\n\n\nConstruct context-free grammar without ε-production\n\nit should follow conditions as followings\n\nIf there is the production S→ε of the form in P, S should not appear in right-side of any production, where S is the start symbol of the grammar;\nThere are no other ε-productions in P\n\n\nHow to construct\n\nG=(VN,VT,P,S)→G′=(VN′,VT′,P′,S′)G=(V_N,V_T,P,S)\\rightarrow G&#x27;=(V&#x27;_N,V&#x27;_T,P&#x27;,S&#x27;)G=(VN​,VT​,P,S)→G′=(VN′​,VT′​,P′,S′)\nfind out all non-terminal symbols that can derive ε after some steps, and put them into the set V0V_0V0​\nconstruct the P’s set of productions of G’ as following steps:\n\n\nIf an symbol in V0V_0V0​ appears in the right side of a production, change the production into two production respectively; put the new productions into P\nput the productions relating to the symbol into P’ except for ε-production relating to the symbol\nif there exists the production of the form S→εS\\rightarrow \\varepsilonS→ε in P,change the production into S’→ε∣SS’\\rightarrow \\varepsilon |SS’→ε∣S and put them into  P’P’P’,let S’S’S’ be the start symbol of G’G’G’, let V’N=VN∪{S′}V’_N=V_N\\cup \\{S&#x27;\\}V’N​=VN​∪{S′}\n\n\n\n\nSyntax tree and ambiguity of a grammar\n\nBasic terms in a syntax tree\n\nSub-tree\nPruning sub-tree\nSentential form\n\n\n\n\n\n Chapter 3 Lexical analysis\n Approaches to implement a lexical analyzer\n\n\nSimple approach\n\n\nConstruct a diagram that illustrates the structure of the tokens of the source language , and then to hand-translate the diagram into a program for finding tokens\n\nEfficient lexical analyzers can be produced in this manner\n\n\n\n\n\nPattern-directed programming approach\n\n\nPattern Matching technique\n\n\nSpecify and design program that execute actions triggered by patterns in strings\n\n\nIntroduce a pattern-action language called Lex for specifying lexical analyzers\n\nPatterns are specified by regular expressions\n\n\n\n\n\n\nA compiler for Lex can generate an efficient finite automation recognizer for the regular expressions\n\n The role of the lexical analyzer\n\n\nFirst phase of a compiler\n\n\nMain task\n\nTo read the input characters\nTo produce a sequence of tokens used by the parser for syntax analysis\nAs an assistant of parser\n\n\n\nInteraction of lexical analyzer with parser\n\n\n\n\n\n\n\n、Processes in lexical analyzers\n*　Scanning\n*　Pre-processing\n* Strip out comments and white space\n* Macro functions\n*　Correlating error messages from compiler with source program\n*　A line number can be associated with an error message\n*　Lexical analysis\n\n\nTerms of the lexical analyzer\n\nToken\n\nTypes of words in source program\nKeywords, operators, identifiers, constants, literal strings, punctuation symbols(such as commas,semicolons)\n\n\nLexeme\n\nActual words in source program\n\n\nPattern\n\nA rule describing the set of lexemes that can represent a particular token in source program\nRelation {&lt;.&lt;=,&gt;,&gt;=,==,&lt;&gt;}\n\n\n\n\n\nAttributes for Token\n\nA pointer to the symbol-table entry in which the information about the token is kept\n\n\nE.g E=M*C**2\n\n&lt;id, pointer to symbol-table entry for E&gt;\n&lt;assign_op,&gt;\n&lt;id, pointer to symbol-table entry for M&gt;\n&lt;multi_op,&gt;\n&lt;id, pointer to symbol-table entry for C&gt;\n&lt;exp_op,&gt;\n&lt;num,integer value 2&gt;\n\n\nLexical Errors\n\nDeleting an extraneous character\nInserting a missing character\nReplacing an incorrect character by a correct character\nTransposing two adjacent characters(such as , fi=&gt;if)\nPre-scanning\n\n\n\nInput Buffering\n\nTwo-buffer input scheme to look ahead on the input and identify tokens\nBuffer pairs\nSentinels(Guards)\n\n\n\n Specification of tokens\n\nRegular definition of tokens\n\nregular expression (RE)\n\n\nregular languageL(r)\nrule of regular expression over alphabet Σ\\SigmaΣ\n\nε→{ε}\\varepsilon \\rightarrow \\{\\varepsilon \\}ε→{ε}\nα∣β\\alpha|\\betaα∣β\nαβ\\alpha \\betaαβ\nα∗\\alpha*α∗\nα+\\alpha+α+\nα?\\alpha ?α?\n[a−z][a-z][a−z]\n\n\n\n Recognition of tokens\n\n\ntask of recognition of token in a lexical analyzer\n\n\nIsolate the lexeme for the next token in the input buffer\n\n\nproduce output pair like &lt;id,pointer to table entry&gt;\n\nA example translation table\n\n\n\nRE\nToken\nAttribute-value\n\n\n\n\nif\nif\n-\n\n\nid\nid\nPointer to table entry\n\n\n&lt;\nrelop\nLT\n\n\n\n\n\n\nmethod to recognition of token\n\n\n\n\nTransition diagram(Stylized flowchart)\n\n\neach state gets a segment of code\nuse nextchar() to read a character and move to next state\n\n\n\n\n\nFA ( Finite Automation )\n\n\nDeterministic or non-deterministic FA\n\nＮFA contains more than one transition out of a state may possible on the same input symbol while DFA not.\n\n\n\nDFA\n\n\nquintuple M(S,Σ,move,s0,F)M(S,\\Sigma,move,s_0,F)M(S,Σ,move,s0​,F)\n\n\nSSS: a set of states\n\n\nΣ\\SigmaΣ: the input symbol alphabet\n\n\nmovemovemove: a transition function, mapping from S×ΣS\\times \\SigmaS×Σ to SSS, move(s,a)=S’move(s,a)=S’move(s,a)=S’\n\n\ns0s_0s0​: the start state\n\n\nFFF: a set of states FFF distinguished as accepting states\n\nF⊆S,s0∈SF\\subseteq S,s_0 \\in SF⊆S,s0​∈S\n\n\n\n\n\nnote\n\nno state has an ε\\varepsilonε\nfor each state s and input symbol a, there is at most one edge labeled a leaving s\ntransition graph are used to describe a FA\nA DFA accepts an input string x if and only if there is some path in the transition graph from start state to some accepting state\n\n\n\n\n\nNFA\n\n\nquintuple M(S,Σ,move,s0,F)M(S,\\Sigma,move,s_0,F)M(S,Σ,move,s0​,F)\n\n\nSSS: a set of states\n\n\nΣ\\SigmaΣ: the input symbol alphabet\n\n\nmovemovemove: a transition function, mapping from S×ΣS\\times \\SigmaS×Σ to SSS, move(s,a)=2Smove(s,a)=2^Smove(s,a)=2S\n\n\ns0s_0s0​: the start state\n\n\nFFF: a set of states FFF distinguished as accepting states\n\n2S⊆S,F⊆S,s0∈S2^S\\subseteq S, F\\subseteq S,s_0 \\in S2S⊆S,F⊆S,s0​∈S\n\n\n\n\n\nnote\n\nϵ\\epsilonϵ is a legal input symbol\n\n\n\n\n\nConvert of an NFA to a DFA\n\navoid ambiguity\n\n\n\nObtain ε-closure(T)\n\n\npush all states in T onto stack\n\n\ninitialize ε-closure(T) to T;\n\nwhile stack is not empty do{\n​\tpop the top element of the stack into t;\n​\tfor each state u with an edge from t to u labeled ε do{\n​\t\tif u is not in ε-closure(T){\n​\t\t\tadd u to ε-closure(T)\n​\t\t\tpush u into stack\n​\t\t}\n​\t}\n}\n\n\n\nInput\n\n\nNFA $N = (S,\\Sigma,move,S_0,Z)$\n\n\n\nOutput\n\n\nDFA $D = (Q,\\Sigma,\\delta,I_0,F)$\n\n\n\n\n\nSubset construciton\n\n\n\nI0=ϵ−clousure(S0),I0∈QI_0 = \\epsilon-clousure(S_0),I_0\\in QI0​=ϵ−clousure(S0​),I0​∈Q\n\n\nforeach\\ I_i,I_i \\in Q \\\n\\ let I_t = \\epsilon-clousure(move(I_i,a) \\\n\\ if\\ I_t\\notin Q\\ then\\ put\\ I_t\\ into Q\n\n\n\nrepeat step2 until there is no new state to put into QQQ\n\n\nletF={I∣I∈Q,I∩Z&lt;&gt;Φ}let F = \\{I|I\\in Q,I \\cap Z&lt;&gt;\\Phi\\}letF={I∣I∈Q,I∩Z&lt;&gt;Φ}\n\n\n\n\n\n\nminimizing the number of states of a DNA\n\n\nInput\n\nDFA M={S,Σ,move,s0,F}M = \\{S,\\Sigma,move,s_0,F\\}M={S,Σ,move,s0​,F}\n\n\n\nOutput\n\nDFA M′M&#x27;M′ accepting the same language as M and having as few states as possible\n\n\n\nAlgorithm\n\nConstruct an initial partition ∏ of the set of states with two groups: the accepting states F and the non-accepting states S-F. ∏0＝{I01,I02}\nFor each group I of ∏**i ,partition I into subgroups such that two states s and t of I are in the same subgroup if and only if for all input symbols a, states s and t have transitions on a to states in the same group of ∏**i ; replace I in *∏**i+1_*by the set of subgroups formed.\nIf ∏**i+1 =∏**i ,let ∏**final =∏**i+1 and continue with step (4). Otherwise,repeat step (2) with ∏**i+1\nChoose one state in each group of the partition ∏**final as the representative for that group. The representatives will be the states of the reduced DFA M’. Let s and t be representative states for s’s and t’s group respectively, and suppose on input a there is a transition of M from s to t. Then M’ has a transition from s to t on a.\nIf M’ has a dead state(a state that is not accepting and that has transitions to itself on all input symbols),then remove it. Also remove any states not reachable from the start state.\n\n\n\n\n\n\n\n\n\nRE to NFA\n\nMethod\n\nParse r into its constituent sub-expressions\nε\n\n\n\n\na∈Σa\\in \\Sigmaa∈Σ\n\n\n\n\n\n\n\n\n\n\nFA to RE\n\n\nRegular Grammar to NFA (Right linear grammar to FA)\n\n\nInput G=(VN,VT,P,S)G = (V_N,V_T,P,S)G=(VN​,VT​,P,S)\n\n\nOutput FA M=(Q,Σ,move,q0,Z)M = (Q,\\Sigma,move,q_0,Z)M=(Q,Σ,move,q0​,Z)\n\n\nMethod\n\nConsider each non-terminal symbol in G as a state, and add a new state T as an accepting state.\nLet Q=VN∪{T},S＝VT,q0＝SQ=V_N\\cup\\{T\\} , S ＝ V_T , q_0 ＝SQ=VN​∪{T},S＝VT​,q0​＝S; if there is the production S→εS\\rightarrow \\varepsilonS→ε, then Z={S,T},elseZ={T}Z=\\{S,T\\}, else Z=\\{T\\}Z={S,T},elseZ={T}\nFor the productions similar as A1 → aA2，construct move(A1,a)= A2\nFor the productions similar as A1 → a, construct move(A1,a)= T\nFor each a in Σ, move(T,a)=ψ, that means the accepting states do not recognize any terminal symbol.\n\n\n\n\n\n\n\nFA to Right-linear grammar\n\nInput M=(S,Σ,f,s0,Z)M=(S,\\Sigma,f,s_0,Z)M=(S,Σ,f,s0​,Z)\nOutput Rg=(VN,VT,P,s0)R_g = (V_N,V_T,P,s_0)Rg​=(VN​,VT​,P,s0​)\nMethod\n\nif s0∉Zs_0\\notin Zs0​∈/​Z\n\nFor the mapping f(Ai,a)=Ajf(A_i,a)=A_jf(Ai​,a)=Aj​ in M Ai→aAjA_i\\rightarrow aA_jAi​→aAj​\n\n\nif s0∈Zs_0\\in Zs0​∈Z\n\nadd a new production Ai→aA_i\\rightarrow aAi​→a,Ai=→a∣aAjA_i=\\rightarrow a|aA_jAi​=→a∣aAj​\n\n\n\n\n\n\n\n\n\n design of a lexical analyzer generator\n\n\n\nLex specification\n\ndeclaration\ntranslation rules\nauxiliary procedures\n\n\n\nDeclaration\n12345678910%&#123;   /*definitions of manifest constants LT,LE,EQ,GT,GE,IF,THEN,ELSE,ID*/  %&#125;/*regular expression*/  delim [\\t\\n]ws   &#123;delim&#125;+  letter  [A-Za-z]digit  [0-9]    id    &#123;letter&#125;(&#123;letter&#125;|&#123;digit&#125;)*\n\n\nmodel\n\n\n\n Chapter 4 Syntax analysis\n approaches to implement a syntax analyzer\n roles of the parser\n\n\nmain task\n\nObtain a string of tokens from the lexical analyzer\nVerify that the string can be generated by the grammar of related programming language\nReport any syntax errors in an intelligible fashion\nRecover from commonly occurring errors so that it can continue processing the remainder of its input\n\n\n\nposition\n\n\n\nmethods\n\nuniversal parsing method\ntop-down method\n\nBuild parse trees from the top(root) to the bottom(leaves)\nThe input is scanned from left to right\nLL(1) grammars (often implemented by hand)\n\n\nbottom-up method\n\nStart from the leaves and work up to the root\nThe input is scanned from left to right\nLR grammars(often constructed by automated tools)\n\n\n\n\n\nSyntax error handling\n\nerror levels\nsimple-to-state goals of the error handler\nerror-recovery strategies\n\npanic mode\nphrase level\n\n\nerror-recovery strategies\n\n\n\n top-down parsing\n\n\nideas\n\nFind a leftmost derivation for an input string\nConstruct a parse tree for the input starting from the root and creating the nodes of the parse tree in preorder\n\n\n\nmain methods\n\nPredictive parsing (no backtracking)*\nRecursive descent (involve backtracking)\n\n\n\nleft recursion\n\n\nImmediate recursion P→Pα∣βP\\rightarrow P\\alpha|\\betaP→Pα∣β\n\n\nIndirect recursion P→Aa,A→PbP\\rightarrow Aa,A\\rightarrow PbP→Aa,A→Pb\n\n\nsolve\n\nconvert left recursion to right recursion\n\n\n\nP\\rightarrow P\\alpha|\\beta \\\nP\\rightarrow \\beta\\alpha* \\\nP\\rightarrow \\beta P&#039;\\\nP&#039;\\rightarrow \\alpha P&#039;|\\varepsilon\n\n\n\n\neliminating ambiguity of a grammar\n\nrewriting the grammar\n\nstmt→if expr then stmt|if expr then stmt else stmt|other\nstmt→matched-stmt|unmatched-stmt\nmatched-stmt→if expr then matched-stmt else matched-stmt|other\nunmatched-stmt→if expr then stmt|if expr then matched-stmt else unmatched-stmt\n\n\n\n\n\nLeft factoring\n\nrewrite the production to defer the decision until we have seen enough of the input to make right choice\nA→δβ1∣δβ2∣δ⋅⋅⋅βnA\\rightarrow \\delta \\beta_1|\\delta \\beta_2|\\delta \\cdot\\cdot\\cdot \\beta_nA→δβ1​∣δβ2​∣δ⋅⋅⋅βn​\nA→δA′,A′→β1∣beta2∣⋅⋅⋅∣βnA\\rightarrow \\delta A&#x27;,A&#x27;\\rightarrow \\beta_1|beta_2|\\cdot\\cdot\\cdot|\\beta_nA→δA′,A′→β1​∣beta2​∣⋅⋅⋅∣βn​\n\n\n\npredictive parsers methods\n\nTransition diagram based predictive parser\nNon-recursive predictive parser\n\n\n\ntransition diagram based predictive parsers\n\ntransition diagram\n\ncreate an initial and final state\nfor each production A→X1X2...XnA\\rightarrow X_1X_2...X_nA→X1​X2​...Xn​,create a path from initial to the final state,with edge labeled X1,X2,...,XnX_1,X_2,...,X_nX1​,X2​,...,Xn​\n\n\n\n\n\nnon-recursive predictive parsing\n\n\nthe determining the production to be applied for a non-terminal\n\n\ntable-driven and use stack\n\n\n\npredictive parsing program\n\nX: the symbol on top of the stack\na: the current input symbol\nIf X=a=$, the parser halts and announces successful completion of parsing\nIf X=a!=$, the parser pops X off the stack and advances the input pointer to the next input symbol\nIf X is a non-terminal, the program consults entry M[X,a] of the parsing table M. This entry will be either an X-production of the grammar or an error entry.\n\n\n\nFirst\n\n\nIf a is any string of grammar symbols, let FIRST(a) be the set of terminals that begin the string derived from a\n\n\nIf a→e, then e is also in FIRST(a)\n\n\nα∈V∗,First(α)={a∣α→a....,a∈VT}\\alpha\\in V^*,First(\\alpha) = \\{a|\\alpha \\rightarrow a....,a\\in V_T\\}α∈V∗,First(α)={a∣α→a....,a∈VT​}\n\n\nCompute\n\n\nIf x is terminal,then First(x)={x}\n\n\nIf x→ε, add ε to First(x)\n\n\nIf x in non-terminal, and X→Y1Y2…Yk,Yj∈(VN∪VT),1≤j≤k,then\n123456789&#123;     j=1; FIRST(X)=&#123;&#125;; //initiate        while ( j&lt;k and ε∈ FIRST(Yj)) &#123;            FIRST(X)=FIRST(X)∪(FIRST(Yj)-&#123;ε&#125;)           j=j+1       &#125;       IF (j=k and ε∈ FIRST(Yk))            FIRST(X)=FIRST(X) ∪ &#123;ε&#125;   &#125;\n\n\n\n\n\n\nFollow\n\nFor non-terminal A, to be the set of terminals a that can appear immediately to the right of A in some sentential form.\nFollow(A)={a∣S→...Aa...,a∈VT}Follow(A) = \\{a|S\\rightarrow ...Aa...,a\\in V_T\\}Follow(A)={a∣S→...Aa...,a∈VT​}\nIf S→...A,then $∈Follow(A)S\\rightarrow ...A,then\\ \\$\\in Follow(A)S→...A,then $∈Follow(A)\nCompute\n\nPlace $ in FOLLOW(S), where S is the start symbol and ​$ is the input right end-marker\nIf there is A→aBb in G, then add (First(b)-ε) to Follow(B)\nIf there is A→aB, or A→aBb where FIRST(b) contains ε，then add Follow(A) to Follow(B).\n\n\n\n\n\nPPT ( Predictive Parsing Tables )\n\nInput Grammar G\nOutput Parsing table M\nmethod\n\nFor each production A→a , do steps 2 and 3\nFor each terminal a in FIRST(a), add A→a to M[A,a]\nIf ε is in FIRST(a), add A→a to M[A,b] for each terminal b in FOLLOW(A). If e is in FIRST(a) and $ is in FOLLOW(A), add A→a to M[A,$]Make each undefined entry of M be error.\nMake each undefined entry of M be error.\n\n\n\n\n\n\n\n\n\n\nLL(1) Grammars\n\n\nDefinition\n\n\nA grammar whose parsing table has no multiply-defined entries is said to be LL(1)\n\n\nThe first “L” stands for scanning the input from left to right\n\n\nThe second “L” stands for producing a leftmost derivation\n\n\n“1” means using one input symbol of look-ahead\n\ns.t each step to make parsing action decisions.\n\n\n\nNote\n\nNo ambiguous can be LL(1)\nLeft-recursive grammar cannot be LL(1)\nA grammar G is LL(1) if and only if whenever A→a | b are two distinct productions of G\n\n\n\n\n\ntransform a grammar to LL(1) grammar\n\nEliminating all left recursion\nLeft factoring\n\n\n\n\n\n bottom-up parsing\n\n\nShift-reduce parsing\n\n\nhandles\n\n\nhandle pruning\n\n\n\nDefinition of operator grammar\n\nThe grammar has the property that no production right side is e or has two adjacent non-terminals\n\n\n\n\n\nLR parsing\n\n\nAn efficient, bottom-up syntax analysis technique that can be used to parse a large class of context-free grammars\n\n\nLR(K)\n\nL: left-to-right scan\nR:construct a rightmost derivation in reverse\nk:the number of input symbols of look ahead\n\n\n\nadvantages\n\nIt can recognize virtually all programming language constructs for which context-free grammars can be written\nIt is the most general non backtracking shift-reduce parsing method\nIt can parse more grammars than predictive parsers can\nIt can detect a syntactic error as soon as it is possible to do so on a left-to-right scan of the input\n\n\n\nSLR\n\nSimple LR\n\n\n\nLR(1)\n\ncanonical LR\n\n\n\nLRLR\n\n\nlook ahead LR\n\n\n\n\n\nnote\n\nThe driver program is the same for all LR parsers; only the parsing table changes from one parser to another\nThe parsing program reads characters from an input buffer one at a time\nSi is a state, each state symbol summarizes the information contained in the stack below it\nEach state symbol summarizes the information contained in the stack\nThe current input symbol are used to index the parsing table and determine the shift-reduce parsing decision\nIn an implementation, the grammar symbols need not appear on the stack\n\n\n\nParsing table\n\nAction\n\nAction[S,a]: S represent the state currently on top of the stack, and a represent the current input symbol. So Action[S,a] means the parsing action for S and a\nShift\n\nThe next input symbol is shifted onto the top of the stack\nShift S, where S is a state\n\n\nReduce\n\nThe parser knows the right end of the handle is at the top of the stack, locates the left end of the handle within the stack and decides what non-terminal to replace the handle. Reduce by a grammar production A→a\n\n\nAccept\n\nThe parser announces successful completion of parsing\n\n\nError\n\nThe parser discovers that a syntax error has occurred and calls an error recovery routine.\n\n\n\n\nAction conflict\n\nShift/reduce conflict\n\nCannot decide whether to shift or to reduce\n\n\nReduce/reduce conflict\n\nCannot decide which of several reductions to make\n\n\n\n\nGoto\n\na goto function that takes a state and grammar symbol as arguments and produces a state\n\n\n\n\n\nAlgorithm\n\nThe next move of the parser is determined by reading the current input symbol a, and the state S on top of the stack,and then consulting the parsing action table entry action[S,a].\nIf action[Sm,ai]=shift S,the parser executes a shift move ,enter the S into the stack,and the next input symbol ai+1 become the current symbol.\nIf action[Sm,ai]=reduce A→a, then the parser executes a reduce move. If the length of a is g, then delete g states from the stack, so that the state at the top of the stack is Sm- g . Push the state S’=GOTO[Sm- g,A] and non-terminal A into the stack. The input symbol does not change.\nIf action[Sm*,ai]*=accept, parsing is completed.\nIf action[Sm*,ai]*=error, the parser has discovered an error and calls an error recovery routine.\n\n\n\nSj   means shift and stack state j, and the top of the stack change into（j,a）\n\n\nrj   means reduce by production numbered j\n\n\nAccept  means accept\n\n\nblank    means error\n\n\n\n\n\n\n\n\nCanonical LR(0)\n\n\nAn LR(0) item of a grammar G is a production of G with a dot at some position of the right side\n\n\n•Such as: A → XYZ yields the four items:\n–A→•XYZ . We hope to see a string derivable from XYZ next on the input.\n–A→X•YZ . We have just seen on the input a string derivable from X and that we hope next to see a string derivable from YZ next on the input.\n–A→XY•Z\n–A→X YZ•\n\n\n•The production A®e generates only one item, A®•.\n\n\n•Each of this item is a viable prefixes\n\n\n\n\nConstruct LR(0) collection\n\n\nDefine a augmented grammar\n\n\nIf G is a grammar with start symbol S,the augmented grammar G’ is G with a new start symbol S’, and production S’ ®S\n•The purpose of the augmented grammar is to indicate to the parser when it should stop parsing and announce acceptance of the input\n\n\n\n\nthe Closure Operation\n\n•If I is a set of items for a grammar G, then closure(I) is the set of items constructed from I by the two rules:\n\n\n\nthe Goto Operation\n\n•Form: goto(I,X),I is a set of items and X is a grammar symbol\n\n\n\n\n\nThe Sets-of-Items Construction\n12345678void ITEMSETS-LR0()&#123;    C:=&#123;CLOSURE(S` →•S)&#125;      /*initial*/      do   &#123;  for (each set of items I in C and each grammar symbol X )        IF  (Goto(I,X) is not empty and not in C)            &#123;add Goto(I,X) to C&#125;   &#125;while  C is still extending&#125;\n\n\n\n\n\n\n\nSLR(1) Parsing Table Algorithm\n\nInput. An augmented grammar G\nOutput. The SLR parsing table functions action and goto for G`\nMethod.\n\nConstruct C={I0,I1,…In}, the collection of sets of LR(0) items for G`.\nState i is constructed from Ii. The parsing actions for state i are determined as follows:\n\nIf [A®a•ab] is in Ii and goto(Ii,a)= Ij, then set ACTION[i,a]=“Shift j”, here a must be a terminal.\nIf [A®a• ]ÎIk, then set ACTION[k,a]=rj for all a in follow(A); here A may not be S`, and j is the No. of production A®a .\n\n\nThe goto transitions for state I are constructed for all non terminals A using the rule: if goto (Ii,A)= Ij, then goto[i,A]=j\nAll entries not defined by rules 2 and 3 are made “error”\nThe initial state of the parser is the one constructed from the set of items containing [S` ® S•].\nIf any conflicting actions are generated by the above rules, we say the grammar is not SLR(1).\n\n\n\nEvery SLR(1) grammar is unambiguous, but there are many unambiguous grammars that are not SLR(1).\n\n\n\n\n\nConstruction of the sets of LR(1) items\n\n\nInput. An augmented grammar G\n\n\nOutput. The sets of LR(1) items that are the set of items valid for one or more viable prefixes of G`\n\n\nMethod. The procedures closure and goto and the main routine items for constructing the sets of items.\n123456789101112131415161718192021function closure(I);&#123; do &#123; for (each item (A→α•Bβ,a) in I,                 each production B → γ in G`,                 and each terminal b in FIRST(βa)                 such that (B→• γ ,b) is not in I  )            add (B→• γ ,b) to I;         &#125;while there is still new items add to I;    return I&#125;function  goto(I,X);&#123; let J be the set of items (A→αX•β,a) such that (A→α• X β,a) is in I ;    return closure(J)&#125;Void items (G`);&#123;C=&#123;closure(&#123; (S`→•S,$)&#125;)&#125;;  do &#123; for (each set of items I in C and each grammar symbol X          such that              goto(I,X) is not empty and not in C )           add goto(I,X) to C        &#125; while there is still new items add to C;  &#125;\n//TODO page 155.\n\n\n\n\n LR parsers\n🚧under construction🚧\n12","plink":"hanyuulu.github.io/CompilationPrinciple/"},{"title":"Jupyter和conda协同工作环境搭建和常见错误处理","date":"2019-10-03T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" 避坑安装方法\n\n如果您还没有安装jupyter notebook，那么按照如下方法可以让jupyter和conda协同工作\n\n123456# 在base环境下# 安装jupyter本体pip install jupyter# 安装nb_jupyterpip install nb_conda# 完成\n\n好啦，开始使用就完事辣~\n\n 关于其他方法安装导致故障的原因和修复\n 方法a\n\n\n安装ipykernel：\n1conda install ipykernel\n\n\n在虚拟环境下创建kernel文件：\n1conda install -n [环境名] ipykernel\n\n\n激活conda环境：\n1source activate [环境名]\n\n\n将环境写入notebook的kernel中\n  1python -m ipykernel install --user --name[环境名] --display-name &quot;[显示名])&quot;\n\n\n Fix\n环境配置列表在%userprofile%\\Appdata\\Roaming\\jupyter\\kernels\\[环境名]\\kernel.json下，手动修正即可\n 调试思路\nconda的工作就是更换环境变量，可以使用sys.path查看conda是否正常工作\n","plink":"hanyuulu.github.io/jupyter/"},{"title":"共享Jupyter notebook环境","date":"2019-10-02T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":"\n\n生成配置文件\n 1jupyter notebook --generate-config\n\n\n生成密码\n12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password: Verify password: Out[2]: &apos;sha1:***************************************************&apos;\n\n\n修改config文件\n1/[user]/.jupyter/jupyter_notebook_config.py\n1234c.NotebookApp.ip=&apos;*&apos;\t# allow all networkc.NotebookApp.password = u&apos;sha:******************&apos;c.NotebookApp.open_browser = Falsec.NotebookApp.port =8888 #port to share\n\n\n启动\n1jupyter notebook\n\n\n","plink":"hanyuulu.github.io/jupyterShare/"},{"title":"非标准数据简单网格化的一种方法","date":"2019-07-22T00:00:00.000Z","updated":"2021-03-12T08:22:58.570Z","content":" 场景概述\n有些时候为了让坐标数据可视化，当我们有需要绘制等高线图之类的场景时，我们需要根据现有的分布不规则的数据点映射到网格点上，比如我们有如下坐标点，每个坐标点都有自己的价格属性，我们需要画一张价格位于地理位置的分布图。此处的不同颜色点是因为做了k-means聚类分析，与本话题无关暂且不表，之前有讨论如何做简单的k-means聚类分析。根据聚类的价格分布，我们最终得到一张地形图如下，具体操作方法见下文。\n\n 一般方法\n此处使用的方法借鉴了地理方向GIS系统绘制等高线地形图的一种较为简单的实现的方案。在若干坐标点中，必定能找到包裹每个网格点的最小三角形（mesh）是待赋值的网格点，pointA，B，C是既有不规则坐标点。对坐标点mesh的高度（价格）赋值我们可以从A，B，C三点中赋值，此处为了简化计算，我的赋值策略是按mesh点到各个point的距离倒数的加权赋值\nHeightmesh=ρA×HeightA+ρB×HeightB+ρC×HeightCHeight_{mesh} = \\rho_A\\times Height_A+ \\rho_B\\times Height_B+ \\rho_C\\times Height_C\nHeightmesh​=ρA​×HeightA​+ρB​×HeightB​+ρC​×HeightC​\nρA=1distance(mesh,A)×K\\rho_A = \\frac{1}{distance(mesh,A)\\times K}\nρA​=distance(mesh,A)×K1​\nρB,ρC\\rho_B,\\rho_CρB​,ρC​同理\nK=1distance(mesh,A)+1distance(mesh,B)+1distance(mesh,C)K=\\frac{1}{distance(mesh,A)}+\\frac{1}{distance(mesh,B)}+\\frac{1}{distance(mesh,C)}\nK=distance(mesh,A)1​+distance(mesh,B)1​+distance(mesh,C)1​\n 具体实现\n相关实现如下，（非相关其他文件未给出）\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# countour.py# 等高线绘制from core import constimport osimport reimport sysfrom json import loadsimport matplotlib.pyplot as pltimport numpy as npsys.path.append('.\\\\')def pri(x, y, points: dict):    '''    - x,y is the position of the mesh point    - points is a list of the nearest three data points    '''    minList = list()    for i in points:        if i is not None:            dis = (i['E'] - x) ** 2 + (i['N'] - y) ** 2            if len(minList) &lt; 3:                minList.append([dis, i])                continue            if dis &lt; max([x[0] for x in minList]):                minList.sort(key=lambda x: x[0])                del (minList[-1])                minList.append([dis, i])    pri = 0    for i in minList:        pri += i[1]['price'] / i[0] / sum([1 / x[0] for x in minList])    return pridef draw(points: dict):    delta = 0.02    x = np.arange(        const.LONGITUDE_LOWER,        const.LONGITUDE_UPPER,        delta    )    y = np.arange(        const.LATITUDE_LOWER,        const.LATITUDE_UPPER,        delta    )    X, Y = np.meshgrid(x, y)    row = list()    for j in y:        line = list()        for i in x:            line.append(pri(i, j, points))        row.append(line)    Z = np.array(row)    fig, ax = plt.subplots()    CS = ax.contour(X, Y, Z, 20)    ax.clabel(CS, inline=True)    ax.contourf(X, Y, Z, 100, cmap=plt.cm.jet)    ax.set_title('contour for %d centers' % len(points))    fileName = os.path.join(        const.OUTPUT_PATH, 'P01contour%d.jpg' % len(points))    plt.savefig(fileName)if __name__ == '__main__':    for folder, subFolder, fileNameList in os.walk(const.OUTPUT_PATH):        if folder == const.OUTPUT_PATH:            for fileName in fileNameList:                # 匹配坐标文件                if re.match('^P01point\\d+\\.json$', fileName):                    f = os.path.join(folder, fileName)                    print(f)                    with open(f, 'r') as w:                        f = w.read()                    rawData = loads(f)                    for key, item in enumerate(rawData):                        if item is not None:                            rawData[key] = &#123;                                'price': sum([x['no'] for x in item]) /                                len([x['no']for x in item]),                                'E': item[0]['E'],                                'N': item[0]['N']                            &#125;                    draw(rawData)\n","plink":"hanyuulu.github.io/positionMesher/"},{"title":"提升Powershell使用体验","date":"2019-07-17T00:00:00.000Z","updated":"2021-03-12T08:22:58.614Z","content":" 终端（Terminal）推荐\n Windows Terminal\nGitHub地址：https://github.com/microsoft/terminal\n\n主题推荐 GitHub地址：https://github.com/mbadolato/iTerm2-Color-Schemes/tree/master/windowsterminal\n笔者自己配的主题：https://github.com/HanyuuLu/toolbox/tree/master/poshTheme\n\n Fluent Terminal\nGitHub地址：https://github.com/felixse/FluentTerminal\n Cmder\nGitHub地址：https://github.com/cmderdev/cmder\n PowerShell 美化\n oh-my-posh\n 安装\n\n若您从未更改过powershell的执行权限（或者不知道此物为何物），则需要更改powershell的执行权限以运行脚本\n需要管理员权限\n\n1Set-ExecutionPolicy Bypass\n\n安装posh-git\n\n1Install-Module posh-git -Scope CurrentUser\n\n安装oh-my-posh本体\n\n1Install-Module oh-my-posh -Scope CurrentUser\n 启用\n 手动启动\n12Import-Module oh-my-posh    # 导入模块Set-Theme Paradox   # 使用Paradox主题\n 伴随powershell自启\n如果profile指向的文件存在，则powershell启动时会顺带启动profile指向的文件存在，则powershell启动时会顺带启动profile指向的文件存在，则powershell启动时会顺带启动profile指向的脚本，所以我们将上述语句写入该文件中\n123New-Item $PROFILE -Type File    # 创建文件，若提示文件已存在则可以直接编辑文件\"Import-Module oh-my-posh    # 导入模块\" &gt;&gt; $PROFILE\"Set-Theme Paradox   # 使用Paradox主题\" &gt;&gt; $PROFILE\n 字体更换\n 更纱黑体\n常规字体是没有办法完全显示oh-my-posh的powerline字符的，因此我们需要一种好看的powerline字符\n\n笔者在此安利Sarasa Gothic / 更纱黑体 / 更紗黑體 / 更紗ゴシック\n微软应用商店下载\nGithub Release下载\n\n 字体更换简介\n建议在以下位置更换使用 Sarasa Term SC 字体（Term为终端字体，SC为简体中文，其他简写请参考应用商店或github readme说明）\n\ncmd\npowershell\nFluent Terminal\nWindows Terminal\nvsCode （编辑器和内置终端）\nVisual Studio\n其他可能使用到终端或者编辑代码的位置\n\n","plink":"hanyuulu.github.io/windows/oh-my-posh/"},{"title":"简单的k-means实践","date":"2019-07-15T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":"\n本文来自于笔者在肝数模过程中的亲身实践，如果仅仅是了解可以直接观看，如果想要复现可以戳实践环境获得开发环境（处于安全考虑，在2019年国赛打完之前此链接的仓库为private，请谅解）\n\n 场景概述\n笔者需要对一个excel数据表中的记录（含有经纬度信息），表格字段如下\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n任务号码\n任务gps纬度\n任务gps经度\n任务标价\n任务执行情况\n\n\n\n我们现在需要将字段B和C中的经纬度提取为坐标并将这些坐标分类，在这里我们使用k-means方法来大致观察坐标并分类（手动实现没用轮子.jpg）\n 实验环境\n\npython 3(笔者使用python 3.6)\n\n 基本原理\n k-means\nk-means的大致思路\n\n在数据集中随机挑选x个数据作为中心点（x为聚类数量）；\n每个数据挑选最近的中心点，围绕这个中心点的所有数据点成为一个聚类。（此处我们的距离使用欧氏距离）；\n完成！\n\n 一些不尽如人意的地方和问题\n\n数据集本身位置，事先未必能较为准确的预估聚类的个数（甚至大致范围也难以确定）；\n由于挑选聚类是随机的，可能这些点选择的不尽人意。\n如何评估随机生成的聚类中心的质量？\n\n 成果预览\n\nP.S. 此处展示了聚类为3的输出，地图是后期通过其他方式贴合上去的，至于贴合方法……有缘更新吧……\n\n\n\n 解决方案&amp;实现\n 聚类逻辑代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151from math import sqrtfrom random import randint, randomimport matplotlib.pyplot as pltfrom dataReader import dataReaderclass Classifier:    # 初始化、读入数据库、标定数据范围    def __init__(self):        # 原始数据        self.rawData = dataReader()[0]        # 下标下限        self.LOWER_LIMIT = 0        # 下标上限        self.UPPER_LIMIT = len(self.rawData) - 1    # 产生一组不重复的随机中心    def generateRandomCenter(self, typeCount: int):        # 随机中心（聚类）数        self.typeCount = typeCount        # 随机中心编号列表        self.coreList = list()        while len(self.coreList) &lt; self.typeCount:            key = randint(self.LOWER_LIMIT, self.UPPER_LIMIT)            if key in self.coreList:                continue            self.coreList.append(key)        # print('[center]%s' % str(self.coreList))    # 聚类计算    def calc(self):        # 聚类列表        self.classList = [list() for _ in range(self.typeCount)]        for i in self.rawData:            key = float('inf')            ptr = -1            for j in self.coreList:                distance = dis(i, self.rawData[j])                if key &gt; distance:                    ptr = self.coreList.index(j)                    key = distance            self.classList[ptr].append(i)        # print('[info] calc finished 😂')    # 绘制聚类图    def draw(self):        plt.rcParams['font.sans-serif'] = ['SimHei']        plt.rcParams['axes.unicode_minus'] = False        plt.figure(figsize=(30, 20), dpi=100)        plt.xlim(112, 115)        plt.ylim(22, 24)        plt.xlabel('经度/°E')        plt.ylabel('纬度/°N')        plt.title(            '%d centers with average distance %.4f'            % (self.typeCount, self.totalAverage)        )        # print(str(self.coreList))        handerList = list()        for i in self.classList:            col = (random(), random(), random())            handerList.append(                plt.plot([x[2] for x in i], [x[1] for x in i],                     'x', color=col)            )        # plt.text(112.74, 23.8, str(self.coreList), ha='left', fontsize=8)        plt.legend(self.coreList)        plt.draw()        # plt.show()        # plt.text(4, 1, t, ha='left', rotation=15, wrap=True)        plt.savefig('resPic\\%s.jpg' % str(self.typeCount))    # 计算得分（平均距离）    def score(self):        # 每个分组的平均距离        self.averageList = list()        try:            for key in range((len(self.coreList))):                self.averageList.append(                    sum([dis(x, self.rawData[self.coreList[key]])                         for x in self.classList[key]]) /                    len(self.classList[key])                )        except Exception:            Exception(\"bad center!\")        # print('[average]')        self.totalAverage = 0        # 加权平均        for i in self.averageList:            self.totalAverage +=  \\                i*len(self.classList[self.averageList.index(i)])            # print('\\t[group %d]\\t%f' % (self.averageList.index(i), i))        self.totalAverage /= len(self.rawData)        # print('\\t[total]\\t\\t%f' % self.totalAverage)        return self.totalAverage    # 单次运行    def run(self):        self.generateRandomCenter(10)        self.calc()        self.score()    # 给定聚类数多次随机取表现较好值    def des(self, typeCount: int):        # 最优结果、得分暂存变量        score = float('inf')        resList = None        # 连续conn次没有得到更优化的结果的次数        conn = 0        # 尝试次数计数器        counter = 0        while (conn &lt; 100):            counter += 1            # print('[attempt %d with %d times better]' % (counter, conn))            self.generateRandomCenter(typeCount)            self.calc()            try:                tempScore = self.score()            except Exception:                print(\"[ERROR]\\tbad center occured skip.\")                continue            if tempScore &lt; score:                resList = self.coreList                score = tempScore                conn = 0            else:                conn += 1        # 还原最佳聚类现场以便后续画图        self.coreList = resList        self.calc()        print('[info]\\tdes finish with best score %f' % score)        print(resList)        return resListdef dis(obj1: list, obj2: list):    assert isinstance(obj1, list), \\        '[ERROR] 第一个参数应当为list,输入的参数类型为$s' % str(type(obj1))    assert isinstance(obj2, list), \\        '[ERROR] 第二个参数应当为list,输入的参数类型为$s' % str(type(obj2))    return sqrt((obj1[1] - obj2[1]) ** 2 + (obj1[2] - obj2[2]) ** 2)if __name__ == '__main__':    exp = Classifier()    for i in range(3, 20):        print('[center counter]\\t%d' % i)        exp.des(i)        exp.draw()\n 数据处理和读入代码\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import xlrdimport sys# import datetimedef dataConverter(src: list)-&gt;list:    res = list()    res.append(src[0])    for i in range(1, 4):        res.append(src[i])    res.append(int(src[4]))    return resdef dataReader():    fileName = None    try:        fileName = sys.argv[-1]        print('[fileName]%s' % fileName)    except Exception:        print('no file name')    data = list()    try:        workbook = xlrd.open_workbook(filename=fileName)        for i in range(workbook.nsheets):            data.append(list())            rangeRow = workbook.sheet_by_index(i).nrows            sheet = workbook.sheet_by_index(i)            for x in range(rangeRow):                temp = sheet.row_values(x)                if temp[0] == '任务号码':                    continue                data[i].append(dataConverter(temp))    except Exception as e:        print('bad data file')        print('\\t[Exception]\\t%s' % str(e))        exit()    # for i in data:    #     for x in i:    #         print(x)    print('😀[info]\\tdata fetched successfully')    return dataif __name__ == '__main__':    data = dataReader()    for sheet in data:        for x in sheet:            print(x)","plink":"hanyuulu.github.io/k-means/"},{"title":"Python中遍历List时删除元素","date":"2019-07-13T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" 场景复现\n\n举一个简单的栗子\n\n123456789&gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; for i in range(len(numList)):...     del(numList[i])...Traceback (most recent call last):  File \"&lt;stdin&gt;\", line 2, in &lt;module&gt;IndexError: list assignment index out of range&gt;&gt;&gt; print(numList)[1, 3, 5, 7, 9]\n\n这里还有另一个栗子\n\n123456&gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; for i in numList:...     numList.remove(i)... &gt;&gt;&gt; print(numList)[1, 3, 5, 7, 9]\n 错误原因\n\n不难发现在遍历python的list的时候删除该list的元素这个操作往往不会按照我们的预期运行\n当使用for发起遍历操作时，for的遍历顺序已经确定了，删除操作会导致列表索引的变化，这可能引起\n\n元素没有按照预期删除\n数组访问越界\n\n\n\n 解决方案\n\n\n删除操作在遍历操作之后(记录待删除元素)\n123456789101112&gt;&gt;&gt; delList = list() &gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; for i in numList:  ...     if i % 2 == 0:...             delList.append(i)... &gt;&gt;&gt; for i in delList: ...     numList.remove(i)... &gt;&gt;&gt; numList[1, 3, 5, 7, 9]&gt;&gt;&gt;\n\n\n使用替代数组\n\n\nFilter\n123456789101112&gt;&gt;&gt; numList = list(range(10))&gt;&gt;&gt; numList = filter(lambda x : x % 2 == 0, numList)&gt;&gt;&gt; print(numList)&lt;filter object at 0x000002B358100470&gt;&gt;&gt;&gt; for i in numList:...     print(i)... 02468\n\n\nList\n1234&gt;&gt;&gt; numList = list(range(10))                   &gt;&gt;&gt; numList = [x for x in numList if x % 2 == 0]&gt;&gt;&gt; numList[0, 2, 4, 6, 8]\n\n\n\n\n遍历list的备份\n1234567&gt;&gt;&gt; numList = list(range(10))                   &gt;&gt;&gt; for i in numList[:]:...     if i % 2 == 0:...             numList.remove(i)... &gt;&gt;&gt; numList[1, 3, 5, 7, 9]\n\n\n逆序遍历\n1234567&gt;&gt;&gt; numList = list(range(10))   &gt;&gt;&gt; for i in range(len(numList) - 1, -1 , -1):...     if numList[i] % 2 == 0:...             del(numList[i])... &gt;&gt;&gt; numList[1, 3, 5, 7, 9]\n\n\n","plink":"hanyuulu.github.io/delInList/"},{"title":"操作系统原理总结","date":"2019-06-18T23:03:06.000Z","updated":"2021-03-12T08:22:58.406Z","content":"[TOC]\n Chapter 1 Introduction\n\n\nSystem view\n_ Resource allocator\n_ Control program\n\n\nDual-Mode Operation\n_ User mode\n_ Kernel mode\n_ privileged instruction\n_ \n_ \n_ Hardware\n_ CPU protection\n_ timer\n_ time sharing\n_ memory protection\n_ Base register\n_ Limit register\n_ I/O protection\n_ all I/O instruction are privilege instructions\n\n\nDevelopment of OS * mainframe systems\n\t\t*   NO OS\n\t\t*   **batch systems**\n\t\t*   **multiprogramming systems**\n\t\t*   **time sharing systems**\n\n\t*   desktop systems\n\n\t*   multiprocessor systems\n\n\t*   distributed systems\n\n\t*   clustered systems\n\n\t*   real-time systems\n\n\t*   handheld systems\n\n\t*   现代操作系统的特征\n\n\t\t*   **并发性Concurrence**\n\t\t*   **共享性Sharing**\n\t\t*   **虚拟性Virtual**\n\t\t*   **异步性Asynchronism**\n\t\t*   提高CPU利用率，充分发挥并发性：**程序之间、设备之间、设备与CPU之间**均**并发**\n\n\t*   Pr：\n\n\t\t批处理系统、多道程序系统和分时系统的技术特性\n\n\n\n Chapter 2 Operating-System Structures\n\n功能和服务的差别：\n\n功能对内：自行实现\n服务对外：可以调用其他功能代为实现\n\n\ncommon function of OS\n\nprocess management\n\nprocess synchronization\nprocess communication\ndeadlock handling\n(分布式)\n\n\nmain memory management\nsecondary-storage management\nfile management\nI/O system management\n\n\nOperating System Services(Services for helping users)\n\nProgram execution\nI/O operations\nFile-system manipulation\nCommunications\nError detection\nResource allocation\nAccounting(审计)\nProtection\n\n\nOperating System Interface\n\nInterface to programs\n\nSystem calls\n\nSystem-call interface(SCI)\nApplication Programming Interface(API)\n\nmanaged by runtime support library\n\n\n\n\n\n\n\nTypes of System calls\n\nProcess control\nFile management\nDevice management\nInformation maintenance\nCommunications\n\n\n\n\n\n\nPR. Why do user use APIs rather than system calls directory?\nAns\n\n跨平台能力（提供相同的 API 封装）移植性好\n模块化封装，可维护性好\n简化了程序编写\n提高了执行效率\n\n\n\n\nOperating System Structure\n\nSimple structure\nLayered structure\n\nvirtual machines\n\n\nMicrokernel structure\n\nBenefis\n\neasier to extend\neasier to port\nmore reliable\nmore secure\n\n\n\n\nModules\nPR:设计操作系统时采用的模块化内核方法和分层方法在那些方面类似？那些方面不同？\n\n\nOperating system design and implementation\n小结\n\n操作系统概念（管理资源、支持程序运行、方便用户使用的程序集）\n操作系统的基本目标：方便性和高效性\n引导程序：中断、中断处理程序、中断向量\n储存结构：内存（小、易失）二级储存（大、非易失）、分层结构\nI/O 结构：设备控制器（本地缓冲）、DMA\n硬件保护：双重模式操作、特权指令、I/O 保护、内存保护、CPU 保护\n操作系统的发展：e.g: 多道程序设计\n操作系统的功能：进程（CPU）管理、内存管理、磁盘管理、文件管理、I/O 管理、用户接口\n操作系统服务：程序执行、I/O 操作、文件系统操作、通信、错误检测与处理、资源分配、统计、保护\n操作系统接口：用户接口（CLI、GUI）、程序接口（系统调用（参数传递、类型））、SCI、API\n操作系统结构\n\n\n\n Chapter 3 Process\n\n\nProcess\n\ntest section(program code)\nprogram counter\ncontents of the processer’s registers\nHeap-stack\ndata section\n\n\nCharacteristic of process\n\nDynamic 动态性\nIndependency 独立性\nConcurrence 并发性\nStructure 结构化\n\n\nPR.进程和程序是两个密切相关的概念，请阐述他们之间的区别和联系\nProcess state\n\n\nProcess control block(PCB)\n\n\n\n\n\nProcess scheduling queues\n\nJob queue (in main memory)\n\nReady queue\ndevice queues\n\nprocess migration between the various queues\n\n\n\n\n\n\nSchedulers\n\nLong-term scheduler(秒级、分钟级，作业调度)\nShort-term scheduler(毫秒级，CPU 调度)\nMedium-term scheduler(swapping)\n\n\nI/O bound process\nCPU bound process\nContext switch\n\nThe context of a process is represented in PCB of the process and includes the values of CPU registers.\n保存执行后的上下文信息\n上下文切换会带来开销\n尽量减少上下文切换以减少开销\n\n\n\n\n\n\n\n\n\nOperation on Process\n\n\nProcess creation\n\n\nchild process(unique process identifier(int)), tree of process\n\n\nresource sharing\n\nparent and children shall all resources\nchildren share subset of parent’s resources\nparent and child share no resources\n\n\n\nExecution\n\nParent and children execute concurrently\nParent waits until children terminate\n\n\n\nAddress space\n\n\nchild duplicate of parent\n\n\nchild has a program loaded into it (new text section)\n\n\nUNIX examples\n\n\nfork() :create new process\n\n\nexec() :used after a fork to replace the process’s memory space with a new program\n\n\n\n\n\n\n12345678910111213141516pid = fork();if(pid&lt;0)\t/* error occured */&#123;    printf(stderr,\"Fork failed\");    exit(-1);&#125;else if(pid==0)\t/* child process */&#123;    execlp(\"/bin/ls\",\"ls\",NULL);&#125;else\t/* parent process */&#123;    wait(NULL);\t/* wait for child process to finish */    printf(\"Child complete\");    exit(0);&#125;\n\n\n\n\nProcess Termination\n\nexit() process executes last statement and asks the operating system to delete it\n\noutput data from child to parent (via wait)\nProcess’s resources are deallocated by OS\n\n\nabort() parent may terminate execution of children process\n\nchild has exceeded allocated resources\ntask assigned to child is no longer required\nparent is exiting *not all of the operation system supports Cascading termination(级联终止)\n\n\n\n\n\n\n\n\n\n\n\nInter-process Communication(IPC)\n\n\nIndependent process cannot affect or be effected by the execution of another process\n\n\nCooperating process can affect or be effected by the execution of another process\n\n\nAdvantages\n\n\nInformation sharing\n\n\nComputation speed-up\n\n\nModularity\n\n\nConvenience\n\n\n\n\n\n\nShared memory &amp; Message passing\n\n\n\n\nShared-memory Systems\n\t- requiring communication process to establish a region of shared memory\n\t- a shared memory region resides in the address space of the process creating the shared memory segment\n\t- the processes are responsible for ensuring that they are not writing to the **same location simultaneously**\n\t\t- Producer-Consumer Problem\n\n\n\nMessage-passing Systems\n\t- MPS has two operations\n\n\t\t- send()\n\t\t- receive()\n\n\t- communication link\n\n\t\t1. link may be unidirectional or bidirectional (双向)\n\n\t\t2. a link may be associated with many processes\n\n\t\t- direct communication\n\n\t\t\t- send(P,message) send a message to process P\n\t\t\t- receive(Q,message)  receive a message from process Q\n\n\t\t- indirect communication\n\n\t\t\t- mailboxes\n\n\t\t\t\t- each mailbox has a unique id\n\n\t\t\t\t- two processes can communicate only if the share a mailbox\n\n\t\t\t\t- Operations\n\n\t\t\t\t\t&gt; 1. create a new mailbox\n\t\t\t\t\t&gt; 2. send and receive messages through mailbox\n\t\t\t\t\t&gt; 3. destroy a mail box\n\n\n\nSynchronization\n\t- Blocking: synchronous\n\t- Non-blocking: asynchronous\n\n\n\nBuffering\n\t- **Zero capacity** sender must wait for receiver\n\t- **Bounded capacity** finite length of $n$ messages, sender must wait if link full\n\t- **Unbounded capacity** infinite length, sender never blocks\n\n\n\n\n\n\n\nCommunication in Client-Server System\n\nSockets\nRemote Procedure Calls\nRemote Method Invocation (Java)\n\n\n\n Chapter 4 Threads\n\n\nMultithreading Models\n\n\nA thread is a flow of control within a process\n\n\nthread is a basic unit of CPU execution (known as light weight Process(LWP))\n\n\nprocess (heavy weight process(HWP)) has a single thread of control\n\n\nmultithreaded process contains several different flows of control within the same address space\n\n\nThread\n\n\nhas\n\nthread ID\nprogram counter\nregister set\nstack\n\n\n\nshare\n\n\ncode section\n\n\ndata section\n\n\nother OS resources(file and signals)\n12\n\n\nBenefits\n12- resource sharing- economy(low cost in overhead of creating and context-switch)\n\n\n\n\nUser Threads\n\n\nuser threads are supported above the kernel. The kernel is not aware of user threads\n\n\nLibrary provides all support for thread creation, termination, joining and scheduling\n\n\nmore efficient(no kernel intervention)\n\n\nif one thread is blocked, every other threads of the same process are also blocked(containing process is blocked)\n\n\n\n\nKernel Threads\n\n\nkernel threads are usually slower than the user threads\n\n\nblocking one thread will not cause other threads of the same process to block\n\n\nthe kernel can schedule threads on different processors(in a multiprocessor environment)\n\n\nPr.\n\n进程和线程之间的区别和联系\n用户级线程和内核级线程的区别\n\n\n\n\n\n\n\nMultithreading models\n\n\nmany to one\n\nonly one thread in the one process can access the kernel at a time\ntrue concurrency is not gained\n\n\n\n\n\none to one\n\n\neach user-level thread maps to kernel thread\n\n\nproviding more concurrency\n\n\nrestricting the number of threads supported by the system\n\n\n\n\n\n\nmany to many\n\n\nallow many user level threads to be mapped to many kernel threads\n\n\n\n\n\n\n\n\n\n\n\n\nThread Libraries\n\nstatus\n\n\n123456789101112131415161718192021int pthread_create(tid,attr,function,arg);/* * pthread_t *tid \thandle of created thread * const pthread_attr_t *attr \tattribes of thread to be created * void *(*function)(void) \tfunction to be mapped to thread * void * arg \tsingle argument to function */int pthread_join(tid,val_ptr);/* * pthread_t *tid \thandle of joinable thread * void ** var_ptr \texit value rturn by joined thread */void pthread_exit(void *status);int pthread_cancel(pthread_t thread);\t//terminated immediatelyint pthread_kill(pthread_t thread,int sig);\n\nCreateThread\nGetCurrentThreadId\nGetCurrentThread\nSuspendThread/ResumeTread\nExitThread\nTerminateThread\nGetExitCodeThread\nGetThreadTimes\n\n\n\nThreading Issues\n\n\nOperating System Examples\n\n\n//TODO 关于线程的实现\n\n\nPr.\n\n信号机制和中断机制的异同\n\n\n\nThread Pools\n\nadvantages - faster to service a request(save the time to create new thread) - allow the number of threads in the application to be bound to the size of the pool\n\n\n\nThread specific data\n\nthreads belonging to a process share the data of the process\nallows each thread to have its own copy of data\nwhen using a thread pool, each thread may be assigned a unique identifier\n\n\n\nScheduler activations\n\n\nupcalls\n\n\n Chapter 5 CPU Scheduling\n\n\nMaximum CPU utilization obtained with multiprogramming\n\n\nThe success of CPU scheduling depends on an property of processes:CPU-I/O Burst Cycle\n\nprocess execution consists of a cycle of CPU execution and I/O wait.\n\n\n\nCPU-bound\n\na few very long CPU bursts\n\n\n\nI/O-bound\n\nmany short CPU bursts\n\n\n\n\n\nWhen the CPU is idle, the OS must select another ready process to run\n\n\nThis selection process is carried out by the short-term scheduler\n\n\nThe CPU scheduler selects a process from the ready queue and allocates the CPU to it\n\n\nThere are many ways to organize the ready queue(e.g. FIFO)\n\n\n\n\nCircumstances that scheduling may take place\n\n\nA process switches from the running state to the terminated state(finished)\n\n\nA process switches from the running state to the wait state(e.g. IO operation)\n↑ 主动操作 ↑ 非抢占式调度\n\n↓ 被动中止 ↓ 抢占式调度 → 同步机制\n\n\nA process switched from the running state to the ready state(e.g. a interrupt occurs)\n\n\nA process switches from the wait state to the ready state(e.g. I/O completion)\n\n\nA process switches from the new state to ready state(e.g. a higher priority process ready)\n\n\nPreemptive(抢占式)\n\ncost associated with access to shared data\nWhen the kernel is in its critical section modifying some important data .\nspecial attention to situation\n\n\n\nNon-preemptive\n\nscheduling occurs when a process voluntarily terminates(主动结束) (case1)or enters the wait state(case2)\nsimple but very inefficient\n\n\n\nPr.\n​ 对于计算中心，抢占式调度和非抢占式调度哪一种比较适合\n\nDispatcher(调度) module\n\nswitching context\nswitching to user mode\njumping to the proper location in the user program to restart that program\n\n\nDispatch latency\n\nthe dispatcher should be as fast as possible\n\n\n\n\n\nScheduling criteria\n\n\nCPU utilization\n\nkeep the CPU as busy as possible\nlightly|40%|-|90%|heavily\n\n\n\nThroughput(吞吐)\n\nhigher throughput means more jobs get done\n\n吞吐量和 CPU 利用率有相关性但并没有直接关系\n\n\nTurnaround time\n\nThe time period from job submission to completion is the turnaround time\n\ntturnaround=twaitingTimeBeforeEnteringTheSystem+twaitingTImeInTheReadyQueue+twaitingTImeInAllOtherEvents+ttimeTheProcessActuallyRunningOnTheCPUt_{turnaround}=\\\\t_{waitingTimeBeforeEnteringTheSystem}+\\\\ t_{waitingTImeInTheReadyQueue}+\\\\t_{waitingTImeInAllOtherEvents}+\\\\t_{timeTheProcessActuallyRunningOnTheCPU}\ntturnaround​=twaitingTimeBeforeEnteringTheSystem​+twaitingTImeInTheReadyQueue​+twaitingTImeInAllOtherEvents​+ttimeTheProcessActuallyRunningOnTheCPU​\n\n\n\n\nWaiting time\n\ntime in ready queue\n\n\n\nResponse time\n\nthe time form the submission of a request\n\n\n\nOptimization Criteria\n\nMAX CPU utilization\nMAX throughtput\nMIN turnaround time(average)\nMIN waiting time\nMIN response time\n\n\n\n为什么需要 CPU 调度\n大多数任务是CPU和I/O交替使用，\n导致CPU和I/O至少有一个空闲，\n通过调度让需要执行I/O的任务去执行I/O。\n把CPU给需要CPU的任务运行。\n\n\nScheduling Algorithms\n\n\nFirst-Come-First-Served Scheduling (FCFS)\n\ncan easily implemented using a queue\nnot preemptive\nconvoy effect (护航效应)\ntroublesome for time-sharing systems\n\n\n\nShort-Job-First Scheduling (SJF)\n\nsorted in next CPU burst length\ncan be nonpreemptive and preemptive\nminimum average waiting time for a given set of process\npredict CPU burst: exponential averaging\nlong jobs may meet starvation!!!\n\n\n\nPriority Scheduling\n\n\neach process has a priority\n\n\npriority may be determined internally or externally\n\ninternal priority\n\ntime limits\nmemory requirement\nnumber of files\netc.\n\n\nexternal priority\n\nimportance of the process (not controlled by the OS)\n\n\n\n\n\nstarvation/Indefinite block\na lower priority may never have a chance to run\n\nAging\n\ngradually increase the priority of process what wait in the system for a long time\n\n\n\n\n\n\n\nRound_Robin Scheduling (RR)(轮询)\n\ndesigned for time-sharing systems\neach process is assigned a time quantum/slice\nIf the process uses CPU for less than one time quantum, it will release the CPU voluntarily (主动退出)\nwhen one time quantum is up , that process is preempted by the scheduler and moved to the tail of the list\nTypically, higher average time than SJF, better response time\ntime quantum is too large → FCFS\ntime quantum is to small → processor sharing (并发)\n\nshorter time quantum means more context switches\n\n\nin general, 80% of the CPU bursts should be shorter than the time quantum\n\n\n\n\nMultilevel Queue Scheduling (多级队列)\n\n\npartitioned into separate queues\n\nforeground (interactive)\nbackground (batch)\n\n\n\nEach process is assigned permanently to one queue based on some properties of the process\n\n\nEach queue has its own scheduling algorithm\n\n\nforeground - RR\n\n\nbackground -FCFS\n\n\n\n\n\nScheduling must be done between the queues\n\nFixed priority scheduling (possibility of starvation)\nTime slice\n\neach queue gets a certain amount of CPU time which it can schedule amongst its processes\n\n\n\n\n\n\n\n\n\nMultilevel Feedback Queue Scheduling\n\n\nallows process to move between queues\n\n\naging can be implemented this way\n\n\nIf a process use more/less CPU time, it is moved to a queue of lower/higher priority → I/O/CPU-bound process will be in higher/lower priority queues\n\n\nexp\n\n\n\n\n\nnumber of queues\nscheduling algorithms for each queue\nmethod used to determine when to upgrade a process\nmethod used to determine when to demote a process\nmethod used to determine which queue a process will enter when that process needs service\n\n\n\n\n\nMultiple-Processor Scheduling\n\nHomogeneous(同构) processors\nLoad balancing\n\npush migration\npull migration\n\n\nAsymmetric multiprocessing (非平衡处理)\n\nonly on processor accesses the system data\n\nalleviating(降低) the need for data shring\n\n\n\n\nSymmetric multiprocessing (SMP)\n\ntwo processors do not choose the same process\n\n\nProcessor Affinity (侵核)\n\nmost SMP systems try to avoid migration of processes from one processor to another\n\nSoft/Hard Affinity (执行过程中可以/不可以侵核)\n\n\n\n\n\n\n\nReal-Time Scheduling\n\nHard real-time systems\nthe scheduler either admits a process and guarantees that the process will complete on-time, or reject the request (resource reservation)\nsecondary storage and virtual memory will cause unavoidable delay\nHard real-time systems usually have special software on special hardware\n\n\n\nSoft real-time systems\n\neasily doable(可行) within a general system\nmay cause unfair resource allocation and longer delay(starvation) for noncritical tasks.\nthe CPU scheduler must prevent aging to occur(critical tasks may have lower priority)\nThe dispatch latency must be small\n\n\n\nPriority Inversion\n\na high-priority process needs to access the data that is currently being accessed by a low-priority process → The high-priority process is blocked by the low-priority process\npriority-inheritance protocol\n\n\n\nThread Scheduling\n\nUser-level threads\n\nthread library\n\n\nKernel-level threads\n\nscheduled by OS\n\n\nuser-level threads must ultimately be mapped to an associated kernel-level thread\nLocal scheduling → User-level Thread\n\nProcess-contention Scope (PCS)\n\n\nGlobal Scheduling → Kernel-level Thread\n\nSystem-contention Scope (SCS)\n\n\n\n\n\nAlgorithm Evaluation\n\n\nDeterministic modeling (Analytic evaluation) 确定情况下 的情形证明\n\n\nQueueing models 队列模型\n\n\nSimulations 仿真\n\n\nImplementation 证明\n从上往下证明力越强，越难证明\n\n\n\n\nOperating System\n\nScheduling threads using preemptive and priority-based scheduling algorithms (Real time, system, time sharing, interactive)\nThe default scheduling class for a process is time sharing (multilevel feedback queue)\n\n\n\n Chapter 6 Process Synchronization\n\n\nBounded-buffer\n\t1234567891011121314151617181920212223242526272829303132//Shared data#define BUFFER_SIZE 10typedef struct&#123;    //...&#125; item;item buffer[BUFFER_SIZE];int in = 0;int out = 0;int counter = 0;//Producer processitem nextProduced;while(1)&#123;    while(counter == BUFFER_SIZE);    \t//do nothing    buffer[in] = nextProduced;    in = (in + 1) % BUFFER_SIZE;    counter++;&#125;//Consumer processitem nextConsumed;while(1)&#123;    while(counter == 0)        //do nothing    nextConsumed = buffer[out];    out = (out + 1) % BUFFER_SIZE;    counter--;&#125;\n\n\n\nAtomic operation\n\t- counter++\n\t- counter—\n\n\n\nRace condition\n\t- two or more processes/thread access and manipulate the same data concurrently\n\t- the outcome of the execution depends on the particular order in which the access takes place\n\t- To prevent race conditions, concurrent processes must be synchronized\n\n\n\nThe Critical-Section Problem\n\t- Each process has a code segment, called critical section\n\n\t- **Problem**: ensure that when one process is executing in its critical section, no other process is allowed to execute in its critical section\n\n\t- The critical-section problem is to design a protocol that processes can use to cooperate\n\n\t\t┌────────────┐\n\n\t\t|    entry section      |\n\n\t\t├────────────┤\n\n\t\t|    critical section    |\n\n\t\t├────────────┤\n\n\t\t|       exit section      |\n\n\t\t├────────────┤\n\n\t\t|remainder section |\n\n\t\t└────────────┘\n\n\t\t**critical section must run in a mutually exclusive way.**\n\n\n\nSolution to Critical-Section Problem\n\t- Mutual Exclusion (互斥、忙等) → 防止冲突\n\t- Progress (空闲让进) → 进展性\n\t- Bounded Waiting (有限等待) → 进展性\n\t\t- &lt;small&gt;防止饥饿，让权等待，多CPU：死锁&lt;/small&gt;\n\t- **the solution cannot depend on relative speed of processes and scheduling policy**\n\t- Mutual Exclusion\n\n\n\nBakery Algorithm\n\t1234567891011121314151617//shared databoolean choosing[n];\t//falseint number[n];\t\t\t//0do&#123;    choosing[i] = true;    number[i] = max(number[0],number[1],...,number[n-1])+1;    choosing[i] = false;    for(j = 0; j &lt; n; ++j)    &#123;        while(choosing[j]);        while((number[j] != 0)&amp;&amp;((number[j],j)&lt;(number[i],i)));    &#125;    //critical section    number[i] = 0;    //remainder section&#125;while(1)\n\n\n\nInterrupt Disabling\n\t- disable interrupts → critical section → enable interrupts\n\t- When interrupts are disabled, no context switch will occur in a critical section\n\t- Infeasible in a multiprocessor system because all CPUs must be informed\n\t- Some feature that depend on interrupts (e.g. clock) may not work properly\n\n\n\nMutual Exclusion (互斥锁)\n\t- TestAndSet\n\n\t\t123456boolean TestAndSet(boolean &amp;target)&#123;\tbooean rv = &amp;target;    &amp;target = true;    return rv;&#125;\n\n\t\t12345678910//shared databoolean lock = false;//Process Pdo&#123;    while(TestAndSet(lock));    //critical section    lock = false;    //remainder section&#125;\n\n\n\nSwap\n\t- **atomically** swap two variables\n\n\t\t123456void Swap(boolean &amp;a,boolean &amp;b)&#123;    boolean temp = &amp;a;    &amp;a = &amp;b;    &amp;b = temp;&#125;\n\n\t\t12345678910111213141516//Global shared databoolean lock;\t//false//Local variable for each processboolean key;Process Pido&#123;\tkey = true;\twhile(key == true)    &#123;    \tSwap(lock,key);    &#125;    //critical section    lock = false;    //remainder section&#125;\n\n\n\nSemaphores\n\t12345678910wait(S)&#123;\twhile(S &lt;= 0);\t\t--S;&#125;signal(S)&#123;    ++S:&#125;\n\n\t- Count semaphore\n\t- Binary semaphore (mutex locks)\n\n\n\nbusy waiting (Spinlock)\n\n\nblock itself (阻塞方法，使用 PCB 唤醒)\n\t- Define a semaphore as a record\n\n\t\t12345typedef struct&#123;    int value;    struct process *L;\t//waiting queue&#125;semaphore;\n\n\t\t- block()\n\t\t- wakeup(P)\n\n\t\t123456789101112131415161718wait(S)&#123;    S.value--;    if (s.value &lt; 0)    &#123;        //add this process to S.L;        block();    &#125;&#125;signal(S)&#123;\tS.value++;    if(S.value &lt;= 0)    &#123;        //remove a process P from S.L;        wakeup(P);    &#125;&#125;\n\n  - if the semaphore is negative, its magnitude is the number of process waiting on that semaphore\n  - Busy waiting has not been **completely** eliminated\n  - furthermore, we have limited busy waiting to the critical sections of the wait() and signal() operations\n\n\n\nDeadlock and Starvation\n\t&lt;small&gt;临界资源、同步关系&lt;/small&gt;\n\n\t- Bounded-Buffer Problem\n\n\t\t123456789101112131415161718192021//Shared dataSemaphore full = 0,empty = n,mutex = 1;do\t//Producer&#123;    //produce an item in nextP    wait(empty);    wait(mutex);    //add nextP to buffer    signal(mutex);    signal(full);&#125;while(1);do\t//Consumer&#123;    wait(full);    wait(mutex);    //remove an item from buffer to nextC    signal(mutex);    signal(empty);    //consume the item in nextC&#125;while(1);\n\n\t- Readers and Writers Problem\n\n\t\t- Reader first\n\t\t- Writer first\n\n\t\t123456789101112131415161718192021222324//Shared dataint readcount;semaphore wrt = 1,mutex = 1;int readcount = 0;do&#123;    wait(wrt);    //writing    signal(wrt);&#125;while(1);do\t\t//Error: 写者饥饿问题&#123;    wait(mutex);    readcount++;    if(readcount == 1)        wait(wrt);    signal(mutex);    //reading    wait(mutex);    readcount--;    if(readcount == 0)        signal(wrt);    signal(mutex);&#125;\n\n\t- Dining-Philosophers Problem\n\n\t- 过独木桥问题\n\n\t\t123456//Shared dataint countA = 0;\t//A方向上已在独木桥上的行人数目int countB = 0;\t//B方向上已在独木桥上的新人数目semaphore MA = 1;\t//countA的互斥锁semaphore MB = 1;\t//countB的互斥锁semaphore mutex = 1;\t//实现互斥使用\n\n\t\t- A方向过桥\n\n\t\t\t123456789101112131415161718do&#123;    wait(MA);    countA++;    if (count == 1)    &#123;        wait(mutex);    &#125;    signal(MA);    //过桥    wait(MA);    countA--;    if(countA == 0)    &#123;        signal(mutex);    &#125;    signal(MA);&#125;while(1);\n\n\n\nMonitors (管程)\n\t- High-level synchronization construct that allows the safe sharing of an abstract data type among concurrent processes\n\n\t\t1234567891011121314monitor monitor-name&#123;\tshared variable declarations\tproceudre body P1()    &#123;    \t//...    &#125;    \tproceudre body P2()    &#123;    \t//...    &#125;    //...    &#123;//initialization code&#125;&#125;\n\n\t- no more than one process can be executing within a monitor\n\n\t- when a process calls a monitor procedure and the monitor has a process running, the caller will be blocked outside the monitor\n\n\t- Mutual exclusion is guaranteed with in a monitor\n\n\t\t![](/Review/OS/1555948188580.png)\n\n\t\t![](OS/1555948188580.png)\n\n\n\nCondition variables\n- x,y\n\n\t- x.wait() means that the process invoking this operation is suspended until another process invokes x.signal();\n\t- x.signal() operation resumes exactly one suspended process. If no process is suspended, the signal() operation has no effect\n\n\t![](/Review/OS/1555948399247.png)\n\n\t![](OS/1555948399247.png)\n\n\n\t|                          Semaphores                          |                     Condition Variables                      |\n\t| :----------------------------------------------------------: | :----------------------------------------------------------: |\n\n\n\n| Can be used anywhere, but not in a monitor | Can only be used in monitors |\n| wait() does not always block its caller | wait() always blocks its caller |\n| signal() either releases a process, or increase the semaphore counter | signal() either releases a process ,or the signal is lost as if it never occurs |\n| If signal() release a process, the caller and the release both continue | If signal() release a process, either the caller or the released continues, but not both | - 管程是公用数据结构，进程是私有数据结构 - 管程集中管理共享变量上的同步操作，临界区分散在每个进程中 - 管程管理共享资源，进程占用系统资源和实现系统并发性 - 管程被欲使用的共享资源的进程调用，管程和调用它的进程不能并发工作，进程之间能并发工作 - 管程是语言或操作系统的成分，不必创建或撤销，进程有生命周期，有创建有消亡\n Chapter 7 Deadlocks\n\n\nsystem model\n\nDeadlock\n\nResources types R1 ,R2 …,Rm\nCPU cycles, memory space, I/O devices, files and so on\neach resource type Ri has Wi instances\nrequest → use → release\n\n\n\n\n\ndeadlock characterization\n\n\nThe conditions for deadlock\n\nmutual exclusion\nhold and wait\nno preemption\ncircular wait\n\n\n\nresource allocation graph\n\n\nedges E,process P,resource R\n\n\nrequest edge Pi→Rj\n\n\nassignment edge Rj→Pi\n\n\n\n\n\n\n\n死锁一定循环，循环未必死锁\n当实例只有一个资源时，有循环就会死锁\n但是当实例有多个资源时，循环可能导致死锁（如上图）\n\n\n\n\n\n\n\n\n\n\n\nMethods for handling deadlocks\n\nEnsure that the system will never enter a deadlock state\n\nPrevention\n\nbreak conditions\n\n\nAvoidance\n\nthe OS needs more information to determine whether the current request can be satisfied of delayed\n\n\nAllow the deadlock, detect it, and recover.\nJust ignore it and pretend deadlocks will never happened. 😃\n\n\n\n\n\ndeadlock prevention\n\nMutual Exclusion\nhold and wait\n\na process must acquire all resources before it runs\nwhen a process requests for resources, it must hold none\n\nResource utilization might be low, since many resources will be held and unused for a long time\nstarvation is possible. A process that needs some popular resources may have to wait indefinitely\n\n\n\n\nNo preemption\n\nif a process that is holding some resources requests another resource that cannot be immediately allocated to it , then all resources currently being held are preempted(抢占)\n\nif the requested resources are not available\n\nif they are being held by process that are waiting for additional resources, these resources are preempted and given to the requesting process.\nelse, the requesting process waits until the requested resources become available. When it is waiting. its resources may be preempted\n\n\n\n\n\n\nCircular wait\n\na process can only request higher than the resources types it holds\na process must release some higher order resources to request a lower resource\n\n\n\n\n\ndeadlock avoidance\n\n\nall of the process declare the maximum number of resources of each type that it may need\n\n\nthe deadlock-avoidance algorithm dynamically exam the resource-allocation state to ensure that there can never be a circular-wait condition\n\n\nResource-allocation state is defined by the number of available and allocated resources, and the maxium demands of the process\n\n\nSafe state\n\n\nsingle instance of a resource type\n\nresource-allocation-graph algorithm\n\nclaim edge pi→pj indicated that process pi may request resource rj; represented by a dashed line\nclaim edge converts to request edge when a process requests a resource\nwhen a resource is released by a process, assignment edge reconverts to a claim edge\nresource must be claimed a prior in the system\n\n\n\n\n\nmultiple instances of a resource type\n\n\nbanker’s algorithm\n| process | max  | allocation | need |\n| ------- | ---- | ---------- | ---- |\n| P~0~ | [7,5,3] | [0,1,0] |[7,4,3]|\n\n| P1 | [3,2,2] | [2,0,0] |[1,2,2]|\navailable[3,3,2]\n\n\n\n\n\n\ndeadlock detection\n\n\nmaintain wait-for-graph and search for a cycle in the graph\n\n\nnodes are process\n\n\nPi→Pj is waiting for Pj\n\n\nsearch for a cycle\n\n\n\n\n\n\n\n\nrecovery form deadlock\n\nPross termination\n\nAbout all deadlocked process\nAbout one process at a time until the deadlock cycle is established\n\n\nResource preemption\n\nselecting a victim (minimize cost if possible)\nrollback\n\nreturn to some safe state restart process for that state\n\n\nstarvation\n\nsame process may always be picked as victim (aging)\ninclude the number of rollback in the cost factor\n\n\n\n\n\n\n\n Chapter 8 Memory Management\n\n\nbackgroud\n\n\nMain memory and register are only storage CPU can access directly\n\n\na register access per CPU clock\n\n\na main memory access many CPU clcok\n\n\ncache sites between main memory and CPU registers\n\nmemory protect\nbase and limit registers\nhardware address protection\nmultistep processing of a user program\n\nsymbolic address\n\nsource program\n\n\nrelocatable address\n\nobject program\n\n\nabsolute address\n\n\ncomplie time\n\nabsolute code\nos, drive\n\n\nload time\n\nrelocatable code\n\n\nexecution time\n\nneed hardware support\n\n\nLogical &amp; Physical address space\n\nlogical address\n\ngenerated by the CPU; referred to as virtual address\n\n\nphysical address\n\nseen by the memory unit\n\n\nlogical and physical addresses are the same in compile-time and load-time address-binding schemes and differ in execution\n\n\n\n\n\n\n\nMemory-Management Unit(MMU)\n\n\nmaps logical address to physical address\n\n\nthe value in relocation(base) register is added to every address generated by a user process at the time it is sent to memory\n\n\nThe user program deals with logical addresses\n\n\n\n\n\n\nDynamic loading\n\nlinking and loading postponed until execution time\n\n\n\nswapping\n\n\nbacking store: fast disk\n\n\nready queue\n\nconsisting of all processes on the backing store or in memory and are ready to run\nmajor part of swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped\n\n\n\n\n\n\n\n\n\n\n\ncontiguous allocation\n\n\nmain memory is usually divided into two partitions\n\nresident operation system\nuser processes\n\n\n\nrelocation register scheme used to protect user process from each other, and from changing operating system code and data\n\n\nallocation types\n\n\nfixed partitions\n\n\nmemory is divided into n partitions at the startup time and altered later on\n\n\neach partition may contain exactly only one process\n\n\neach partition may have a job queue. Or, all partitions share the same job queue\n\n\n\n\n\n\nvariable partitions\n\n\nhole\n\n\nwhen a process arrives, it is allocated memory from a hole large enough to accommodate it\n\n\nthe partition sized are not fixed\n\n\nos maintains maintains information about\n\n\nallocated partitions\n\n\nfree partitions\n\n\n\n\n\n\nFirst fit\n\n性能较好\n\n\n\nBest fit\n\n使用率最优\n\n\n\nworst fit\n\n烂差\n\n\n\nexternal fragmentation: hole\n\nexternal fragmentation problem exists when there is enough total free memory space to satisfy a request, but the available spaces are not contiguous\ncompaction(一般不用 ,开销较大)\npermitting the physical address space of the processes to be noncontiguous\n\npaging and segmentation\n\n\n\n\n\ninternal fragmentation\n\n\n\n\n\n\n\n\n\n\n\n\npaging\n\n\nphysical memory: pages\n\n\nlogical memory: frames\n\n\npage table\n\nkeep track of all free frames\nto run a program of size n pages, need to find n free frames and load program\nStill have internal Fragmentation\n\n\n\naddress generated by CPU can be divided into\n\n\nPage number§\n\nbase address of each page\n\n\n\nPage offset(d)\n\n\na 2m space logical address\n\n\n\npage number\npage offset\n\n\n\n\np\nd\n\n\nm-n\nn\n\n\n\n\n\n\n\n\n\n\nmost allocate a page table for each process\nin the simplest case, the page table is implemented as a set of dedicated registers\nThe use of registers is fit for the small page tables and not is fit for the large page tables\npage table is kept in main memory\npage-table base register(PTBR) points to the page table\nrequire two memory accesses, one for page table and another for memory\n\n\n\nImplementation of page table(TLB)\n\n\nthe two memory access problem can be solved by the use of special fast-lookup hardware\n\nassociative memory or translation look-aside buffer\n\n\n\n\npage#\nframe#\n\n\n\n\nxxx\nxxx\n\n\n\n\n\nif page# is in associative register, get frame# out. Else, get frame# from page table\n\n\n\n\n\n\n\n\n\n\nsome TLBs store address-space identifiers (ASIDs) in each TLB entry to provide address space protection for process\n\n\nEffective Access Time\n\n\nHit ratio(命中率)(assume memory cycle time is 1 microsecond)\n\n\n\nα\\alphaα\nhit ratio\n\n\n\n\nε\\varepsilonε time unit\nTLB lookup\n\n\neffective access time(EAT)\n(1+ε)α+(2+ε)(1−α)=2+ε−−α(1+\\varepsilon)\\alpha+(2+\\varepsilon)(1-\\alpha)=2+\\varepsilon--\\alpha(1+ε)α+(2+ε)(1−α)=2+ε−−α\n\n\n\n\n\n\n\nMemory protection\n\npage table length register(PTLR) stores the length of a process’s page table\nread-only,read-write,or execute bits(r-w-e permission)\n\n\n\nShared pages\n\n\nshare common code\n\n\none copy of read-only code for many process they need\n\n\n\n\n\n\nstructure of page table\n\n\nHierarchical paging(分层)\n\n\ncommon in 32 bits\n\n\ntwo-level page table\n\n\na logical address is as follows\n\n\n\n\np1 is an index into the outer page table, and p2 is the displacement within the page of the outer page table(页目录表)\n\n\n\n\n\n\nthree-level paging scheme\n\n\n\n\n\n\n\n\n\n\nhashed page tables\n\n\ncommon in address spaces &gt; 32 bits\n\n\nThe virtual page number is hashed into a page table.\n\n\n\n\n\n\ninverted page tables\n\n\nOne entry for each real frame of memory.\n\n\nEntry consists of the virtual address of the page stored in that real memory location, with information about the process that owns that page.\n\n\nDecreases memory needed not to store each page table, but increases time needed to search the table when a page reference occurs.\n\n\nUse hash table to limit the search to one or at most a few page-table entries.\n\n\n\n\n\n\n\n\nsegmentation\n\n\na program is a collection of segments. A segment is a logical unit such as\n\n\nmain program, procedure, function , method, object, object, local variables, global variables, common block, stack, symbol table, arrays\n\n\nlogical address consists of &lt;segment-number,offset&gt;\n\n\nsegment table\n\n\nbase\n\n\nlimit\n\n\n\n\nvalidation bit = 0 → illegal segment\n\n\nread/write/execute privileges\n\n\n\n\n\n\n\n\n\n\n Chapter 9 Virtual Memory\n\n\nbackground\n\nlogic address space can be larger than physical address space\nshares library using virtual memory\ncopy on write\n\nprocess creation\ncopy on write(COW) allows both parent and child processed to initially share the same pages in memory\nif either process modifies a shared page, then only the page is copied\nCOW allows more efficient process creation as only are copied\nfree pages are allocated from a pool of zeroed-filled pages\n\n\n\n\n\ndemand paging\n\n\nbring a page into memory only when it is needed\n\nless I/O needed\nless memory needed\nfaster response\nmore users\n\n\n\npage is needed → reference to it\n\ninvalid reference → abort\nnot in memory → bring to memory\n\n\n\nLazy swapper(Pager)\n\n\nvalid-invalid bit\n\n1- valid and in memory\n0- invalid or not in memory(default)\n\n\n\npage fault\n\n\ninvalid reference &gt; abort\n\n\njust not in memory\n\n\nget empty frame\n\n\nswap page into farame\n\n\nreset tables validation bit = 1\n\n\nrestart instruction\n\n\n\npage fault rate p\np==0, no page faults\np==1, every reference is a fault\nEffective Access Time(EAT)\n\nEAT=(1−p)×memory access time+p(page fault overhead)EAT = (1-p)\\times memory\\ access\\ time + p(page\\ fault\\ overhead)EAT=(1−p)×memory access time+p(page fault overhead)\npage faultoverhead=service the page=fault interrupt+[swap page out]+swap page in+restart overheadpage\\ fault overhead = service  \\ the \\ page = fault \\  interrupt+[swap\\ page\\ out]+swap\\ page\\ in+restart\\ overheadpage faultoverhead=service the page=fault interrupt+[swap page out]+swap page in+restart overhead\n\n\n\n\n\n\n\n\n\npage replacement\n\nlarge virtual memory can be provided on a smaller physical memory\nsame pages may be brought into memory several times\n\n\n\nbasic page replacement\n\nfind a free frame and use it\nif no frame free, use a page replacement algorithm to select a victim frame\nwrite the victim frame to the disk and change the page and frame tables\nread the desired page into the free frame. Update the page and frame tables\nrestart the process\nuse modify bit to reduce overhead of page transfers(if not modified,not write)\nlowest page fault rate\n\n\n\nAlgorithm\n\nFIFO first in first out\nLRU least recently used\nLRU approximation algorithms\n\nsecond chance algorithm\nclock replacement(FIFO)\nif the page to be replaced has reference bit = 1.then\n\nset reference bit 0\nleave page in memory\nreplace next page, subject to same rules\n\n\nReference bit\n\ninitially = 0\nreferenced bit =1\nreplace the one which bit is 0\n\n\nkeep a counter of the number of references that have been made to each page\nLFU\n\nreplace pages with smallest count\n\n\nMFU\n\nbased on the argument that the page with the smallest count was probably just brought in and has yet to be used\n\n\n\n\nOPT 最佳置换算法\n\n\n\nallocation of frames\n\nFixed allocation\n\nequal allocation\nproportional allocation\n\nallocation according to the size of the process\nsi = size of process pi\ns=∑\\sum∑si\nm=total number of frames\nai = allocation for pi = sis×m\\frac{s_i}{s}\\times mssi​​×m\n\n\n\n\npriority allocation\n\nuse a proportional allocation scheme using priorities rather than size\nif process pi generates a page fault\n\nselect for replacement one of its frames\nselect for replacement a frame from a process with lower priority numebr\n\n\nGlobal or local allocation\n\nglobal\n\nselect from all frames\n\n\nlocal\n\nselect from its own set\n\n\n\n\n\n\n\n\n\nthrashing(颠簸)\n\n\n\n\n\n\nif a CPU does not have “enough” frames, the page fault rate is very high\n\nlow CPU utilization\noperating system thinks that it needs to increase the degree of multiprogramming\nanother process is added to the system\n\n\n\nA process is busying swapping pages in and out\n\n\nWhy does paging work\n\nlocality model\n\na locality is a set of pages that are actively used together\nprocess migrates form one locality to another\nlocalities may overlap\n\n\n\n\n\nwhy does the trashing occur\n\nsize of locality &gt; allocated memory size\n\n\n\nWorking set model\n\n\nΔ ≡ working-set window ≡ a fixed number of page references\n\n\nWSSi (Working set of process Pi)\n\n\nto small not encompass entire loclity\n\n\nto large encompass several localities\n\n\n∞ encompass entire program\n\n\n\n\nestablish “acceptable” page fault rate\n\n\n\n\nmemory-mapped files\n\n\nallocation-mapped files\n\n\nallocating kernel memory\n\n\ntreated different form user memory\n\n\noften allocated from a free-memory pool\n\nkernel requests memory for structures of varying sizes\nsome kernel memory needs to be contiguous\n\n\n\nbuddy system\n\n\n\n\nslab allocator\n\n\n\n\n\n\nother consideration\n\nprepaging\npage size\n\nfragmentation ,small page\ntable size, large page\nI/O overhead, large page\nlocality, small page\nTLB reach = TLB size x page size\n\nmultiple page size\n\n\nprogram structure\nI/O interlock\n\n\n\n\n\noperating system examples\n\n\n Chapter 10 File system interface\n\n\nfile concept\n\n\na file is a named collection of related information that is recorded on secondary storage\n\n\ncontiguous logical address space\n\n\nfile structure\n\nsimple record structure\n\nlines\nfixed length\nvariable length\n\n\ncomplex structures\n\nformatted document\nrelocatable load file\n\n\n\n\n\narrributes\n\nname\nldentifier\ntype\nlocation\nsize\nprotection\ntime,date, and user identification\ninformation about file are kept in the directory structure, which is maintained on the disk\n\n\n\noperation\n\ncreate\nwrite\nread\nreposition within file - file seek\ndelete\ntruncate (截短)- erase the contents of a file but keep its arrtibutes\nopen\nclose\ninternal tables\n\nper-process open file table\nsystem-wide open file table\n\n\n\n\n\naccess methods\n\n\nsequential access\n\nrewind/read/wrire\n\n\n\ndirect access\n\n\n\n\ndirectory structure\n\ndisks are split into on or more partitions\neach partition contains information about files within it\nthe information is kept in entries in a device directory or volume table of contents\n\n\n\noperation performed on directory\n\nsearch for a file\ncreate a file\ndelete a file\nlist a directory\nrename a file\ntraverse the file system\n\n\n\norganize the file directory(Logically) to obrain\n\nefficiency = locating a file quickly\nnaming -convenient to users\n\ntwo users can have same for different files\nthe same file can have several different name\n\n\ngrouping - logical grouping of files by properties\n\n\n\nDirectory\n\n\nPr\n\nnaming\ngrouping\npathname\nsame file for different user\nefficient searching\ngrouping capability\n\n\n\nsingle level directory\n\n\n\n\ntwo level directory\n\n\nseparate directory for each user\n\n\n\n\n\n\nTree structured directories\n\n\n\n\nefficient searching\n\n\ngrouping capability\n\n\ncurrent directory( working directory )\n\n\nabsolute / relative path name\n\n\ncreating a new file is done in current directory\n\n\ndelete a file\n\n\nmkdir\n\n\nacyclic graph directories\n\n\nshared subdirectories and files\n\n\ntwo different names(aliasing)\n\n\nif dict deletes count &gt; dangling pointer\n\n\nsolutions\n\nbackpointers, so we can delete all pointers\nentry hold count solution\n\n\n\n\n\n\n\nhow to guarantee no cycles\n\nallow only links to file not subdirections\ngarbage collecton\nevery time a new link is added use a cycle detection algorithm to determine whether it is OK\n\n\n\n\n\n\n\n\n\nfile system mounting\n\na file system must be mounted before it can be accessed\nan unmounted file system is mounted at a mount point\n\n\n\nfile sharing\n\nsharing of files on multi-user system is desirable\nsharing may be done though a protection scheme\non distributed systems, files ay be shared across a network\nnetwork file system(NFS) is a common distributed file sharing method\n\n\n\nprotection\n\nowner / creator control\n\nwhat can be done by whom\n\n\ntype of access\n\nread\nwrite\nexecute\nappend\ndelete\nlist\n\n\n\n\n\n Chapter 11 File system implementation\n\n\nfile system structure\n\nfile structure\n\nlogical storage unit\ncollection of related information\n\n\nfile system resides on secondary storage(disks)\nfile system organized into layers\napplication programs &gt; logical file system &gt; file-organization module &gt; basic file system &gt; I/O control &gt; devices\n\n\n\nfile system implementation\n\n\nfile control block\n\nfile permissions\nfile dates\nfile owner, group, ACL\nfile size\nfile data blocks or pointers to file data blocks\n\n\n\nin memory file system structures\n\n\n\n\nvirtual file systems\n\nvirtual file system(VFS) provide an object oriented way of implementing file systems\nVFS allows the same system call interface (API) to be used for different types of file systems\nThe API is to the VFS interface, rather than any specific type of file system\n\n\n\n\n\ndirectory implementation\n\nlinear list of file names with pointer to the data blocks\n\nsimple to program\ntime consuming to exectute\n\n\nHash table - linear list with hash data structure\n\ndecreases directory search time\ncollisions - situations where two file names hash to the same location\n\n\n\n\n\nallocation methods\n\n\nan allocation method refers to how disk blocks are allocated for files\n\n\ncontiguous allocation\n\n\nsimple\n\n\nrandom access (sequential direct)\n\n\nwasteful of space (dynamic storage allocation problem)\n\n\nfiles cannot grow\n\n\n\nextent-based systems\n\nmany newer file system use a modified contiguous allocation scheme\nextent-based file systems allocate disk blocks in extents\nan extent is a contiguous block of disks\n\nextents are allocated for file allocation\na file consists of one or more extents\n\n\n\n\n\n\n\n\n\nlinked allocation\n\n\neach file is a liked list of disk blocks\n\n\nblocks may be scattered anywhere on the disk\n\n\nsimple\n\n\nno waste of space\n\n\nfiles can grow\n\n\nno random access\n\n\neach block contains a pointer, wasting space\n\n\nblocks scatter everywhere and a large number of disk seeks may be necessay\n\n\nreliability - if a pointer is lost or damaged?\n\n\n\n\nfile allocation table\n\n\n\n\n\n\n\n\nindexed allocation\n\n\nbring all pointers together into the index block\n\n\na file’s directory entry contains a pointer to its index. Hence, the index block of an indexed allocation plays the same role as the page table\n\n\n\n\nrandom access\n\n\nthe indexed allocation suffers from wasted space. The index block may not be fully used\n\n\nthe number of entries of an index table determines the size of a file\n\nOvercome\n\nmultiple index blocks, chain them into a inked list\nmultiple index blocks, but make them into a tree just like the indexed access method(multilevel)\na combination of both\n\n\n\n\n\n\n\n\n\n\n\nfree space management\n\n\nfree space list\n\n\nbit vector\n\n\n\n\nblock number calculation\n= number of bits per word *\nnumber of 0-value words +\noffset of first 1 bit\n\n\nrequires extra space\n\n\neasy to get contiguous files\n\n\n\n\nlinked list\n\n\ncannot get contiguous space easily\n\n\nno waste of space\n\n\n\n\n\n\ngrouping\n\n\n\n\naddress counting\n\n\nto make list short with the following trick\n\n\nblocks are often allocated and freed in groups\n\n\nfor every group, we can store the address of the first free block and the number of the following n free blocks\n\n\n\n\n\n\n\n\nlinked list + grouping\n\n\nlinked list + address + count\n\n\n\n\n\n\nefficiency and performance\n\nefficiency dependent on\n\ndisk allocation and directory management algorithms\ntype of data kept in file’s directory entry\n\n\nperformance\n\ndisk cache\nfree-behind and read-ahead (optimize sequential access)\nvirtual disk, ram disk , etc.\n\n\npage cache\n\n\n\nrecovery\n\nconsistency checking\nback up data from disk to another\nrecover lost file or disk by restoring data from backup\n\n\n\nlog structured file systems (审计和统计)\n\nrecord each update to the file system as a transaction\nall transactions are written to a log\n\n\n\nNFS\n\nnetwork file system\n\n\n\n Chapter 12 mass storage structure\n\n\ndisk structure\n\n\nmagnetic disks provide bulk of secondary storage of modern computers\n\ntransfer rate\n\ndata flow between drive and computer\n\n\npositioning time\n\nrandom access time\n\ntime to move disk arm to desired cylinder (seek time) and time for desired sector to rotate under the disk head (rotational latency)\nhead crash results from disk head making contact with the disk surface\n\n\n\n\ndisk can be removeable\nattached to computer via I/O bus\n\nhost controller in computer uses bus to talk to disk controller built into drive or storage array\n\n\nlogical blocks\n\nsector 0 outmost\nfrom outmost to inner most\n\n\n\n\n\n\n\ndisk attachment\n\nhost attached via an I/O port\nnetwork attached via a network connection\n\n\n\ndisk scheduling\n\n\naccess time\n\nseek time\nrotational latency\n\n\n\ndisk bandwidth\n\nthe total number of bytes transferred, divided by the total time between the first request for service and the completion of the last transfer\n\n\n\nFCFS\n\n\nSSTF(shortest seek time first)\n\n\nmay cause starvation of some requests\n\n\nSCAN - elevator algorithm\n\n\nC-SCAN\n\n\nprovide a more uniform wait time than SCAN\n\n\n\n\n\n\nC-LOOK\n\n\n\n\nSSTF is common and has natural appeal\n\n\nSCAN and C-SCAN perform better for systems that place a heavy load on the disk\n\n\neither SSTF or LOOK is a reasonable choice for the default algorithm\n\n\nperformance depends on the number and types of reuests\n\n\nrequests for disk service can be influences by the file-allocation method\n\n\n\n\ndisk management\n\n\ndisk formatting\n\n\nlow-level formatting, of physical formatting\n\n\ndividing a disk into sectors that the disk controller can read and write\n\n\n\n\npartition\n\n\nlogical formatting\n\nmaking a file system\n\n\n\n\n\n\n\nboot block\n\n\nboot block initializes system\n\n\nthe bootstrap is stored in ROM\nbootstrap loader program\n\n\n\n\n\n\n\n\nError handling\n\n\na disk track with a bad sector\n\n\nsubstituting a spare for the bad sector\n\n\nshifting all the sectors to bypass the bad one\n\n\n\n\n\n\n\n\nswap space management\n\nswap space\n\nswap space can be carved out of the normal file system, or, more commonly, it can be in a separate disk partition\n\n\n\n\n\nRAID structure\n\n\nRedundant Array of Independent Disk (冗余磁盘阵列)\n\n\nimproves reliability via redundancy and performance via parallelism\n\n\nraid is arranged into dix different levels\n\n\n\n\n\n\nstable storage implementation\n\n\ntertiary storage devices\n\n\n​\n","plink":"hanyuulu.github.io/OS/"},{"title":"高级数据结构复习","date":"2019-06-10T19:59:55.000Z","updated":"2021-03-12T08:22:58.378Z","content":" 平摊分析与基本思路\n Aggregate method （聚集分析）\n Potential Function\nP(i)=amortizedCost(i)−actualCost(i)+P(i−1)P(i)=amortizedCost(i)-actualCost(i)+P(i-1)P(i)=amortizedCost(i)−actualCost(i)+P(i−1)\n∑(P(i)−P(i−1))=∑(amortizedCost(i)−actualCost(i))\\sum(P(i)-P(i-1))=\\sum(amortizedCost(i)-actualCost(i))∑(P(i)−P(i−1))=∑(amortizedCost(i)−actualCost(i))\nP(n)−P(0)=∑(amortizedCost(i)−actualCost(i))P(n)-P(0)=\\sum(amortizedCost(i)-actualCost(i))P(n)−P(0)=∑(amortizedCost(i)−actualCost(i))\nP(n)−P(0)≥0P(n)-P(0)\\geq 0P(n)−P(0)≥0\nWhen P(0)=0,P(i) is the amount by which the first i operations have been over charged\n Accounting method (记账分析)\nGuess that the amortized cost of an increment is 2\nNow show that P(m)-P(0) &gt;= 0 is all for m\n1st increment:\n\none unit of amortized cost is used to pay for the change in bit 0 from 0 to 1\nthe other unit remains as a credit on bit and is used later to pay for the time when bit 0 changes form 1 to 0\n\nnthcreament\n​\t…\nP(m)−P(0)=∑(amotyizedCost(i)−actualCost(i))P(m)-P(0)=\\sum(amotyizedCost(i)-actualCost(i))P(m)−P(0)=∑(amotyizedCost(i)−actualCost(i))\n= amount by which the first m increments have been over charged\n=number of credits\n= number of 1s\n≥0\\geq 0≥0\n Potential method (势能法)\nGuess a suitable potential funciton for whtich P(n)−P(0)≥0P(n)-P(0) \\geq 0P(n)−P(0)≥0 for all n\nDerive amortized cost for ith operation usting ΔP=P(i)−P(i−1)=amortizedCost−actualCost\\Delta P = P(i)-P(i-1)=amortizedCost  - actualCostΔP=P(i)−P(i−1)=amortizedCost−actualCost\namortizedCost=acutalCost+ΔPamortizedCost  = acutalCost + \\Delta PamortizedCost=acutalCost+ΔP\n 数据结构、二叉树与树\n\n\nArbitrary Ordered Trees\n\n\nUse parenthesis notation to represent the tree\n\n\nAs the binary string(((())())((())()())): traverse tree as “(“ for node, then subtrees, then “)”\n\n\n2 Bits per node\n\n\n\n\n\n\nHeap-like notation\n\n\n\n\nOrded threes\n\nparent\nfirst child\nnext sibling\ndegree\nsubtree size\n\n\n\nLevel-order degree sequence\n\n\n\n\n 外排序\n 缓冲使用策略，原因和方法\n\n\nReason\n\n\nnot feasible to input n records, sort and output in sorted order\n\n\nALU-main memory-disk\n\n\nprefetch\n\n\n\n\n3 input/output buffers\n\ninput, small, large\nmiddle\nfill middle group from disk\nif next record ≤\\leq≤ middle-min- send to small\nif next record ≥\\geq≥ middle-max- send to large\nelse remove middle-min- or middle-max from middle and add new record to middle group\nfill input buffer when it gets empty\nwrite small/large buffer when full\nwrite middle group in sorted order when done\ndouble-ended priority queue\n\n\n\nInternal Merge Sort\n\ncreate initial sorted segments\nmerge pairs of sorted segmetns in merge passes, until only 1 segment remains\n\n\n\nExternal Merge Sort\n\nrun generation\n\na run is a sorted sequence of records\n\n\nrun merging\n\n\n\nRun generation\n\nloser tree\n\n\n\nTournament Trees\n\n\nHuffman trees\n\n\nDouble-ended priority queues\n\n\nBuffering\n\n\n 红黑树\n 最小最大堆\n 插入\n只需要将节点插在二叉树的最后一个叶子结点位置，然后比较它对它父亲节点的大小，如果大则停止；如果小则交换位置，然后对父亲节点递归该过程直至根节点。复杂度为O(log(n))O(log(n))O(log(n))。\n一般来说，插入的位置可以不是最后一个叶子节点，可以作为任意中间节点的孩子节点插入，将这个叶子节点变为中间节点后，按上文所说的方法调整节点顺序以保证维持堆特性不变。\n 删除\n要从堆中删除一个节点，用最后一个节点替换掉要删除的节点，然后调整节点顺序以维持堆特性。\n 设计数据结构与算法\n Review\n\nAmoritized analysis\nSuccinct data structures\nFunction for bit vectors\n\nBInary trees\nOrdered tree\n\n\nString matching\n\nBM\n\n\nDouble ended priority\nExternal Sort\n\nbuffer management\n\n\nRed-black trees\naugmenting data structures\n\n","plink":"hanyuulu.github.io/AdvancedDataStructures/"},{"title":"Win32 API 银行家算法的实现","date":"2019-05-26T00:00:00.000Z","updated":"2021-03-12T08:22:58.382Z","content":"\nPs:就是拿自己写的报告\n\n一、基本信息\n\n\n\n实验题目\n完成人姓名\n学号\n报告日期\n\n\n\n\n银行家算法的实现\nHanyuu\nNone\n2019/0525\n\n\n\n 二、实验目的\n通过实验，加深对多实例资源分配系统中死锁避免方法——银行家算法的理解，掌握 Windows 环境下银行家算法的实现方法，同时巩固利用 Windows API进行共享数据互斥访问和多线程编程的方法。\n 三、实验内容\n\n在 Windows 操作系统上，利用 Win32 API 编写多线程应用程序实现银行家算法。\n创建 n 个线程来申请或释放资源，只有保证系统安全，才会批准资源申请。\n通过 Win32 API 提供的信号量机制，实现共享数据的并发访问\n\n 四、实验步骤，主要数据结构和说明\n 设计思路\n 设计\n\n\n系统的各种资源类型被收纳在ResourceRow中，每个程序都有自己的allocation，max，need的resourceRow对象以表示其对应资源的数量。Container为每个注册的进程分配一个全局唯一的pid。启动进程通过调用start函数调起running工作线程。Container保持对资源的调配，所有线程需要资源都要向container发起请求，使用完毕后要向container声明释放资源。\n 流程图\n123456789101112Process-&gt;Container:Register processnote left of Process:Initialize the containerProcess-&gt;Container:Register max,allocatedNote left of Process:Request some resourcesProcess-&gt;Container:Request some resourcesContainer-&gt;ResourceCols:Check if the resource remained\\n is enough to support all processResourceCols-&gt;Container:Return the resultsContainer-&gt;ResourceCols:Modify the resource listContainer-&gt;Process:Return the results of \\nthe request(Permit/Forbid)Note left of Process:Relsase some resourcesProcess-&gt;Container:Testify the release of the resourceContainer-&gt;ResourceCols:Modify the resource list\n五、程序运行的结果\n\n\n 六、实验体会\n构建一个相对完整的运行体系比纯粹实现一个单独的功能相对要复杂不少。但是拥有良好的可扩展性和易于修改的特性。\n 七、源代码\nProcessRow.h\n123456789101112131415161718192021222324252627282930313233343536#pragma once#include&lt;string&gt;#include&lt;sstream&gt;const unsigned ROW_COUNT = 4;const unsigned MAX_PROCESS = 512;struct ResourceRow&#123;public:\tunsigned res[ROW_COUNT];\tResourceRow()\t&#123;\t\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t\t&#123;\t\t\tres[i] = 0;\t\t&#125;\t&#125;\tResourceRow(unsigned* input)\t&#123;\t\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t\t&#123;\t\t\tres[i] = input[i];\t\t&#125;\t&#125;\tstd::string str()\t&#123;\t\tstd::stringstream res;\t\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t\t&#123;\t\t\tres &lt;&lt; this-&gt;res[i] &lt;&lt; \" \";\t\t&#125;\t\treturn res.str();\t&#125;&#125;;bool operator&gt;=(const ResourceRow&amp; a, const ResourceRow&amp; b);\nProcessRow.cpp\n12345678910#include\"resourceRow.h\"bool operator&gt;=(const ResourceRow&amp; a, const ResourceRow&amp; b)&#123;\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tif (a.res[i] &lt; b.res[i])\t\t\treturn false;\t&#125;\treturn true;&#125;\nProcessCol.h\n123456789101112131415161718192021222324252627#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;\nProcessCol.cpp\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;#pragma once#include &lt;process.h&gt;#include &lt;Windows.h&gt;#include\"resourceRow.h\"//#include \"Container.h\"//#include \"banker.h\"//extern const unsigned ROW_COUNT = 4;//extern const unsigned MAX_PROCESS = 512;//extern HANDLE mutex;//extern HANDLE Rmutex;//extern class Container;//extern Container* container;class ProcessCol&#123;public:\tunsigned pid;\tResourceRow allocation;\tResourceRow max;\tResourceRow need;\tstatic DWORD WINAPI running(LPVOID lpThreadParemeter);\tHANDLE start();\tProcessCol(unsigned pid);\tProcessCol();&#125;;\nContainer.h\n12345678910111213141516#pragma once#include\"processCol.h\"class Container&#123;public:\tProcessCol list[MAX_PROCESS];\tunsigned processCount;\tResourceRow avilable;\tvoid print();\tContainer();\tbool pushProcess(ProcessCol* process);\tvoid release(unsigned pid);\tvoid requests(unsigned pid, ResourceRow request);&#125;;\nContainer.cpp\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#pragma once#include&lt;iostream&gt;#include\"Container.h\"Container* container;extern HANDLE mutex;extern HANDLE Rmutex;void Container::print()&#123;\tstd::cout &lt;&lt; \"[avilable]\" &lt;&lt; avilable.str() &lt;&lt; std::endl;\tfor (unsigned i = 0; i &lt; processCount; ++i)\t&#123;\t\tstd::cout &lt;&lt; list[i].pid &lt;&lt; \"    \" &lt;&lt; list[i].allocation.str() &lt;&lt; \"    \" &lt;&lt; list[i].max.str() &lt;&lt; \"    \" &lt;&lt; list[i].need.str() &lt;&lt; std::endl;\t&#125;\tstd::cout &lt;&lt; std::endl;&#125;Container::Container()&#123;\tprocessCount = 0;\tmutex = CreateSemaphore(nullptr, 1, 1, nullptr);\tRmutex = CreateSemaphore(nullptr, 1, 1, nullptr);\t//for (unsigned i = 0; i &lt; MAX_PROCESS; ++i)\t//&#123;\t//\tlist[i] = nullptr;\t//&#125;&#125;bool Container::pushProcess(ProcessCol* process)&#123;\tif (processCount &gt;= MAX_PROCESS - 1)\t&#123;\t\treturn false;\t&#125;\tprocess-&gt;pid = processCount;\tlist[processCount] = *process;\tprocessCount += 1;\treturn true;&#125;void Container::release(unsigned pid)&#123;\tWaitForSingleObject(mutex, INFINITE);\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tavilable.res[i] += list[pid].allocation.res[i];\t\tlist[pid].allocation.res[i] = 0;\t\tlist[pid].need.res[i] = list[pid].max.res[i];\t&#125;\tstd::cout &lt;&lt; \"pid: \" &lt;&lt; pid &lt;&lt; \" 已释放\" &lt;&lt; std::endl;\tcontainer-&gt;print();\tReleaseSemaphore(mutex, 1, nullptr);&#125;void Container::requests(unsigned pid, ResourceRow request)&#123;\tWaitForSingleObject(mutex, INFINITE);\tResourceRow newAvilable;\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tnewAvilable.res[i] = avilable.res[i];\t&#125;\tunsigned count = this-&gt;processCount;\tbool* flag = new bool[count];\tfor (unsigned i = 0; i &lt; count; ++i)\t&#123;\t\tflag[i] = false;\t&#125;\twhile (count &gt; 0)\t&#123;\t\tbool key = false;\t\tfor (unsigned i = 0; i &lt; this-&gt;processCount; ++i)\t\t&#123;\t\t\tif (flag[i] == false)\t\t\t&#123;\t\t\t\tif (newAvilable.res &gt;= list[i].need)\t\t\t\t&#123;\t\t\t\t\tfor (unsigned j = 0; j &lt; ROW_COUNT; ++j)\t\t\t\t\t&#123;\t\t\t\t\t\tnewAvilable.res[i] += list[i].allocation.res[i];\t\t\t\t\t&#125;\t\t\t\t\tflag[i] = true;\t\t\t\t\tkey = true;\t\t\t\t\tcount -= 1;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tif (count == 0)\t\t&#123;\t\t\tstd::cout &lt;&lt; \"pid: \" &lt;&lt; pid &lt;&lt; \" 请求成功\" &lt;&lt; std::endl;\t\t\tfor (unsigned i = 0; i &lt; ROW_COUNT; ++i)\t\t\t&#123;\t\t\t\tlist[pid].allocation.res[i] += request.res[i];\t\t\t\tlist[pid].need.res[i] -= request.res[i];\t\t\t\tavilable.res[i] -= request.res[i];\t\t\t&#125;\t\t\tcontainer-&gt;print();\t\t\tReleaseSemaphore(mutex, 1, nullptr);\t\t\treturn;\t\t&#125;\t\tif (key == false)\t\t&#123;\t\t\tstd::cout &lt;&lt; \"pid: \" &lt;&lt; pid &lt;&lt; \"请求失败\" &lt;&lt; std::endl;\t\t\tcontainer-&gt;print();\t\t\tReleaseSemaphore(mutex, 1, nullptr);\t\t\treturn;\t\t&#125;\t&#125;\tfor (int i = 0; i &lt; ROW_COUNT; ++i)\t&#123;\t\tavilable.res[i] -= request.res[i];\t\tlist[pid].allocation.res[i] += request.res[i];\t\tlist[pid].need.res[i] = list[pid].max.res[i] - list[pid].allocation.res[i];\t&#125;\t//ReleaseSemaphore(mutex, 1, nullptr);&#125;\nBanker.h\n1234567891011#pragma once#include &lt;iostream&gt;#include &lt;Windows.h&gt;#include &lt;process.h&gt;#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;string&gt;#include &lt;sstream&gt;#include &lt;time.h&gt;#include\"Container.h\"#include\"processCol.h\"\nBanker.cpp\n123456789101112131415161718192021222324#include\"banker.h\"extern Container* container;int main()&#123;\tsrand((int)time(0));\tcontainer = new Container();\tfor (unsigned i = 0; i &lt; 4; ++i)\t\tcontainer-&gt;pushProcess(new ProcessCol());\tcontainer-&gt;avilable.res[0] = 10;\tcontainer-&gt;avilable.res[1] = 10;\tcontainer-&gt;avilable.res[2] = 20;\tcontainer-&gt;avilable.res[3] = 9;\tHANDLE* hdl = new HANDLE[container-&gt;processCount];\tfor (unsigned i = 0; i &lt; container-&gt;processCount; ++i)\t&#123;\t\thdl[i] = container-&gt;list[i].start();\t&#125;\tfor (unsigned i = 0; i &lt; container-&gt;processCount; ++i)\t&#123;\t\tWaitForSingleObject(hdl[i],INFINITE);\t&#125;\tSleep(40000);&#125;\n","plink":"hanyuulu.github.io/BankersAlgorithm/"},{"title":"生产者消费者问题解决（windows API和Pthread双解决方案）","date":"2019-05-09T00:00:00.000Z","updated":"2021-03-12T08:22:58.534Z","content":"\nPs:就是拿自己写的报告\n\n 一、实验目的\n通过实验，掌握Windows 和 Linux 环境下互斥锁和信号量的实现方法，加 深对临界区问题和进程同步机制的理解，同时熟悉利用Windows API 和 Pthread API 进行多线程编程的方法\n 二、实验内容\n\n在Windows 操作系统上，利用 Win32 API 提供的信号量机制，编写应用\n程序实现生产者——消费者问题。\n在 Linux 操作系统上，利用 Pthread API 提供的信号量机制，编写应用程\n序实现生产者——消费者问题。\n两种环境下，生产者和消费者均作为独立线程，并通过 empty、full、mutex 三个信号量实现对缓冲进行插入与删除。\n通过打印缓冲区中的内容至屏幕，来验证应用程序的正确性。\n\n 三、实验环境\n\n\nwindows 10 1903\n\n\nWindows API\n\nVisual Studio 2019\n\n\n\nPthread API\n\n\nWIndows Subsystem for Linux\n\n\nUbuntu 4.4.0-18362-Microsoft #1-Microsoft Mon Mar 18 12:02:00 PST 2019 x86_64 x86_64 x86_64 GNU/Linux\n\n\ng++ 7.4.0\n\n\nGNU gdb 8.1.0.20180409-git\n\n\nvisual studio code 1.33.1\n\n\n\n\n\n\n 四、实验步骤\n\n\n思路\n\n\nShared data\n\nSemaphore\n\nfull\t//指示缓冲区中已有内容数目，防止消费者尝试从空的缓冲区中读取内容\nempty //指示缓冲区中可用内容数目，方式生产者尝试向已满的缓冲区中存放内容\nmutex //访问锁，保证同一时刻至多只有一个用户在访问buffer\n\n\ninitially\n\nfull=0\nempty = n\nmutex = 1\n\n\n\n\n\nProducer Process\n123456789do&#123;  // Produce an item in nextp  wait(empty);  wait(mutex);  // add nextp to buffer  signal(mutex);  signal(full);&#125;while(1);\n\n\nConsumer Process\n12345678do&#123;  wait(full);  wait(mutex);  // remove nextp to buffer  signal(mutex);  signal(empty);&#125;while(1);\n\n\n\n\n 五、主要数据结构及说明\n\n信号量\n\nfull\n\n指示缓冲区中已有内容数目，防止消费者尝试从空的缓冲区中读取内容\n\n\nempty\n\n指示缓冲区中可用内容数目，方式生产者尝试向已满的缓冲区中存放内容\n\n\nmutex\n\n访问锁，保证同一时刻至多只有一个用户在访问buffer\n\n\n\n\n缓冲区\n\n实现结构\n\n定长数组\n\n\n逻辑结构\n\n循环队列\n\n\n\n\n\n 六、程序运行的初值和运行结果\n\n\nWindows API\n\n\n初值\n\n\n\n\n运行结果\n\n\n\n\n\n\nPthread API\n\n初值\n\n\n\n\n\n运行结果\n\n\n\n\n\n\n 七、实验体会\n 问题和解决方法\n\nQ\n\ng++编译失败，找不到Pthread链接\n\n\nA\n\n编译路径中不含Pthread,需添加-lpthread\n\n\n\n 体会和收获\n\ng++ gdb多线程调试经验\nwindows API调试Pthread调试经验\n\n 八、源代码\n\n\nsource code\n\n\nwindows API\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;iostream&gt;#include &lt;Windows.h&gt;#include &lt;process.h&gt;#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;constexpr unsigned BUFFER = 10;HANDLE empty;HANDLE full;HANDLE mutex;int in = 0, out = 0;int buffer[BUFFER];void print()&#123;\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tstd::cout &lt;&lt; buffer[i]&lt;&lt;' ';\t&#125;\tstd::cout &lt;&lt; std::endl;&#125;HANDLE WINAPI producer(LPVOID lpParameter)&#123;\tdo\t&#123;\t\tWaitForSingleObject(empty, INFINITE);\t\tWaitForSingleObject(mutex, INFINITE);\t\tbuffer[in] = rand() % BUFFER;\t\tin = (++in) % BUFFER;\t\tstd::cout &lt;&lt; \"product at \" &lt;&lt; in &lt;&lt; std::endl;\t\tprint();\t\tReleaseSemaphore(mutex, 1, nullptr);\t\tReleaseSemaphore(full, 1, nullptr);\t\tSleep(200);\t&#125; while (true);\treturn 0L;&#125;HANDLE WINAPI consumer(LPVOID lpParameter)&#123;\tdo\t&#123;\t\tWaitForSingleObject(full, INFINITE);\t\tWaitForSingleObject(mutex, INFINITE);\t\tbuffer[out] = -1;\t\tout = (out + 1) % BUFFER;\t\tstd::cout &lt;&lt; \"consume at \" &lt;&lt; out &lt;&lt; std::endl;\t\tprint();\t\tReleaseSemaphore(mutex, 1, nullptr);\t\tReleaseSemaphore(empty, 1, nullptr);\t\tSleep(200);\t&#125; while (true);\treturn 0L;&#125;int main()&#123;\tsrand((unsigned)time);\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tbuffer[i] = -1;\t&#125;\tDWORD\tDW;\tempty = CreateSemaphore(nullptr, BUFFER, BUFFER, nullptr);\tfull = CreateSemaphore(nullptr, 0, BUFFER, nullptr);\tmutex = CreateSemaphore(nullptr, 1, 1, nullptr);\tHANDLE p = CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)producer, nullptr, 0L, nullptr);\tHANDLE c = CreateThread(nullptr,0, (LPTHREAD_START_ROUTINE)consumer, nullptr, 0L, nullptr);\tHANDLE p1 = CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)producer, nullptr, 0L, nullptr);\tHANDLE c1 = CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)consumer, nullptr, 0L, nullptr);\tWaitForSingleObject(p, INFINITE);\tWaitForSingleObject(c, INFINITE);\tWaitForSingleObject(p1, INFINITE);\tWaitForSingleObject(c1, INFINITE);\treturn 0;&#125;\n\n\nPthread API\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;time.h&gt;const int BUFFER = 10;sem_t empty, full;pthread_mutex_t mutex;int in = 0;int out = 0;int buffer[BUFFER];void print()&#123;\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tprintf(\"%d \", buffer[i]);\t&#125;\tprintf(\"\\n\");&#125;void *Lproducer(void *arg)&#123;\tdo\t&#123;\t\tsem_wait(&amp;empty);\t\tpthread_mutex_lock(&amp;mutex);\t\tstd::cout &lt;&lt; \"product at \" &lt;&lt; in&lt;&lt;std::endl;\t\tbuffer[in] = rand() % BUFFER;\t\tin = (++in) % BUFFER;\t\tprint();\t\tpthread_mutex_unlock(&amp;mutex);\t\tsem_post(&amp;full);\t\tsleep(1);\t&#125; while (true);\treturn NULL;&#125;void *Lconsumer(void *arg)&#123;\tdo\t&#123;\t\tsem_wait(&amp;full);\t\tpthread_mutex_lock(&amp;mutex);\t\tstd::cout &lt;&lt; \"consumer at\" &lt;&lt; out&lt;&lt;std::endl;\t\tbuffer[out] = -1;\t\tout = (++out) % BUFFER;\t\tprint();\t\tpthread_mutex_unlock(&amp;mutex);\t\tsem_post(&amp;empty);\t\tsleep(1);\t&#125; while (true);\treturn NULL;&#125;int main()&#123;\tfor (int i = 0; i &lt; BUFFER; ++i)\t&#123;\t\tbuffer[i] = -1;\t&#125;\tpthread_t c,c1;\tpthread_t p,p1;\tsem_init(&amp;full, 0, 0);\tsem_init(&amp;empty, 0, BUFFER);\tpthread_create(&amp;c, NULL, Lconsumer, NULL);\tpthread_create(&amp;c, NULL, Lconsumer, NULL);\tpthread_create(&amp;p, NULL, Lproducer, NULL);\tpthread_create(&amp;p, NULL, Lproducer, NULL);\tpthread_join(c, NULL);\tpthread_join(p, NULL);\tpthread_join(c1, NULL);\tpthread_join(p1, NULL);\treturn 0;&#125;\n\n\n\n\n","plink":"hanyuulu.github.io/boundedBuffer/"},{"title":"算法分析与设计","date":"2019-04-24T23:03:06.000Z","updated":"2021-03-12T08:22:58.382Z","content":"[TOC]\n\n课程内容\n\n\n\n\n算法高级理论\nNP完全性理论与近似性算法\n\n\n\n\n高级算法\n随机化算法、线性规划与网络流\n\n\n基础算法\n递归分治、动态规划、贪心算法、回溯与分支限界\n\n\n算法基础理论\n算法分析与问题的复杂性\n\n\n\n Chapter 1 概述\n\n渐近分析记号\n\n渐近上界OOO\n渐进下界Ω\\OmegaΩ\n紧渐进界Θ\\ThetaΘ\n非紧上界ooo\n非紧下界ω\\omegaω\n\n\nO的运算性质\nNP完全性理论\n\nEasy problem\n\n存在多项式时间算法的问题\n\n\nHard problem\n\n需要指数时间算法解决的问题\n\n\n不可解问题\nP&amp;NP\n判定问题\nk确定性算法和P类问题\n\n对于某个判定问题Π，存在一个非负整数k，对于输入规模为n的实例，能够以O(nk)O(n^k)O(nk)的时间运行一个确定性算法，能够判定的问题\n\n\n非确定性算法和NP类问题\n\n对于某个问题Π，存在一个非负整数k，对于输入规模为n的实例，能够以O(nk)O(n^k)O(nk)的时间运行一个非确定性算法，能够判定的问题\n\n\nNP完全问题(NPC问题)\n\n令Π是个判定问题，如果问题Π属于NP问题，并且对NP类问题中的每一个问题Π’，都有Π′∝pΠ\\Pi&#x27;\\propto_p\\PiΠ′∝p​Π，则称问题为NPC问题\n\n\nNP难问题\n\n令Π是个判定问题，如果对于NP类问题中的每一个问题Π’，都有Π′∝pΠ\\Pi&#x27;\\propto_p\\PiΠ′∝p​Π，则称问题为NP难问题\n\n\n\n\n\n Chapter 2\n 递归与分治策略\n\n\n递归\n\n双递归函数\n整数划分问题\nHanoi问题\n迭代法求解\n\n正确性-归纳验证\n数学归纳法\n\n\n优缺点\n\n\n\n分治\n\n特征\n\n\n问题规模缩小到一定程度可以容易地解决\n\n\n最优子结构性质该问题可以分解为若干个规模较小的相同问题\n\n\n利用该问题分解出的子问题的解可以合并为该问题的解\n\n\n子问题相互独立子问题不包含公共子问题\n\n平衡子问题\n\n\n二分搜索\n大整数乘法\n\n\n\n还原迭代法\n\n\n公式法\nT(n)=\n\\begin{equation}\n\\left\\{\n    \\begin{array}{lr}\n    O(1)\\  n = 1 \\\\\n    aT(\\frac{n}{b})+f(n) \\ n&gt;1\n    \\end{array}\n\\right.\n\\end{equation}\n\n基于还原迭代法，可以得到递归方程的解\nT(n)=nlogba+∑i=0logbn−1aif(nbi)T(n)=n^{log_ba}+\\sum_{i=0}^{log_b{n-1}}a^if(\\frac{n}{b^i})\nT(n)=nlogb​a+i=0∑logb​n−1​aif(bin​)\n\n复杂度分析\n\n\n\n递归树法\n\n\n主定理\n\n设a≥1a\\geq1a≥1,b&gt;1b&gt;1b&gt;1是常数，f(n)f(n)f(n)为函数，T(n)T(n)T(n) 为非负数，且T(n)=aT(nb)+f(n)T(n)=aT(\\frac{n}{b})+f(n)T(n)=aT(bn​)+f(n)，则\n\n若f(n)=O(nlogba−ϵ))f(n)=O(n^{log_ba-\\epsilon}))f(n)=O(nlogb​a−ϵ)),存在ϵ&gt;0\\epsilon&gt;0ϵ&gt;0是常数，则有T(n)=Θ(nlogba)T(n)=\\Theta(n^{log_ba})T(n)=Θ(nlogb​a)\n若f(n)=O(nlogba))f(n)=O(n^{log_ba}))f(n)=O(nlogb​a))，则有T(n)=Θ(nlogbalog n)T(n)=\\Theta(n^{log_ba}log\\ n)T(n)=Θ(nlogb​alog n)\n若f(n)=O(nlogba+ϵ))f(n)=O(n^{log_ba+\\epsilon}))f(n)=O(nlogb​a+ϵ))，存在ϵ&gt;0\\epsilon&gt;0ϵ&gt;0是常数，且对所有充分大的n有af(nb)≤cf(n)af(\\frac{n}{b})\\leq cf(n)af(bn​)≤cf(n)，c&lt;1是常数，则有T(n)=Θ(f(n))T(n)=\\Theta(f(n))T(n)=Θ(f(n))\n\n\n\n\n\nStrassen矩阵乘法\n\n\n二分归并排序/合并排序\n\n\n快速排序\n\n\n最接近点对问题\n\n\n\n\n\n\n Chapter 3\n 动态规划\n\n\n最优化问题\n\n\n最优性原理\n\n每一阶段的决策仅依赖前一阶段产生的状态\n最优子结构性质\n\n\n\n解空间、约束条件、可行解、目标函数、最优解、最优化问题\n\n\n重叠子问题\n\n\n无后效\n\n\n找零问题\n\n\n使用表记录所有已经解决的子问题\n\n\n最短路径问题\n\n\n矩阵连乘问题\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//3d1-1 重叠子问题的递归最优解//A1 30*35 A2 35*15 A3 15*5 A4 5*10 A5 10*20 A6 20*25//p[0-6]=&#123;30,35,15,5,10,20,25&#125;#include &quot;stdafx.h&quot;#include &lt;iostream&gt; using namespace std;  const int L = 7; int RecurMatrixChain(int i,int j,int **s,int *p);//递归求最优解void Traceback(int i,int j,int **s);//构造最优解int main()&#123;\tint p[L]=&#123;30,35,15,5,10,20,25&#125;;    int **s = new int *[L];\tfor(int i=0;i&lt;L;i++)      &#123;  \t\ts[i] = new int[L];      &#125; \tcout&lt;&lt;&quot;矩阵的最少计算次数为：&quot;&lt;&lt;RecurMatrixChain(1,6,s,p)&lt;&lt;endl;\tcout&lt;&lt;&quot;矩阵最优计算次序为：&quot;&lt;&lt;endl;\tTraceback(1,6,s);\treturn 0;&#125;int RecurMatrixChain(int i,int j,int **s,int *p)&#123;\tif(i==j) return 0;\tint u = RecurMatrixChain(i,i,s,p)+RecurMatrixChain(i+1,j,s,p)+p[i-1]*p[i]*p[j];\ts[i][j] = i;\tfor(int k=i+1; k&lt;j; k++)\t&#123;\t\tint t = RecurMatrixChain(i,k,s,p) + RecurMatrixChain(k+1,j,s,p) + p[i-1]*p[k]*p[j];\t\tif(t&lt;u)\t\t&#123;\t\t\tu=t;\t\t\ts[i][j]=k;\t\t&#125;\t&#125;\treturn u;&#125;void Traceback(int i,int j,int **s)&#123;\tif(i==j) return;\tTraceback(i,s[i][j],s);\tTraceback(s[i][j]+1,j,s);\tcout&lt;&lt;&quot;Multiply A&quot;&lt;&lt;i&lt;&lt;&quot;,&quot;&lt;&lt;s[i][j];\tcout&lt;&lt;&quot; and A&quot;&lt;&lt;(s[i][j]+1)&lt;&lt;&quot;,&quot;&lt;&lt;j&lt;&lt;endl;&#125;\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//3d1-2 矩阵连乘 备忘录递归实现//A1 30*35 A2 35*15 A3 15*5 A4 5*10 A5 10*20 A6 20*25//p[0-6]=&#123;30,35,15,5,10,20,25&#125;#include \"stdafx.h\"#include &lt;iostream&gt;using namespace std;const int L = 7;int LookupChain(int i, int j, int **m, int **s, int *p);int MemoizedMatrixChain(int n, int **m, int **s, int *p);void Traceback(int i, int j, int **s); //构造最优解int main()&#123;\tint p[L] = &#123;30, 35, 15, 5, 10, 20, 25&#125;;\tint **s = new int *[L];\tint **m = new int *[L];\tfor (int i = 0; i &lt; L; i++)\t&#123;\t\ts[i] = new int[L];\t\tm[i] = new int[L];\t&#125;\tcout &lt;&lt; \"矩阵的最少计算次数为：\" &lt;&lt; MemoizedMatrixChain(6, m, s, p) &lt;&lt; endl;\tcout &lt;&lt; \"矩阵最优计算次序为：\" &lt;&lt; endl;\tTraceback(1, 6, s);\treturn 0;&#125;int MemoizedMatrixChain(int n, int **m, int **s, int *p)&#123;\tfor (int i = 1; i &lt;= n; i++)\t&#123;\t\tfor (int j = 1; j &lt;= n; j++)\t\t&#123;\t\t\tm[i][j] = 0;\t\t&#125;\t&#125;\treturn LookupChain(1, n, m, s, p);&#125;int LookupChain(int i, int j, int **m, int **s, int *p)&#123;\tif (m[i][j] &gt; 0)\t&#123;\t\treturn m[i][j];\t&#125;\tif (i == j)\t&#123;\t\treturn 0;\t&#125;\tint u = LookupChain(i, i, m, s, p) + LookupChain(i + 1, j, m, s, p) + p[i - 1] * p[i] * p[j];\ts[i][j] = i;\tfor (int k = i + 1; k &lt; j; k++)\t&#123;\t\tint t = LookupChain(i, k, m, s, p) + LookupChain(k + 1, j, m, s, p) + p[i - 1] * p[k] * p[j];\t\tif (t &lt; u)\t\t&#123;\t\t\tu = t;\t\t\ts[i][j] = k;\t\t&#125;\t&#125;\tm[i][j] = u;\treturn u;&#125;void Traceback(int i, int j, int **s)&#123;\tif (i == j)\t\treturn;\tTraceback(i, s[i][j], s);\tTraceback(s[i][j] + 1, j, s);\tcout &lt;&lt; \"Multiply A\" &lt;&lt; i &lt;&lt; \",\" &lt;&lt; s[i][j];\tcout &lt;&lt; \" and A\" &lt;&lt; (s[i][j] + 1) &lt;&lt; \",\" &lt;&lt; j &lt;&lt; endl;&#125;\n\n最长公共子序列\n背包问题\n\n1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;int main()&#123;    int N;//物品个数 5    int V;//背包容量 15    cin &gt;&gt; N &gt;&gt; V;    int weight[N + 1];// 5 4 7 2 6    int value[N + 1];// 12 3 10 3 6    weight[0] = value[0] = 0;    int maxTotalValue[V + 1]; //maxTotalValue[i]:背包已装容量为i时,背包里所装物品的最大总价值    memset(maxTotalValue, 0, sizeof(maxTotalValue));    for(int i = 1; i &lt;= N; i++)        cin &gt;&gt; weight[i] &gt;&gt; value[i];    for(int j = 1; j &lt;= N; j++)        for(int i = 0; i &lt;= V; i++)            &#123;                cout &lt;&lt; \"背包已装容量:\" &lt;&lt; i &lt;&lt; endl;                if(i &gt;= weight[j])                    &#123;                        if(maxTotalValue[i] &gt;= value[j] + maxTotalValue[i - weight[j]])                            //cout &lt;&lt; \"背包中未装入物品:\" &lt;&lt; j &lt;&lt; endl;                            ;                        else                            &#123;                                maxTotalValue[i] = maxTotalValue[i - weight[j]] + value[j];                                cout &lt;&lt; \"背包中已装入物品:\" &lt;&lt; j &lt;&lt; endl;                            &#125;                    &#125;                else                    //cout &lt;&lt; \"背包中未装入物品:\" &lt;&lt; j &lt;&lt; endl;                    ;            &#125;    cout &lt;&lt; \"背包能装物品的最大总价值:\" &lt;&lt; maxTotalValue[V] &lt;&lt; endl;    return 0;&#125;\n Chapter 4\n 贪心算法\n\n局部最优选择\n*近似解\n找零问题\n最优子结构性质\n贪心选择性质\n活动选择问题\n最优前缀码问题\n最小生成树\n\nPrim算法\nKruskal算法\n\n\n单源最短路径问题\n\n Chapter 5\n 回溯法\n\n\n问题的解向量\n\n\n深度优先、广度优先\n\n\n多米诺性质\n\n\n图着色问题\n\n\n搜索树\n\n\n剪枝\n\n\n会场分配问题\n\n\n解空间\n\nM叉树、子集树、排列树\n\n\n\n回溯\n\n递归回溯\n迭代回溯\n\n\n\n Chapter 6\n 分支限界法\n\n广度优先、最小耗费优先\n队列式分支限界法\n优先队列式分支限界法\n栈式分支限界法\n估值\n代价函数\n最短路径问题\n\nDijakstra算法\n\n\n最大团问题\n\n Chapter 7\n 随机化算法\n\n\n伪随机数\n\n\n随机数值算法\n\n主要用于数值问题求解\n算法的输出往往是近似解\n近似解的精确度与算法执行时间成正比\n\n\n\nSherwood算法\n\n\nta‾(n)=∑x∈XntA(x)∣Xn∣\\overline{t_a}(n)=\\sum_{x\\in X_n}\\frac{t_A(x)}{|X_n|}\nta​​(n)=x∈Xn​∑​∣Xn​∣tA​(x)​\n\n\n主打平均性能\n\n\nLas Vegas算法\n\n随机算法运行一次得到正确解或者无解\n可反复运行LV算法，直到得到正确解为止\n\n\n\nMonte Carlo算法\n\n\n设p是一个实数，且12&lt;p&lt;1\\frac{1}{2}&lt;p&lt;121​&lt;p&lt;1。如果一个MC算法对于问题的任一实例得到正确解的概率不小于p，则称该MC算法是p正确的，且称p−12p-\\frac{1}{2}p−21​是该算法的优势。\n\n\n如果对于同一个实例，Monte Carlo算法不会给出两个不同的正确解答，则称该Monte Carlo算法是一致的\n\n\n如果重复运行一个一致的p正确的MC算法，每次都进行随机选择，即可产生不正确解的概率→任意小\n\n\n对于一个一致的p正确MC算法，要提高正确解的概率，只要执行该算法若干次，并选择出现频次最高的解即可。\n\n\n如果重复调用一个一致的(12+ϵ)(\\frac{1}{2}+\\epsilon)(21​+ϵ)正确的MC算法2m-1次，得到正确解的概率至少为1−δ1-\\delta1−δ,其中\n\n\n\n\nδ=12−ϵ∑i=0m−1(2ii)(14−ϵ2)i≤(1−4ϵ2)m4ϵπm\\delta=\\frac{1}{2}-\\epsilon\\sum_{i=0}^{m-1}\n\\begin{pmatrix}2i\\\\i\\end{pmatrix}\n(\\frac{1}{4}-\\epsilon^2)^i\\leq\\frac{(1-4\\epsilon^2)^m}{4\\epsilon\\sqrt{\\pi m}}δ=21​−ϵi=0∑m−1​(2ii​)(41​−ϵ2)i≤4ϵπm​(1−4ϵ2)m​\n\n主元素问题\n素数测试\n\n","plink":"hanyuulu.github.io/Algorithm/"},{"title":"计算机网络复习","date":"2019-04-24T10:03:06.000Z","updated":"2021-03-12T08:22:58.390Z","content":"[TOC]\n Chapter 1\n\n计算机网络分类\n\n跨度\n\nPAN、LAN、MAN、WAN、Internet\n\n\n拓补结构\n\nBUS、Star、Ring、Mesh\n\n\n管理性质\n\n公用网、专用网\n\n\n交换方式\n\n电路交换、报文交换、分组交换\n\n\n网络功能\n\n通信子网、资源子网\n\n\n\n\n通信协议的三要素\n\n语法：确定通信双方通信时数据报文的格式\n语义：确定通信双方的通信内容的含义\n时序：指出通信双方信息交互的顺序，如建立连接、数据传输、数据重传、 终止连接\n\n\n\n Chapter 2\n\n\n网络通信基本原理\n\n\n基本概念\n\n\n信道带宽\n\n信道可以不失真地传输信号的频率范围(Hz)\n信道带宽取决于信道的质量\n\n\n\n信道容量\n\n信道在单位时间内可以传输的最大信号量\n数据通信领域：以Data transfer rate(数据传输速率)的形式表 示：信道在单位时间内可以传输的最大比特数\n\n\n\nNyquist‘s Theorem\n\n信道带宽（H）,信道容量（B）,信道数据速率（C）\n无噪声下的B与H的关系： B = 2 × H（Baud)\n无噪声下的C与H的关系： C = 2 × H × log2N (bps) 其中：N为一个码元可取的离散值个数\n\n\n\nShannon’s Theorem\n\n\n信道带宽（H）,信道容量（B）,信道数据速率（C）\n\n\n有热噪声时C、H和噪声的关系：C = H× log2 (1+S/N) (bps)\n其中S为信号功率， N为噪声功率，S/N为信噪比，通常把信噪比表示成 10×lg(S/N) 分贝(dB)\n\n\n\n\n\n\n波特率\n\n每秒钟电平变化的次数（Hz）\n\n\n\n数据传输速率\n\n数据传输速率 = 波特率 × log2N (N 为每个码元的取值个数)\n\n\n\n性能指标\n\n速率\n\n信道/网络的额定数据传送速率(bps)，非实际速率\n\n\n带宽\n\n模拟信号具有的频带宽度\n数据通信领域指单位时间内网络中的某信道所能通过的“最高 数据率”\n\n\n吞吐量\n\n单位时间内通过网络(或信道、接口)的实际数据量。受网络带 宽或网络的额定速率的限制，常用每秒传送的字节数或帧数来表示\n\n\n时延\n\n数据(比特、报文或分组)从网络(或链路)一端传送到另一端所需的 时间。包括：\n\n发送时延：主机或网络设备发送数据帧（第1位到最后1位）所需要的时间发送时延=数据帧长度(bit)/发送速率(bit/s)\n传播时延：电磁波在信道中传播一定的距离需要花费的时间 传播时延=信道长度(m)/电磁波的传播速率（光纤约为2*105m/s，铜线为 2.3 *105m/s ）\n处理时延：主机或设备收到分组后的处理时间（分析首部、数据部分、差 错检验、选择路由等）\n排队时延：输入队列中排队等待处理，输出队列中排队等待转发\n\n\n数据在网络的总时延=发送+传播+处理+排队时延\n\n\n时延带宽积\n\n带宽时延积=传播时延×带宽，表示在特定时间该网络上的最大 数据量–已发送但尚未确认的数据\n若发送端连续发送数据，则在发送的第一个比特即将达到终点 时，发送端己经发送的比特数\n\n\n往返时间RTT\n\n双向交互一次所需的时间，包括中间结点的处理时延、排队时 延以及转发时延。为避免出错，数据传输常采用应答式交互\n\n\n利用率\n\nChannel utilization rate(信道利用率):\n\n信道传输数据的时间百分比，空闲时的信道利用率是零\n信道利用率并非越高越好（堵塞增加了时延），参见高速公路的车流量\n\n\nNetwork utilization rate(网络利用率):\n\n全网络的信道利用率的加权平均值。\n当网络的利用率接近最大值1 时，网络的时延就趋于无穷大(通常超过 50%时，需准备扩容)\n\n\n\n\n\n\n\n\n\n通信系统\n\n\n\n\n调制解调器\n\n调制解调\n调制方法\n\n调幅\n调频\n调相\n组合调制\n\n\n\n\n\n编码解码\n\n\n编码\n\nPulse code modulation ，PCM，脉码调制技术\n采样、量化、编码\nNyquist Sampling Theorem\n\n最大频率为 F 的模拟信号 被不失真还原的前提条件是 取样频率不低于 2F\n\n\n\n\n\n\n\n\n\n通信编码\n\nNRZI（不归零交替编码）\n\n相邻比特点评变化情况\n\n变化1\n不变化0\n\n\n\n\n曼彻斯特编码\n\n一个比特时间一分为二，在此时间内发生低电平到高电平的变化 表示1，高电平到低电平的变化表示0\n编码中含有同步信息(每个比特中部的电平跃变信号)\n\n\n差分曼彻斯特比编码\n\n一个比特时间一分为二，表示的值依赖于前一比特的最终电平状态\n前半部分电平不同于前一比特的最终电平状态：0\n前半部分电平相同于前一比特的最终电平状态：1\n\n\n\n\n\n传输方式\n\n\n并行传输\n\n\n串行传输\n\n同步传输\n\n依靠双方始终的精确同步\n\n同步模式：一个或多个特定的字符或者符号组合\n\n\n\n\n异步传输\n\n单个字符独立传输\n\n独特的起始位和终止位\n\n\n\n\n\n\n\n检错码\n\n校验字段（冗余信息）\n奇偶校验\n\n奇/偶校验\n水平垂直偶校验码\n\n\nCRC（循环校验码）\n\n\n\n多路复用\n\n\n频分多路复用FDM\n\n\n\n\n时分多路复用TDM\n\n\n\n\n波分多路复用WDM\n\n\n数据交换\n\n电路交换\n\n在数据传输之前，源点和目的点之间需要建立了一条独 占的物理电路（即使通信线路空闲，也不能供其他用户使用），包 含建立线路、数据传输、释放线路三个阶段\n\n\n报文交换\n\n存储转发，无需占用整个物理线路，中间结点根据报文 附加的目的地址确定输出端口和线路，排队等待线路空闲后再转发\n\n\n分组交换\n\n存储转发，对报文交换进行改进，来自上层的报文被分 割成多个分组再通过网络进行发送。目的结点必须等到该报文的所 有分组都到齐之后进行组装，才能将报文交付给上层\n\n\n\n\n\n\n\n Chapter 3\n\n\nOSI/RM模型\n\n\n\n物理层\n数据链路层\n网络层\n传输层\n会话层\n表示层\n应用层\n\n\n\n层间通信\n\n\n\n\n Chapter 4\n\n\n局域网\n\n\nLAN逻辑结构\n\n\nNetwork\n\n广播方式，不需要路由，可省略该层功能\n\n\n\nData link\n\n\nMAC（介质访问控制子层）\n\n定义节点共享传输媒体时采用的访问技术，包括借助于物理层的无差错传输技术等\n\n\n\nLLC（逻辑链路控制子层）\n\n屏蔽不同的MACX子层之间的差异，以便提供统一的接口\n\n\n\n\n\nPhysical\n\n定义结点的传输媒体的接口特性，包括机械特性，电气特性\n\n只有局域网的数据链路层进行了子层划分\n\n\n\n\n\n\n多路访问\n\n\nmultiple-access protocols\n\n\nRandom access protocols\n\nALOHA *\nCSMA*\nCSMA/CD(Carrier sense Multiple access Collision detection载波侦听多路访问冲突检测)\nCSMS/CA\n\n\n\nControlled-access protocols(随机访问竞争)\n\nReservation*\nPolling*\nToken passing(受控访问)\n\n\n\nChannelization protocols(通道化)\n\nFDMA\nTDMA\nCDMA\n\n\n\n\n\n\n\nCSMA/CD\n\n载波侦听(CS)：发送结点在发送信息帧之前必须侦听介质是否处 于空闲状态（说前先听），如果有其他结点在发送数据，则暂时 不要发送数据，以免发生碰撞\n多路访问(MA)：多个结点可以同时访问介质；一个结点发送的 信息帧可以被多个结点接收\n冲突检测(CD)：发送结点在发出信息帧的同时，还必须监听介质， 判断是否发生冲突（边说边听\n当检测到碰撞后\n\n数据碰撞会使总线上传输的信号产生了严重的失真，无法从中恢 复出有用的信息\n每一个正在发送数据的站，一旦发现总线上出现了碰撞，就要立 即停止发送，免得继续浪费网络资源，然后等待一段随机时间 （二进制指数退避）后再次发送\n\n\n\n\n\n\n\n最小帧长度\n\n\n发送方将信息帧全部发往介质时，如果未检测到冲突，则认为发送成功\n\n\n发送方发送的帧长度必须足够大，以确保发送方在检测到冲突时还在发送数据\n\n\n最小帧长度：保证发送结点可以对发送的冲突进行有效的冲突检 测，即保证其发送时间不小于信号在网络中传播距离最远的两个 结点之间传输的时间的2倍\n\n\n10base5：最小帧长度为64字节\n\n10base5\n10:10Mbps\nBase:基带传输\n5:200M\nT: 双绞线\nF:光纤\n\n\n\n\n\nEthernet\n\n\nCSMA/CD\n\n\nDIX标准，与802.3略有区别\n\n\n\n最长数据字段1500（防止缓冲溢出）\n\n\n\n\n\n令牌\n\n\n结点获得媒体使用权的标志，保证有序地访问共享媒体\n\n\n令牌总线 802.4\n\n物理拓扑\n\n总线\n\n\n逻辑拓扑\n\n环\n\n\n半双工\n\n只有获得令牌的结点才能发送 信息，其它结点只能接收信息，或者 被动地发送信息（在拥有令牌的结点 要求下，发送信息）\n\n\n为了保证逻辑闭合环路的形成，每个 结点都动态地维护着一个连接表，该 表记录着本结点在环路中的前继、后 继和本结点的地址，每个结点根据后 继地址确定下一占有令牌的结点\n\n\n\n令牌环网 802.5\n\n物理拓扑\n\n环\n\n\n逻辑拓扑\n\n环\n\n\n单向\n发送方回收帧\n媒体访问\n\n令牌+优先级\n\n\n环中继转发器RPU\n\n\n\n\n\n\n\n\n\n Chapter 5\n\n\n广域网\n\n帧中继网络\n\n一种虚电路广域网，高质量传输媒体应用，速率可达2～155Mb/s，传输差错 率下降，为简化X.25协议，不提供差错处理过程\n工作在物理层和数据链路层，提供部分的网络层功能\n\n\n\n\n\nFR\n\n精简X.25协议\n用光纤等高质量传输媒体，提高速率和降低误码率\n分组重发、流量控制、防止拥塞（正向拥塞通知，反向拥塞通知， 丢失指示等）等处理由端系统完成，降低网络时延\n将路由和简化的2层功能进行集成，提高协议效率\n保持X.25永久虚电路特性，提供虚拟专线服务，减少用户成本\n支持按需分配带宽，在“承诺信息速率”的基础上，支持突发性数 据量“瞬时”超标\n保持网络概念，减少专线方式所需的用户接入线，一条物理连接能 够提供多个逻辑连接\n\n\n\nATM（异步传输模式）\n\n\n基于信元（53B）的分组交换技术\n\n\n面向连接：虚电路\n\n物理链路逻辑上被分为多条虚拟路径(Virtual Path, VP)，VP又 被划分为多条虚拟信道(Virtual Channel, VC)，每个VP和VC都 由标识符标识(VPI和VCI) ，VPI和VCI的组合(VPI/VCI )唯一地 标识了一条VC\n\n\n\n提供预约带宽机制\n\n\n\n\n\n\n\n\n\n\n\n\n Chapter 6\n\n\n网络互连\n\n\n网络互连部件\n\n\n主要进行底层协议的转换\n\n\n转发器\n\n物理层\n\n\n\n网桥\n\n链路层及以下\n\n\n\n路由器\n\n\n网络层及以下\n\n\n\n\n\n\n转发器(Repeater, 中继器、集线器)\n\n\n互连仅在物理层及其下层(传输媒体)存在 差异的网络，延伸网段、改变传输媒体，实现网段之间的电气信号的接收和再生\n\n\n\n\n转发器并不能连接两个局域网，它连接的是同一局域网的两个分段转发器转发每一帧，没有过滤能力\n\n\n\n\n网桥/交换机（Bridge/Switch)\n\n\n用于互连两个独立的子网，实现信息帧的存储 转发，工作在物理层和数据链路层\n\n\n\n\n\n\n执行OSI数据链路层及其下层的协议转换，适用于相同网络或者仅在低两层实现上有 差别的网络之间的互连\n\n\n\n\n网桥(Bridge)的功能\n\n地址过滤：具有统一的数据链路层的编址格式，网桥能够识别各种地址，并根据数据帧的宿地址，有选择地让数据帧穿越网桥\n帧限制：网桥不对帧进行分段，只进行必要的帧格式转换，以适应不同的子网，超长帧则被丢弃，各子网相对独立，控制帧不能穿越网桥\n监控功能：作为单个子网的一部分，参与对子网的监控和对信息帧的校验，具有“存储-转发”的能力，工作过程包括接收帧、检查 帧和转发帧三个部分\n缓冲能力：适应不同子网对媒体访问的控制方式，可以解决数据传输不匹配的子网之间的互连\n透明性：不应影响原有子网的通信能力\n网桥：不同子网的结点间的通信\n\n问题：多个子网互连时，如何找到分属不同子网的结点？\n基本方法：网桥对信息帧宿地址的处理：如果该地址不属于原子网， 则向所有的端口转发（广播)\n结果:大量的&quot;无用帧&quot;被扩散到网络上导致广播风暴（帧在网络上无限制的转发）\n解决方案\n\n设置地址映射表，有选择地进行转发\n分析途经网桥的每个帧，如果宿地址出现在映射表中， 封装/转发该帧至对应网段（端口），否则广播(泛洪)\n\n\n\n\n类型\n\n透明桥/学习桥/自适应桥\n\n网桥环路→地址映射表无法工作→广播风暴\n\n对于存在环路的网络，执行构树过程，确保网络中任意两 个结点之间有且仅有一条路径，可构造基于网桥的支撑树(Span Tree, 生成树)，消除环，多余资源留作备用\n\n目标：任意两个结点之间仅有一条（跨越不同网段）的路径\n原理：逐个增加网桥（端口），一旦出现环路，则阻塞引起该环路的端口\n算法依据：网段为点，桥为边的图中求生成树（支撑树）\n\n\n\n\n\n\n指定路径桥\n\n发送帧的源结点负责路由选择\nIBM令牌环在数据帧中包含路径\n\n源结点知道所发送的帧传输的确切路径，可以直接传输 ，否则，源结点以广播方式向目的结点发送一个用于探测的发现帧（discovery frame)，发现帧将通过网桥互连的局域网中沿着所有可能的路由传送\n在传送过程中，每个发现帧都记录所经过的路由。当这些发现帧到达目的结点 时，就选择出一个最佳路由（跳步数最少的路径）\n指定路径桥可以获得最佳的路径，其缺点是测试帧的发送增加了网络的信息流量，可能形成“广播风暴”，甚至可能导致网络拥塞现象\n\n\n\n\n\n\n收到数据帧后，根据帧的目的地址查地址映射表，然后确定将这个帧转发到哪个接口，或者丢弃(过滤)\n通过网桥互连的局域网，在网络层看是属于同一个网\n\n\n\n以太网交换机\n\n多口的网桥\n同时连通多对接口，使多对主机能同时通信，相互通信的主机独占传输媒介，无碰撞地传输数据(网桥一次只能分析和转发一个帧)\n交换机隔离冲突域\n\n\n\n路由器(Router)：三层交换\n\n网桥的限制：仅适合低二层有差异的网络互连\n为了要互连两个或多个独立的同构或异构的网络，如局域网/广域网、局域网/局域网的互连，需要使用路由器，进行分组的封装和转发，屏蔽3层以下的差异\n通过路由器互连的网络属于不同网段（网络地址不同）：路由器不同接口分配不 同网络的IP地址\n路由器隔离广播域\n路由器的体系结构\n\n执行OSI网络层及其下层协议转换\n网络层主要功能：路由选择\n\n\n路由器的主要功能\n\n寻址：通过路由器互连的网络具有公共的网络地址，并且，网间协议对全网地址 作出规定，以使路由器可以区分各个结点所在的通信子网\n路由选择：相对灵活的路由选择功能，以最快的速度将分组传送通过网络\n\n开放式最短路径优先协议(OSPF：RFC 1247)\n边界网关协议(BGP：RFC 1163)\n内部网关路由协议(IGRP)\n\n\n分组分段/合段：根据子网的分组长度要求，进行分组的分段和合段\n存储-转发、分组格式转换和处理：严格地执行&quot;存储-转发&quot;的原则，即先接收和 存储分组，在完成必要的分组分析和格式转换之后，转发分组至特定的子网\n分组过滤：分组校验（丢弃出错的分组）\n功能主要由软件完成，效率较低，高性能的路由器具有高的价格\n\n\n\n\n\n二层交换\n\n\n网桥、交换机根据帧的宿地址和映射表，不作修改地交换至输出端口(同构网络)， 交换对象为帧\n\n\n\n\n\n\n三层交换\n\n\n根据分组的宿地址和路由表，在路由器上实现分组的交换\n\n\n三层交换机：简化的路由器，二层功能+IP路由，效率高\n\n\n\n\n\n\n\n\n\n\n\n\n虚拟局域网 (virtual LAN)\n\n传统的局域网\n\n以物理网段为基本网络用户单位，如果一个节点接到一个网络设备（HUB、中继器、网桥或交换机）上，那么，它就与其他接在同一设备上的节点属于同一个局域网，可以互发广播报文\n\n\n虚拟局域网简称VLAN，跨接不同物理LAN网段的节点连接成逻辑 LAN网段，处于不同物理网段的用户通过软件设置处于同一局域网中， 形成逻辑的工作组。在同一逻辑工作组中的节点可以互发广播报文\n不同网段上的用户不能处于同一网段中\nVLAN通信\n\n隔离二层广播域：严格地隔离了各个VLAN之间的任何流量，即不同VLAN之间的流量不能直接跨越VLAN的边界\nVLAN直接通信需要使用路由，通过路由将报文从一个VLAN转发到另外一个VLAN\n\n\n\n\n\n Chapter 7\n\n\nInternet\n\n\n\n应用层\n\n工作模式\n\n客户机-服务器\n\n\n\n\n\n\n\n\n\n\n\nTCP Transmission control protocol\n\n\n在IP的基础上，支持面向连接的、可靠的、面向流的投递服务\n\n\n面向流的投递服务\n\n无结构字节流，收发字节顺序完全一致，根据对方给出的窗口值和网络拥塞程度决定//todo\n\n\n\nTCP模块之间建立点对点连接（虚电路）//todo\n\n\n套接字（socket）\n\nIP:socket\n五元组\n\n协议\n源IP\n源端口\n目的IP\n目的端口\n\n\n\n\n\nTCP报文格式\n\n//todoTCP首部最小长度20byte\n\n\n\n\n\nTCP建立连接\n\n三次握手\n\n//todo\n[x] ACK\n[ ] NAK(直接丢弃)\n\n\n\n\n\nTCP拆除连接\n\n四次确认\n\n//todo\n\n\n\n\n\nTCP可靠传输\n\n\n校验\n\n\n字节为单位，体积可变的滑动窗口（可靠传输、流量控制）\n\nTCP建立连接阶段，双方协商窗口尺寸，接收方预留数据缓存区\n\n发送方根据协商结果，发送符合窗口尺寸的数据字节流，并等待对方确认\n发送方根据确认信息，改变发送窗口的尺寸\n\n\n\n确保了可靠性和流量控制\n\n\n超时重传\n\n\n拥塞控制&amp;流量控制\n\n慢启动\n\n拥塞避免\n快重传\n快恢复\n\n\n\n\n\n\n\n网络层\n\nIP 数据投递服务\n\n不可靠、无连接、尽力而为的服务\n\nICMP\n\n\n\n\nIP地址段类型和划分\n专用IP地址\n10.xx.xx.xx\n172.16.00.00~172.31.255.255\n192.168.9.0~192.168.255.255\nIP地址分配\n\n子网掩码\nCIDR\n\n\n路由表\nIP路由过程\n分层次的路由信息协议\n\n局域网\n路由信息协议(RIP)\n\n分布式、基于向量的路由选择协议\n每一个路由器维护从它自己到每一个目的网络的距离记录（跳数）\n不能在两个网络之间同时使用多条路由\n仅和相邻路由器交换信息\n\n\n开放最短路径优先（OSPF Open shortest path first）\n\nDijkstra算法\n使用洪泛传播ISP\n多路径间的负载均衡\n\n\n\n\n\n\n\n数据链路层\n\n地址映射\nIP地址寻址ARP\n物理地址（e.g. MAC address）寻址\n\n\n\n Chapter 8\n\n\n网络安全措施\n\n网络操作系统安全\n局域网安全\nInternet互联安全\n\n\n\n数据安全\n\n加密/解密技术\n密钥管理\n数字签名\n认证技术\n防火墙技术\n\n区分内外网\n\n\n数据加密算法\n\n算法公开、密钥保密\n对称密钥加密\n\n高强度高效率\n密钥管理复杂\n一对一\n\n\n非对称密钥加密\n\n加密效率低\n密钥管理有优势、密钥分配协议\n多对一单项保密通信\n加密算法混合使用\n\n\n内容完整性检查\n\n信息摘录技术\n\n防重放攻击\n\n时间戳\n序列号\n\n\n\n\n\n\n数字签名\n\n信息摘录\n非对称加密\n\n\n认证技术\n\n消息验证\n\n数字签名\n\n\n身份验证\n\n秘密信息\n\n口令\n\n\n物理安全\n\n\n抗否认、防抵赖服务\n第三方认证\n内容保密\n内容完整性\n序列完整性\n实体鉴别\n抗发方否认\n抗收方否认\n\n\n\n\n\n\n\n Chapter 9\n\n简单网络管理协议SNMP\n\n协议数据单元PDU\n\n\n\n","plink":"hanyuulu.github.io/ComputerNetwork/"},{"title":"软件体系架构","date":"2019-04-23T23:03:06.000Z","updated":"2021-03-12T08:22:58.450Z","content":"[TOC]\n Chapter 1 概述\n\n软件架构产生的背景\n\n软件危机\n\n根源\n\n软件复杂易变，行为特性难于预见，需求向设计缺乏有效的转换导致开发过程中的困难和不可控\n随着软件体系规模越来越大越来越复杂，整个系统的贵和和规格说明越来越重要\n对于大规模复杂软件系统，总体的系统结构设计和规格说明非常重要\n对软件体系的结构的研究有望成为提升软件生产率和解决软件维护问题的有效途径之一\n\n\n软件架构\n\n作用\n\n\n\n\n\n\n软件架构的思想和特征\n\n主要思想\n\n软件架构是一个系统软件的设计图，不仅限于软件系统的总体结构，还包含一些质量属性以及功能与结构之间的映射关系，即设计决策\n软件架构的两个主要焦点集中于系统的总体结构以及需求和实现之间的对应\n主要思想是将注意力集中在系统总体结构的组织上\n筛选按手段是运用抽象方法屏蔽模块间的连接，是人们的认知提升并保持在整体结构的部件的交互层次，并进一步将交互从计算中分离出来，建立“组件+连接件+配置”的软件系统高层结构组织方式\n\n\n特征\n\n注重可重用性——组件及架构及重用\n利益相关者多——平衡需求\n关注点分离——模块化、分治\n质量驱动——关注非功能属性\n提倡概念完整性——强调设计结构是一个持续的过程\n循环风格——用标准方法来处理反复出现的问题\n\n\n\n\n软件架构的发展阶段，各阶段特征\n\n1968-1994 基础研究阶段\n\n1968 NATO 软件架构概念提出\n模块化实践\n\n高内聚低耦合\n模块大小适度\n模块链调用深度不可过多\n接口干净，信息隐藏\n尽可能地复用已有模块（功能独立）\n\n\n\n\n1991-2000 概念体系和核心技术形成阶段\n\n组件技术（component）\n\n\n1996-1999 理论体系丰富发展阶段\n\n软件架构的描述与表述\n软件架构分析、设计与测试\n软件架构发现、演化与重用\n基于软件架构的开发方法\n软件架构的风格\netc…\n\n\n1999-至今 理论完善和普及应用阶段\n\n\n软件架构研究和应用现状\n\n chapher 2 软件架构概念\n\n软件架构定义\n\n一研究人员一般认为\n软件架构就是一个系统的草图\n\n\n组成派定义\n\n组成派关注于软件本身，将软件架构看作构件和交互的集合\n\n\n决策派定义\n\n决策派关注于软件架构中的实体（人），将软件架构视为一系列重要设计决策的集合\n\n\n参考框架定义（一般性定义）：\n\n组件component\n\n角色role\n\n\n连接件connector\n\n端口port\n\n\n配置configuration\n\n\n\n chapter 3 软件架构模型\n\n\n软件架构模型是什么\n\n软件架构建模是对架构设计决策的具象化和文档化\n\n\n\n软件架构建模的五类方法\n\n\n基于非规范图形表示的建模方法\n\n基于图形可视化建模方法\n\n非正式图形表示\n\n盒线图\netc.\n\n\n正式图形表示\n\n树形结构\n树地图\n改进的树地图\n旭日图\n双曲树\n\n\n\n\n\n\n基于UML的建模方法\n\n逻辑视图\n开发视图\n过程视图\n物理视图\n优点\n\n统一标准\n支持多视图结构\n模型操作工具\n统一的交叉引用\n\n\n\n\n\n基于形式化的方法\n\n\n基于UML形式化的方法\n1234567graph LRA[需求分析]--&gt;B[需求文档规格说明]B--&gt;C[UML建模]C--&gt;D[形式化描述和验证]D--&gt;E[程序编码]E--&gt;F[形式规范自动生成和测试变量]F--&gt;G[软件产品]\n\n需求分析到形式化描述和验证占全部工作量的60%~70%\n\n\n\n\n\n软件架构建模方法的发展趋势\n\n\n\n\n第一层次\n\n文本模型\n\n\n\n第二层次\n\n图形可视化模型\n\n\n\n第三层次\n\n\nUML模型\n\n\n第四层次\n\n\n形式化模型\n\n\n第五层次\n\n未来模型\n\n\n\n\n\n Chapter 4 软件架构风格和模式\n\n\n什么是软件架构风格/软件架构惯用模式\n\n描述特定应用领域中系统组织方式的惯用模式\n\n\n\n使用架构风格的好处\n\n作为“可复用的组织模式和习语”，为设计人员的交流提供了公共的术语空间，促进了设计复用和代码复用\n极大地促进了设计的重用性和代码的重用性，并且使得系统的组织结构易被理解\n使用标准的架构风格可较好地支持系统内部的互操作性以及针对特定风格的分析\n\n\n\n经典体系结构风格的特点、优点、缺点、适用范围\n\n数据流风格 加一个批处理序列\n\n\n管道过滤器风格\n\n特点\n\n过滤器是独立运行的部件\n过滤器无法感知其处理上下连接的过滤器\n结果的正确性不依赖与各个过滤器运行的先后次序\n\n\n优点\n\n每个组件行为不受其他组件的影响，整个系统的行为易于理解\n管道-过滤器风格支持功能模块的复用\n基于管道-过滤器风格的系统具有较强的可维护性和可扩展性\n支持一些特定的分析（e.g.吞吐量计算和死锁检测）\n管道-过滤器风格具有并发性\n\n\n缺点\n\n管道-过滤器风格往往导致系统处理过程的成批操纵\n对加密数据流需要在每个模块中进行解析或反解析，增加了过滤器实现的复杂性\n交互处理能力弱\n\n\n\n\n\n\n\n调用返回风格\n\n\n主程序/子程序风格\n\n特点\n\n从功能观点设计系统，通过逐步分解和逐步细化得到系统架构，\n主程序的正确性依赖与它调用的子程序的正确性\n组件为主程序和子程序\n连接件为调用-返回机制\n拓补结构为层次化结构\n\n\n优点\n\n具有很高的数据访问效率（计算共享一个储存区）\n不同的计算功能被划分在不同的模块中\n\n\n缺点\n\n对数据储存格式的变化将会影响几乎所有的模块\n对处理流程的改变与系统功能的增强适应性较差\n这种分解方案难以支持有效的复用\n\n\n\n\n面向对象风格\n\n特点\n\n对象负责维护其表示的完整性\n对象的表示对其他对象而言是隐蔽的\n\n\n优点\n\n对象隐藏了其实现细节、可以在不影响其他对象的情况下改变对象的实现，不仅使得对象的使用变得简单、方便，而且具有很高的安全性和可靠性\n设计者可将一些数据存取操作的问题分解成一些交互代理程序的集合\n\n\n缺点\n\n当一个对象和其他对象通过过程调用等方式进行交互时，必须知道其他对象的标识。无论何时改变对象的标识，都必须修改所有显示调用它的其他对象，并消除由此带来的一些副作用\n\n\n\n\n层次化风格\n\n特点\n\n系统分层\n每个层次由一系列组件组成\n层次之间存在接口\n下层组件向上层组件提供服务，上层组件被看作是下层组件的客户端\n\n\n优点\n\n支持基于可增加抽象层的设计，允许将一个复杂问题分解为一个增量步骤序列的实现\n支持扩展，每一层的改变最多只影响相邻层\n支持重用，只要给相邻层提供相同的接口，它允许系统中同一层的不同实现相互交换使用\n\n\n缺点\n\n不是所有系统都容易采用这种模式来构建\n定义一个合适的抽象层次可能会非常困难，特别是对应标准化的层次模型\n\n\n\n\n\n\n\n独立组件风格\n\n\n\n事件驱动风格\n\n特点\n\n事件发布者不知道那些组件会受到时间的影响；组件不能对事件的处理排序，或者事件发生后的处理结果做任何假设\n从架构上来说，事件驱动系统的组件提供了一个过程集合和一组事件\n过程可以使用显式的方法进行调用，也可以用组件在系统事件中注册。当触发事件时，会自动引发这些过程的调用\n连接件既可以时显式过程调用，也可以是一种绑定事件声明和过程调用的手段\n\n\n优点\n\n事件声明者不需要知道那些组件会影响事件，组件之间关联较弱\n提高软件复用能力。只要在系统事件中注册组件的过程，就可以将该组件继承到系统中\n系统便于升级。只要组件名和事件中所注册的过程名保持不变，原有组件就可以被新组件取代\n\n\n缺点\n\n组件放弃了对计算的控制权，完全由系统来决定\n存在数据交换问题\n该风格中，正确性验证成为一个问题（难以调试）\n\n\n\n\n\n\n\n虚拟机风格\n\n\n\n解释器风格\n\n\n解释器（Interpreter）是一个用来执行其他程序的程序，它针对不同的硬件平台实现了一个虚拟机，将高层次的程序翻译为低抽象层次的所能理解的指令，，以弥合程序语义所期望的与硬件提供的计算引擎之间的差距\n\n\n优点\n\n它有利于实现程序的可移植性和语言的跨平台能力\n\n\n\n它可以对未来的硬件进行模拟和仿真，能够降低测试所带来的复杂性和昂贵花费\n\n\n缺点\n\n额外的间接层次导致了系统性能的下降（e.g. Java without JIT）\n\n\n\n\n\n\n\n\n\n基于规则的系统风格\n\n\n显示里的业务需求经常频繁的发生变化，不断修改代码效率低、成本高。最好把频繁变化的业务逻辑抽取出来，形成独立的规则库\n\n\n规则可独立于软件系统而存在，可以被随时更新\n\n\n系统运行时，读取规则库，依据当前运行状态，从规则库中选择与之匹配的规则解释运行\n| 基于规则的系统     | 解释器风格             |\n| ------------------ | ---------------------- |\n| 知识库             | 待解释程序             |\n| 规则解释器         | 解释器引擎             |\n| 规则与数据元素选择 | 解释器引擎内部控制状态 |\n| 工作内存           | 程序当前的运行状态     |\n\n\n\n\n\n\n仓库风格\n\n\n\n仓库风格\n\n\n特点\n\n仓库是储存和维护数据的中心场所\n仓库式风格的两种组件\n\n中央数据结构组件\n相对独立的组件集合\n\n\n\n\n\n优点\n\n便于模块间的数据共享,方便模块的添加,更新和删除,避免了知识源的不必要的重复储存等\n\n\n\n缺点\n\n对于各个模块,需要一定的同步/加锁机制保证数据结构的完整性和一致性\n\n\n\n\n\n\n\n黑板系统风格\n\n\n特点\n\n\n黑板系统是传统上被用于信号处理方面进行复杂解释的应用程序,以及松散耦合的组件访问共享数据的应用程序\n\n\n黑板架构实现的基本出发点是已经存在一个对公共数据结构进行协同操作的独立程序集合\n\n\n组成部分\n\n\n知识源\n\n\n黑板数据结构\n\n\n控制器\n\n\n\n\n\n\n\n\n\n\n优点\n\n\n便于多客户共享大量数据,他们不关心数据何时有的,谁提供的,怎样提供的\n\n\n既便于添加新的作为知识源代理的应用程序,也便于扩展共享的黑板数据结构\n\n\n知识源可重用\n\n\n支持容错性和健壮性\n\n\n\n\n缺点\n\n\n不同的知识源代理对于共享数据结构要达成一致,而且这也造成对黑板数据结构的修改较为苦难(要考虑到给个代理的调用)\n\n\n需要一定的同步/加锁机制保证数据结构的完整性和一致性,增大了系统复杂度\n\n\n\n\n\n\n\n\n其他\n\n\nC2风格\n\n\n\n特点\n\n\n系统组织规则\n\n系统中的组件和连接件都有一个顶部和一个底部\n组件的顶部应连接到某连接件的底部,组件的底部应连接到某连接件的顶部,不允许组件之间的直接连接\n\n一个连接件可以和任意数目的其他组件和连接件连接\n- 当两个连接件进行直接连接时,必须由其中一个的底部到另一个的底部\n\n\n\n\nC2的内部,通信和处理时分开完成的\n\n\n\n\n\n优点\n- 可使用任何编程语言开发组件,组件重用和替换易实现\n- 由于组件之间相对独立,依赖较小,因而该风格具有一定扩展能力,可支持不同粒度的组件\n- 组件不需共享地址空间\n- 可实现多个用户和多个系统之间的交互\n- 课使用多个工具集和多种媒体类型,动态更新系统框架结构(适合交互系统)\n\n\n缺点\n\n\n不太适合大规模流式系统,以及对数据库使用比较频繁的应用\n\n\n\n客户机/服务器风格（两层C/S架构）\n\n\n\n特点\n\n协作关系\n- 客户机\n- 服务器\n- 客户机和服务器程序配置在分布式环境中时:通过远程调用(RPC)协议进行通信\n优点\n\n客户机组件和服务器组件分别运行在不同的计算机上,有利于分布式数据的组织和处理\n组件之间的位置是相互透明的\n客户机程序和服务器程序可运行在不同的操作系统上,便于实现异构环境和多种不同开发技术的融合\n软件环境和硬件环境的配置具有极大的灵活性,易于系统功能的扩展\n将大规模的业务逻辑分布到多个通过网络连接的低成本的计算机上,降低了系统的整体开销\n\n\n缺点\n\n开发成本高(客户机软硬件要求搞)\n客户机程序的设计复杂度大,客户机负载重\n信息内容和形式单一\nC/S架构升级需要开发人员到现场更新客户机程序,对运行环境进行重新配置,增加了维护费用\n两层C/S结构采用了单一的服务器,同时以局域网为中心,难以扩展到inrtante和Internet\n数据安全性不高\n\n\n\n\n\n\n\n浏览器/服务器风格（三层C/S架构）\n\n特点\n\n相对两层C/S架构的优点\n\n合理地划分三层结构的功能，可以使系统的逻辑结构更加清晰，提高软件的可维护性和可扩充性\n在实现三层C/S架构时，可以更有效地选择运行平台和硬件环境，从而使每一层都具有清晰的逻辑结构，良好的符合处理能力和叫号的开放性\n在C/S结构中，可以分别选择合适的变成语言并行开发\n系统具有较高的安全性\n\n\n在使用三层C/S架构时需要注意以下问题\n\n如果各层之间通信效率不高，及时每一层的硬件配置都很高，系统的整体性能也不会太高\n必须慎重考虑三层之间的通信方法，通信频率和数据传输量，这和提高各层的独立性一样也是实现三层C/S架构的关键性问题\n\n\n\n\n浏览器/服务器风格是三层C/S风格的一种实现方式\n\n与三层C/S结构的解决方案相比，B/S架构在客户机采用了WWW浏览器，把web服务作为应用服务器\n\n\n优点\n\n客户端只需要安装浏览器，操作简单，能够发布动态信息和静态信息\n运用HTTP标准协议和统一客户端软件，能够实现跨平台通信\n开发成本比较低，只需要维护web服务器和中心数据库，客户端升级可以通过升级浏览器是实现\n\n\n缺点\n\n个性化程度低,所有客户端程序的功能都是一样的\n客户端数据处理能力较差,加重了web服务器的工作负担,影响系统的整体性能\n在B/S架构中,数据提交一般以页面为单位,动态交互性不强,不利于在线事务处理(OLTP)\nB/S架构可扩展性比较差,系统安全性难以保障\nB/S架构的应用系统查询中心数据库,其速度要远低于C/S架构\n\n\n\n\n\n平台/插件风格\n\n特点\n\n平台\n\n程序的主题或主框架\n\n内核功能\n插件处理功能\n\n\n\n\n接口\n\n平台扩展接口\n插件接口\n\n\n插件\n\n对软件功能的扩展或补充模块\n\n\n\n\n优点\n\n降低系统各模块之间的互依赖性\n系统模块独立开发,部署,维护\n根据需求动态的组装,分离系统\n\n\n缺点\n\n只服务与该主程序,可重用性差\n\n\n\n\n\n面向Agent风格\n\n特点\n\nAgent\n\n一个能感知环境并主动决策和行为的软件实体\n\n\nAgent组件\n\n对系统处理的高度抽象,具有高度灵活和高度智能特色的软件实体\n自主性,智能性,交互性\n\n\nAgent连接件\n\n对复合型组件的连接,提供通信,协调,转换,接通等服务\n\n\n\n\n优点\n\n面向Agent的软件工程方法对于解决复杂问题是一种好技术,特别是对于分布开放异构的软件环境\n\n\n缺点\n\n大多数结构中Agent自身缺乏社会性结构描述和与环境的交互\n\n\n\n\n\n面向方面软件架构风格\n\n特点\n\n一般认为AOP在传统软件架构基础上增加了方面组件(Aspect Component)这一个新的构成单元,通过 方面组件来封装系统的横切关注点(需求特性或关注点)\n\n\n优缺点\n\n可以定义交叉的关系,并将这些关系应用于跨模块的,彼此不同的对象模型\nAOP同时还可以让我们层次化功能性而不是嵌入功能性,从而使得代码有更好的可读性和易于维护\n他会和面向对象编程很好地合作,互补\n\n\n\n\n\n面向服务架构风格\n\n\n特点\n\n\n面像服务架构模型（SOA）\n\n\n服务\n\n一个粗粒度的，可发现的软件实体\n\n\n\n接口\n\n\n\n\n\n发布\n发现\n绑定和调用\n\n\n\n\n\n优点\n\n灵活性，根据需求变化，重新编排服务\n对IT资产的复用\n使企业的信息建设真正以业务为核心。业务人员根据需求编排服务，而不必考虑技术细节\n\n\n\n缺点\n\n服务的划分很困难\n服务的编排问题\n接口标准可能会带来系统的额外开销和不稳定性\n对硬件IT资产谈不上复用\n目前主流实现方式很多，松散脆弱\n目前主流实现方式局限于不带界面的服务的共享\n\n\n\n\n\n正交架构风格\n\n\n特点\n\n\n由完成不同功能的n个线索（子系统）组成\n\n\n系统具有m个不同抽象级别的层\n\n\n线索之间是相互独立的\n\n\n系统有一个公共驱动层（一般为最高层）和公共数据结构（一般为最底层）\n\n组织层（Layer）\n\n由一组具有相同抽象级别的组件构成\n\n\n线索（Thread）子系统的特例的组件（Component）\n线索是相互独立的，即线索中的组件之间没有相互调用\n\n\n\n\n\n\n\n优点\n\n结构清晰，易于理解。由于线索功能相互独立，组件的位置可以清楚地说明它所实现的抽象层次和负担的功能\n易修改，可维护性强。由于线索之间是相互独立的，所以对一个线索的修改不会影响到其他线索\n可移植性强，重用粒度大。因为正交结构可以为一个领域内的所有应用程序所共享，这些软件有着相同或类似的层次和线索，可以实现架构级的重用\n\n\n\n缺点\n\n在实际应用中，并不是所有软件系统都能完全正交化，或者有时完全正交化的成本太高。因此，在进行应用项目的软件架构设计时，必须反复权衡进一步正交化的额外开销与所得到的更好的性能之间的关系\n\n\n\n\n\n异构风格\n\n特点\n\n在设计软件系统时，从不同角度来观察和思考问题，会对架构风格的选择产生影响\n每一种架构风格都有不同的特点，适用于不同的应用问题，因此，架构风格的选择是多样化的和复杂的\n实际应用中，各种软件架构并不是独立存在的，在一个系统中，往往会有多种架构共存和相互融合，形成更复杂的框架结构，即异构架构\n组合方式\n\n层次结构\n单一组件使用符合的连接件\n\n\n\n\n优点\n\n可以实现遗留代码的重用\n在某些单位中，规定了共享软件包和某些标准，但仍会存在解释和表示习惯上的不同。选择异构架构风格，可以解决这一问题\n\n\n缺点\n\n不同风格之间的兼容问题有时很难解决\n\n\n\n\n\n基于层次消息总线的架构风格（JB/HMB风格）\n\n特点\n\n以青鸟软件生产线的实践为背景，提出了基于层次消息总线的软件架构(Jade bird hierarchical message bus based style)\nJB/HMB风格基于层次消息总线、支持组件的分布和并发，组件之间通过消息总线进行通讯\n消息总线是系统的连接件，负责消息的分派、传递和过滤以及处理结果的返回。各个组件挂接在消息总线上，向总线登记感兴趣的消息类型\n\n\n优点\n\n较好地支持架构设计\n构件之间的耦合性较低\n构建使用灵活\n构建重用性较高\n动态性（支持系统演化）\n\n\n缺点\n\n总线可重用性差\n重用要求高\n\n\n\n\n\n模型-视图-控制器风格\n\n特点\n\n模型\n视图\n控制器\n\n\n优点\n\n多个视图与一个模型相对应。变化一一传播机制确保了所有相关视图都能够及\n时地获取模型变化信息，从而使所有视图和控制器同步，便于维护\n具有良好的移植性。由于模型独立于视图，因此可以方便的实现不同部分的移植\n系统被分割为三个独立的部分，当功能发生变化时，改变其中的一个部分就能满足要求\n\n\n缺点\n\n增加了系统设计和运行复杂性\n视图与控制器连接过于紧密，妨碍了二者的独立重用\n视图访问模型的效率比较低。由于模型具有不同的操作接口，因此视图需要多次访问模型才能获得足够的数据\n频繁访问未变化的数据，也将降低系统的性能\n\n\n\n\n\n\n\n Chapter 5 架构描述语言\n\n什么是软件架构描述语言\n\nADL（Architecture description language）用于任何软件架构的表示形式\n\n\n为何有多种软件架构描述语言\n\n//TODO\n\n\nADL的核心设计元素\n\n组件(Component)\n\n表示系统中主要的计算元素和数据存储，如客户端、服务器、数据库等\n\n\n连接件(Connector)\n\n定义了组件之间的交互关系，如过程调用、消息传递、事件广播等\n\n\n软件架构配置（ArchitectureConfiguration）\n\n描述组件、连接件之间的拓扑关系\n\n\n约束条件（constraint)\n\n定义组件之间依赖、组件与连接件之间依赖的约束\n\n\n\n\n\n Chapter 6 软件架构与敏捷开发\n\n\n敏捷开发的基本理念\n\n强调个体和互动比强调过程和工具更好\n强调获得可运行的软件比强调完成详尽的文档好\n强调与客户合作比强调进行详细的合同谈好\n强调响应变化比强调遵循既定的计划好\n\n\n\n尽早并持续地交付有价值的软件以满足顾客需求\n敏捷流程欢迎需求的变化，并利用这种变化来提高用户的竞争优势\n经常交付可用的软件，发布间隔可以从几周到几个月，能短则短\n业务人员和开发人员在项目开发过程中应该每天共同工作\n选择有进取心的人作为项目核心人员，充分支持并信任他们\n无论团队内外，面对面交流始终是最有效的沟通方式\n可用的软件是衡量项目进展的主要指标\n敏捷流程应能保持可持续发展。责任人，开发者和用户应该能够保持一个长期的，恒定的开发速度\n不断关注技术和设计能增强敏捷能力\n保持简明（尽可能简化工作量的技巧）\n最高的构架，需求和设计出自于自组织的团队\n时时总结如何提高团队效率，并付诸行动\n\n\n\n敏捷开发与架构的设计的关系\n\n软件架构与敏捷开发的出发点是一致的\n\n目的：提高软件开发效率，提高软件质量，降低软件成本，将开发团队的价值最大化（权衡的过程）\n\n\n敏捷开发也要重视软件架构\n敏捷开发改变了软件架构的设计方式\n\n\n\n敏捷开发中如何改变了软件架构的设计方式\n\n\n敏捷开发非常重视软件的架构设计，但是轻架构的详细设计\n\n\n敏捷思想中进传统的架构设计分成\n\n\n种子架构设计\n\n软件的架构层次\n重要模块\n重要的说明类\n\n\n\n详细架构设计\n\n\n\n敏捷开发把传统软件开发前期的详细架构设计分散到了整个敏捷开发软件过程中，以达到提高效率，减少风险的目的\n\n\n\n\n\n\n\n两类常见敏捷架构设计方法\n\n\n规划式设计和演进式设计，具体体现为初始化阶段设计和迭代过程中的设计\n\n\n团队设计\n\n\n群体决策\n\n\n优点\n\n团队设计的理论依据是群体决策。其结论要比个人决策更加完整，避免个人遗漏，相对稳定、周密\n\n\n\n缺点\n\n需要额外付出沟通成本、决策效率低、责任不明\n确等。\n\n\n\n\n\n简单设计\n\n敏捷的思想要求软件架构设计必须是简单设计\n\n表达方式的简单化\n现实抽象的简单化。\n\n敏捷开发中对详细架构描述文档等中间产物的弱化，只满足有效沟通即可\n\n\n现实抽象的简单化\n\n仅针对当前需求建模分析，不做“多余的&quot;工作\n\n\n\n\n简单设计可以降低开发成本、提升沟通效率、增强适应性和稳定性\n\n\n\n\n\n Chapter 7 架构驱动的软件开发\n\n\n架构驱动的软件开发步骤和开发流程\n\n\n步骤\n\n架构需求获取\n基本架构设计\n架构记录和文档化\n架构评估\n架构实现\n架构维护\n\n\n\n开发流程\n\n\n\n\n\n\n质量场景、质量模型\n\n抽象场景\n\n根据软件的使用进行一定层面的分类（如：软件流水线方式、三层结构等），这些分类就会对相应软件提出一定的需求，此类需求即为架构需求的抽象场景\n\n\n质量场景\n\n架构需求要用质量场景进行描述\n\n对于架构师和领域专家来说，需要做的是从抽象场景描述中获得特定的质量属性场景\n通常来说，我们考虑的特定的质量场景是对性能、可移植性、可替换性、可重用性等质量属性产\n生影响时的质量场景\n\n\n\n\n质量模型\n\n软件质量理想模型\n\n质量场景进行描述，可以用来描述，评估和预测质量属性的模型\n可以清晰地描述质量模型中元素和元素之间的相互关系的模型\n实例化的软件质量理想模型和对质量场景的注解\n\n\n\n\n\n\n\n架构的结构\n\n通过一定的结构对软件的架构进行描述，把这样的结构称为架构结构\n架构结构描述了架构的基本信息，也包括了类，方法，对象，文件，库等所有需要人做的设计和编码\n架构视图是由架构结构派生而出的，它可以是架构结构的子部分，也可以是多个架构结构信息的综合\n\n\n\n Chapter 8 软件架构建模方法\n\n\n成功的软件架构应具有的品质\n\n良好的模块化\n适应功能需求的变化，适应技术的变化\n对系统的动态运行有良好的规划\n对数据的良好规划\n明确，灵活的部署规划\n\n\n\n将软件架构的概念和原则引入软件需求阶段有什么好处？不引入可能会引起什么问题？\n\n好处\n\n有助于保证需求规约 ，系统设计之间的可追踪新和一致性，有效保持软件质量\n有助于更有结构性和可重用的需求规约\n\n\n用传统方法产生需求规约，不考虑软件架构概念和原则，，则在软件架构设计阶段建立需求规约与架构的映射将相对困难\n\n\n\n软件架构和软件需求是如何协同演化的？\n\n软件需求和软件架构两者是相辅相成的关系，一方面软件需求影响软件架构设计，另一方面软件架构帮助需求分析的明确和细化\n\n\n\n需求与架构的相互影响可以看作一个螺旋的过程，也是一个双峰的过程\n\n\n\n\n\n\n将软件架构映射到详细设计经常遇到什么问题？如何解决？\n\n问题\n\n缺失重要架构视图，片面强调功能需求\n不够深入，架构设计方案过于笼统，基本还停留在概念性架构的层面，没有提供明确的技术蓝图\n名不副实的分层架构，缺失层次之间的交互接口和交互机制，只进行职责划分\n在某些方面过度设计。\n\n\n解决方案\n\n对于缺失重要架构视图问题，可以针对遗漏的架构视图进行设计\n对于不够深入问题，需要将设计决策细化到和技术相关的层面\n对于名不副实的分层架构问题，需要步步深入，明确各层之间的交互接口和交互机制\n虽然我们必须考虑到系统的扩展性，可维护性等，但切忌过度设计\n\n\n\n\n\nMDAmodel driven architecture基于模型驱动软件架构的基本思想，应用MDA的好处\n\n计算无关模型(CIM.Comutation Independent Model)也称业务模型\n\n描述系统的外部行为和运行环境\n\n\n平台无关模型(PIM,Platform Independent Model)\n\n具有高抽象层次、无关于任何实现技术的模型\n\n\n平台特定模型(PSM,Platform secific Model)\n\n为某种特定实现技量身定做，让你用这种技术中可用现构造来描述系统的模型。PIM会被变换一个或多个PSM\n\n\nMDA开发步骤\n\n用计算无关模型CIM捕获需求\n\n创建平台无关模型PIM\n将PIM转化成为一个或多个平台特定模型PSM，并加入平台特定的规则和代码\n将PSM转化为代码等\n\n\n\n\n基本思想\n\n将软件系统分成模型和实现两部分\n\n模型是对系统的描述，实现是利用特定技术在特定平台或环境中对模型的解释。模型仅仅负责对系统的描述与实现技术无关。这是模型的实现技术无关性\n\n\n\n\n好处\n\n将模型与实现分离后，能够很好的适应技术易变性。由于实现往往高度依赖特定技术和特定平台，当技术发生迁移时，只需针对这种技术作相应的实现，编写相应的运行平台或变换工具。所以，能够比较好的应对实现技术发展带来的挑战\n\n\n\n\n\n架构设计原则\n\n一般原则\n\n商业原则\n数据原则\n应用程序原则\n技术原则\n\n\n关键设计原则\n\n关注分离点\n单一职责原则\n最少知识原则\n\n\n\n\n\n Chapter 15 软件架构评估方法\n\n\n软件架构评估的必要性\n\n软件体系结构的好坏关系到软件产品的好坏，软件产品的好坏关系到软件公司的发展\n通过评估能了解系统的体系结构和重要属性（质量属性），能够屏蔽风险，带来诸多收益\n到目前为止没有很好的自动化评估系统\n\n\n\n软件架构评估的方式分类\n\n基于调查问卷或检查表的评估方式\n基于场景的评估方式\n基于度量的评估方式\n质量属性、（质量）场景基于场景的评估\n\n\n\n体系结构权衡分析方法（ATAM）的相关概念、评估过程（步骤）、优缺点\n\n基本概念\n\n敏感点(Sensitivity point)\n\n敏感点是一个或多个构件的特征\n敏感点可以使设计师搞清楚实现质量目标时应该注意什么\n\n\n权衡点(Tradeoffpoint)\n\n权衡点是影响多个质量属性的特征\n是多个质量属性的敏感点\n权衡点需要进行权衡\n\n\n敏感点影响一个质量属性\n权衡点影响多个质量属性\n风险承担者，涉众，牵涉到的人\n场景\n\n刺激\n环境\n响应\n\n\n\n\n评估过程\n\n陈述，包括通过它进行的信息交流\n\nATAM方法的陈述\n商业动机的陈述\nSA的陈述\n\n\n调查与分析，包括对照体系结构方法评估关键质量属性需求\n\n确定体系结构方法\n生成质量效用树\n分析体系结构方法\n\n\n测试，包括对照所有相关人员的需求检验最新结果\n\n集体讨论并确定场景优先级\n分析体系结构方法\n\n\n形成报告，包括陈述ATAM的结果\n\n结果的表述\n\n\n\n\n\n\n\n软件体系结构分析方法（SAAM）的评估过程（步骤）、优缺点（敏感点、权衡点、效用树…）\n\n\n评估过程\n\n\n\n场景的形成\n体系结构的表述\n场景分类和优先级的确定\n对场景的单个评估\n场景相互作用的评估\n形成总体评估\n\n\n\n\n\n Chapter 9软件架构的演化和维护\n\n\n软件架构演化的目的\n\n维持软件架构自身的有用性\n\n\n\n软件架构演化的实施\n\n\n软件架构演化方式的分类\n\n\n静态演化：需求、过程\n\n\n需求\n\n设计时演化需求\n\n在架构开发和实现过程中对原有架构进行调整，保证软件实现与架构的一致性以及软件开发过程的顺利进行\n运行前演化需求：软件发布之后由于运行环境的变化，需要对软件进行修改升级，在此期间软件的架构同样要进行演化\n\n\n\n\n\n过程\n\n\n\n软件理解\n\n查阅软件文档，分析软件架构，识别系统组成元素及其之间的相互关系，提取系统的抽象表\n示形式\n\n\n需求变更分析\n\n静态演化往往是由于用户需求变化、系统运行出错和运行环境发生改变等原因所引起的,需要找出新的软件需求与原有的差异\n\n\n演化计划\n\n分析原系统，确定演化范围和成本，选择合适的演化计划\n\n\n系统重构\n\n根据演化计划对系统进行重构，使之适应当前的需求\n\n\n系统测试\n\n对演化后的系统进行测试，查找其中的错误和不足之处\n\n\n\n\n\n\n\n动态演化：需求、类型、内容、技术\n\n需求\n\n软件内部执行所导致的体系结构改变\n是软件系统外部的请求对软件进行的重配置\n\n\n类型\n\n交互动态性\n结构动态性\n架构动态性\n\n\n内容\n\n属性改名\n\n在运行过程中，用户可能会对非功能指标进行重新定义，如服务响应时间等\n\n\n行为变化\n\n在运行过程中，用户需求变化或系统自身服务质量的调节，都将引发软件行为的变化。如：为了提高安全级别而更换加密算法；将http协议改为https协议\n\n\n拓扑结构改变\n\n如增、删组件，增、删连接件，改变组件与连接件之间的关联关系等\n\n\n风格变化\n\n一般软件演化后其架构风格应当保持不变，如果非要改变软件的架构风格，也只能将架构风格变为其“衍生&quot;风格，如将两层c/s结构调整为三层c/s结构或c/s和B/s的混合结构\n\n\n\n\n技术\n\n动态软件架构 (SDA, Dynamic Software Architecture)\n动态重配置 (DR, Dynamic Reconfiguration)\n\n\n\n\n\n\n\n软件架构演化原则\n\n\n成本控制原则\n\n\n进度可控原则\n\n\n风险可控原则\n\n\n主体维持原则\n\n\n系统总体结构优化原则\n\n\n平滑演化原则\n\n\n目标一致原则\n\n\n模块独立烟花原则/修改局部化原则\n\n\n影响可控原则\n\n\n复杂性可控原则\n\n\n有利于重构原则\n\n\n有利于重用原则\n\n\n设计原则遵从性原则\n\n\n适应新技术原则\n\n\n环境适应性原则\n\n\n标准依从性原则\n\n\n质量向好原则\n\n\n适应新需求原则\n\n\n\n\n","plink":"hanyuulu.github.io/SoftwareArchitecture/"},{"title":"systemCall添加自定义项目","date":"2019-03-18T18:14:00.000Z","updated":"2021-03-12T08:22:58.594Z","content":"\np.s:因为这个md解析器有些调皮……所以可能偷偷改了一些样式导致阅读障碍…… \n如果遇到了请帮助我改正这些错误，谢谢。\n\n 一，基本信息\n\n\n\n实验题目\n向 Linux 内核增加一个系统调用\n\n\n\n\n完成人姓名\nHanyuu Furude\n\n\n学号\n你猜( ﹁ ﹁ ) ~→\n\n\n报告日期\n2019/03/18\n\n\n\n 二，实验目的\n通过实验，熟悉 Linux 操作系统的使用，掌握构建与启动 Linux 内核的方法；\n掌握用户程序如何利用系统调用与操作系统内核实现通信的方法，加深对系统调\n用机制的理解；进一步掌握如何向操作系统内核增加新的系统调用的方法，以扩 展操作系统的功能。\n 三，实验内容\n\n\nLinux 环境下的 C 或 C++编译和调试工具的使用。\n\n\n向 Linux 内核增加新的系统调用，系统调用名称和功能自行定义，但必须 实现如下输出功能：“My Student No. is ×××，and My Name is ×××”。\n\n\nLinux 新内核的编译、安装和配置。 4. 编写应用程序以测试新的系统调用并输出测试结果。\n\n\n 四，实验步骤\n 思路\n在计算中，系统调用是计算机程序从其执行的操作系统内核请求服务的编程方式。这可能包括与硬件相关的服务（例如，访问硬盘驱动器）、新进程的创建和执行以及与集成内核服务（如进程调度）的通信。系统调用提供了进程和操作系统之间的基本接口。\n除了一些嵌入式系统之外，大多数现代处理器的体系结构都涉及到一个安全模型。例如，环模型规定了软件可以在多个特权级别下执行：一个程序通常被限制在它自己的地址空间，这样它就不能访问或修改其他正在运行的程序或操作系统本身，并且通常被阻止直接操作硬件设备（如帧缓冲区或网络）设备）。\n通常，系统提供一个库或API，位于正常程序和操作系统之间。在类Unix系统上，该API通常是C库（libc）实现（如glibc）的一部分，glibc为系统调用提供包装函数，通常与它们调用的系统调用命名相同。在Windows NT上，该API是nt dll.dll库中本机API的一部分；这是常规Windows API的实现所使用的未经记录的API，并且直接由Windows上的某些系统程序使用。库的包装函数公开了使用系统调用的普通函数调用约定（程序集级别的子例程调用），并使系统调用更模块化。这里，包装器的主要功能是将要传递给系统调用的所有参数放在适当的处理器寄存器中（也可能放在调用堆栈上），并为内核设置一个唯一的系统调用号。这样，在操作系统和应用程序之间存在的库就增加了可移植性。\n 步骤\n 系统版本\ndeepin-15.9-amd64\n 原内核版本\n4.15.0-29deepin-generic\n\n 后内核版本\n4.19.29\n\n 具体步骤\n\n下载Linux内核4.19.29\n\n\n\n\n解压\n\n\nxz -d linux-4.19.29.tar.xz\ntar -xf linux-4.19.29.tar\n\n\n\n\n将源代码移动到/usr/src文件夹下\n\n\n安装一些后面要用到的依赖\n\n\n笔者在安装时未记录缺少的依赖，应当根据需要安装（安装时提示缺少什么就安装什么）\n\nsudo apt install ncurses-static.x86_64\nsudo apt install openssl-static.x86_64\nsudo apt install libelf-dev\n\n\n\n进入系统调用入口表（记录了System Call的一些基本信息）\n\n\nvim ./arch/x86/entry/systemCallAdds/systemCallAdd_64.tbl\n\n​\t添加自定义的系统调用\n\n\n\n调用号\nabi\n调用名称\n入口（函数名）\n\n\n\n\n548\ncommon\nhanyuu\nsys_hanyuu\n\n\n\n\n\n添加系统调用声明\n\n\nvim ./include/linux/systemCallAdds.h\n\n若函数无参数则填写void\n\n\n实现系统调用\n\n./kernel/sys.c\n\n内核态下应当使用printk()\n用户态下使用printf()\n\n\n\n编译内核\n\n预处理\n\nsudo make menuconfig\n\n无需裁剪内核或者更改直接两次按ESC退出即可\n\n\n编译内核\n\n\nj[n]指示同时允许n个任务参与编译，请根据配置调整，笔者此处配置为\n\nCPU: Intel 8500 (6C6T all for Hyper-V)\nMemory: 40G (15G for Deepin in Hyper-V)\nDisk: Samsung 850 EVO (60G virtual disk)\n\n在Hyper-V虚拟机中该配置表现较为良好\n\n\nsudo make -j64\n截图为完成过后重新演示截图，此处j32，效率稍低\n\n\n\n漫长的编译时光……还是挺吃配置的……\n\n\n\nsudo make modules_install\n\n\n\nmake install\n安装编译好的内核\n\na. 编译完成后，重启\n\nsudo reboot\n\nb. 编写程序调用定义好的System Call\n\nprintk()处于内核态不会直接在屏幕上打印，但是他的输出可以在/proc/kmsg目录下查看\n\n\n使用dmesg也可以查看系统调用。\n​\n 五，主要数据结构及其说明\nLinux 内核包含已知的所有系统调用的列表, 即所谓的 系统调用表(System call)。 每个系统调用都分配一个唯一的数字和一个内核内部函数, 负责实际完成所需的任务。若要执行系统调用, 所需呼叫的数量存储在 CPU 的EAX 寄存器中, 然后触发软件中断 128。根据 FastCall 调用约定, 系统调用上的参数将传入 CPU 寄存器中。\n软件异常 在用户模式下中断程序执行, 并强制在内核模式下执行异常处理程序。这将确保上下文从无特权的环更改为环0。被称为异常处理程序是内核中的一个函数, 它读出 EAX 寄存器, 然后, 如果它包含有效的系统调用号码, 则从系统调用表中相应的内核函数与后续寄存器调用参数。在查看参数后, 从 “用户” 模式请求的任务最终由内核完成。如果此功能返回, 异常处理程序也将成功完成, 正常的程序流将继续在无特权模式下。\n\nmov $6, %eax ; close() ist Systemaufruf 6\nmov $15, %ebx ; Dateideskriptor als erstes Argument\nint $0x80  ; Softwareinterrupt\n\n 六，程序运行时的初值和结果\n无初值，结果为printk()函数中的内容，截图见上文。\n 七，实验体会\nSystem call 作为沟通上下层的连接件，其实现没有想象中的那么难也不算简单，只要敢于尝试就会有所收获。\n 八，源程序并附上注释\n\n./arch/x86/entry/systemCallAdds/systemCallAdd_64.tbl\n\n\n548\tcommon hanyuu sys_hanyuu //添加系统调用入口表\n\n\ninclude/linux/systemCallAdds.h\n\n\namslink sys_hanyuu(void);\t//自定义系统调用声明\n\n\nkernel/sys.c\n\n12345678910111213141516171819/** Hanyuu's system call*/asmlinkage long sys_hanyuu(void)\t//自定义系统调用实现&#123;printk(\"\\n[[hanyuu]] System call start\\n\");printk(\"my student number is [N/A] and my name ls Hanyuu Furude.\");printk(\"\\n[[hanyuu]] System call end\\n\");return 0;&#125;hanyuu.c// 测试程序#include &lt;unisted.h&gt;int main()&#123;systemcall(548);\t//调用自定义系统调用return 0;&#125;","plink":"hanyuulu.github.io/systemCallAdd/"},{"title":"vim Reference","date":"2019-03-08T18:33:38.000Z","updated":"2021-03-12T08:22:58.614Z","content":"\nVim编辑程序有三种操作模式，分别称为 编辑模式、插入模式 和 命令模式，当运行Vim时，首先进入编辑模式\n在 vim 内部通过 ! 前缀可以执行 shell 命令\n\n编辑模式\n\n\n\n快捷键\nChange\nDelete\nYank(Copy)\n\n\n\n\nLine\ncc\ndd\nyy\n\n\nLetter\ncl\ndl\nyl\n\n\nWord\ncw\ndw\nyw\n\n\n\n跳转\n字符移动\n    h，j，k，l 左下上右\n\n行内移动\n    w 正向移动到相邻单词的首字符\n    b 逆向移动到相邻单词的首字符\n    B 向前一个单词,以空格和TAB为分隔符\n    e 正向移动到相邻单词的尾字符\n    ge 逆向移动到相邻单词的尾字符\n    0 数字０，左移光标到本行的开始；\n    $ 右移光标，到本行的末尾；\n    ^ 移动光标，到本行的第一个非空字符\n\n页移动\n    H 跳转到当前屏幕的第一行\n    M 跳转到本屏显示的中间一行\n    L 跳转到最后一行\n    2H 表示将光标移到屏幕的第２行\n    3L 表示将光标移到屏幕的倒数第3行\n    z + enter 是当前行成为屏幕的第一行\n    z + - 是当前一行成为最后一行\n    ctrl + f 在文件中前移一页（相当于 page down）；\n    ctrl + b 在文件中后移一页（相当于 page up）；\n    ctrl + d 往下滚动半屏\n    ctrl + u 往上滚动半屏\n\n文件移动\n    gg 跳到首行\n    G 调到尾行\n    nG 跳转到n行\n    % 跳到另一边括号\n\n配合查找字符的方式移动\n    fa 正向移动到第一个字符 a 处\n    Fa 逆向移动到第一个字符 a 处\n\n非相邻的单词或字符间移动\n    8w 正向移动到相隔八个单词的首字符\n    4Fa 逆向移动到第四个 a 字符\n\n更大范围的移动\n    * 当光标停留在一个单词上，* 键会在文件内搜索该单词，并跳转到下一处；\n    # 当光标停留在一个单词上，# 在文件内搜索该单词，并跳转到上一处；\n    (/) 移动到 前/后 句 的开始；\n    {/} 跳转到 当前/下一个 段落 的开始。\n    g_ 到本行最后一个不是 blank 字符的位置。\n    fa 到下一个为 a 的字符处，你也可以fs到下一个为s的字符。\n    t, 到逗号前的第一个字符。逗号可以变成其它字符。\n    3fa 在当前行查找第三个出现的 a。\n    F/T 和 f 和 t 一样，只不过是相反方向;\n    gg 将光标定位到文件第一行起始位置；\n    G 将光标定位到文件最后一行起始位置；\n    NG或Ngg 将光标定位到第 N 行的起始位置\n\n搜索匹配\n    /text 向后搜索\n    ？text 向前搜索\n    :g/targetWord 全局搜索\n    :%s/oldWord/newWord/gc 全局替换\n    n 搜索下一个同样的内容\n    N 搜索上一个同样的内容\n\n替换和删除\nVim常规的删除命令是 d、 x (前者删除 行 ，后者删除 字符 ),结合Vim的其他特性可以实现基础的删除功能。将光标定位于文件内指定位置后，可以用其他字符来替换光标所指向的字符，或从当前光标位置删除一个或多个字符或一行、多行\n    gg dG 删除全部内容\n    d0 删除至行首\n    dl 删除当前字符， dl=x\n    dh 删除前一个字符\n    dd 删除当前行\n    dj 删除上一行\n    dk 删除下一行\n    dw 删除到下一个单词开头\n    de 删除到本单词末尾\n    dE 删除到本单词末尾包括标点在内\n    db 删除到前一个单词\n    dB 删除到前一个单词包括标点在内\n    10d 删除当前行开始的10行\n    d$ 删除当前字符之后的所有字符（本行）\n    D 删除当前字符至行尾。D=d$\n    kd gg 删除当前行之前所有行（不包括当前行）\n    jdG 删除当前行之后所有行（不包括当前行）\n    :1,10d 删除1-10行\n    :11,$d 删除11行及以后所有的行\n    :1,$d 删除所有行\n    J 删除两行之间的空行，实际上是合并两行\n    rc 用 c 替换光标所指向的当前字符；\n    nrc 用 c 替换光标所指向的前 n 个字符；\n    5rA 用 A 替换光标所指向的前 5 个字符；\n    x 删除光标所指向的当前字符；\n    nx 删除光标所指向的前 n 个字符；\n    3x 删除光标所指向的前 3 个字符；\n    dw 删除光标右侧的字；\n    ndw 删除光标右侧的 n 个字；\n    3dw 删除光标右侧的 3 个字；\n    db 删除光标左侧的字；\n    ndb 删除光标左侧的 n 个字；\n    5db 删除光标左侧的 5 个字；\n    dd 删除光标所在行，并去除空隙；\n    ndd 删除（剪切） n 行内容，并去除空隙；\n    3dd 删除（剪切） 3 行内容，并去除空隙；\n    Vim常规的替换命令有 c 和 s ，结合Vim的其他特性可以实现基础的替换功能，不过替换命令执行以后，通常会由 编辑模式 进入 插入模式\n    s 用输入的正文替换光标所指向的字符；\n    S 删除当前行，并进入编辑模式；\n    ns 用输入的正文替换光标右侧 n 个字符；\n    nS 删除当前行在内的 n 行，并进入编辑模式；\n    cw 用输入的正文替换光标右侧的字；\n    cW 用输入的正文替换从光标到行尾的所有字符（同 c$ )；\n    ncw 用输入的正文替换光标右侧的 n 个字；\n    cb 用输入的正文替换光标左侧的字；\n    ncb 用输入的正文替换光标左侧的 n 个字；\n    cd 用输入的正文替换光标的所在行；\n    ncd 用输入的正文替换光标下面的 n 行；\n    c$ 用输入的正文替换从光标开始到本行末尾的所有字符；\n    c0 用输入的正文替换从本行开头到光标的所有字符。\n\n复制粘贴\n    yy 拷贝当前行\n    nyy 拷贝当前后开始的n行，比如2yy拷贝当前行及其下一行\n    *“+y 复制 1 行到操作系统的粘贴板\n    *“+nyy 复制 n 行到操作系统的粘贴板\n    :1,10 co 20 将1-10行插入到第20行之后\n    :1,co\n\n    将整个文件复制一份并添加到文件尾部\n    正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按y即可复制\n    ddp 交换当前行和其下一行\n    xp 交换当前字符和其后一个字符\n    正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按d即可剪切\n    ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴\n    :1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。\n    :1, 10 m 20 将第1-10行移动到第20行之后。\n    x 剪切当前字符\n    3x 剪切当前光标开始向后三个字符\n    X 剪切当前字符的前一个字符。X=dh\n    p 粘贴到下一行或右侧，修改和删除的数据自动到粘贴板中\n    P 粘贴到上一行或左侧\n    如果是要替换别的单词，则先按 v 进入 visual mode，选中要替换的单词，再按粘贴即可,粘贴板中就换成了被替换的单词\n    yiw （yank inner word）在一个单词的任意字母使用,就复制该单词\n    yw 则只是复制从光标所在字母到词尾的部分\n\n撤销和重复\n    u 撤销最近一次修改 undo\n    . 重复最后一条修改正文的命令\n    U 撤销所有修改\n    ctrl + r 取消最后一次的撤销 redo\n\n块编辑\n    v 可进入visual模式，使用标准快捷键移动光标可选择文本块，之后可输入标准编辑命令\n    ctrl + v 列编辑\n    行尾块…\n\n命令行模式下的一些技巧\n    DTc 删除从光标的c之间的所有字符\n    Rc 将光标的字符替换为c\n    nDD 删除n行数据\n    nYY 复制n行数据\n    nX 删除n个字符\n    R 进入替换状态，esc退出\n\n插入模式\n进入\n    i 在当前位置生前插入\n    I 在当前行首插入\n    a 在当前位置后插入\n    A 在当前行尾插入\n    o 在当前行之后插入一行\n    O 在当前行之前插入一行\n    s 删掉当前字符，并进行输入\n    x 删掉当前字符，停留在Normal模式\n\n退出\n    Esc\n    ctrl + O 暂时性的\n    ctrl + C 取消当前的任何操作\n    ctrl + [ 官方推荐替换Esc\n\n移动光标 尽量不要进入插入模式移动光标\n    ctrl + H 光标移当前行行首 imap\n    ctrl + J 光标移下一行行首 imap\n    ctrl + K 光标移上一行行尾 imap\n    ctrl + L 光标移当前行行尾 imap\n    Alt + H 光标左移一格 imap\n    Alt + J 光标下移一格 imap\n    Alt + K 光标上移一格 imap\n    Alt + L 光标右移一格 imap\n\n命令模式\n打开、保存\n:e path_to_file/filename 在已经启动的Vim中打开一个文件\n:w 保存当前编辑的文件\n:w file_temp 将当前文件另存为file_temp\n\n退出\nZZ 保存并退出\n:wq 保存并退出\n:e! 放弃所有修改，并打开原来文件\nShift +Z,Q 无条件退出\nq! 无条件退出\nctrl + Z 退出vim，不推荐，会生成.swp的文件\n\n行号与文件\n    编辑中的每一行正文都有自己的行号，用下列命令可以移动光标到指定行（效果与 编辑模式 下的 ngg 或 nG 相同）\n\n:n 将光标移到第 n 行\n\n命令模式下，可以规定命令操作的行号范围。数值用来指定绝对行号；字符“.”表示光标所在行的行号；字符符“$”表示正文最后一行的行号；简单的表达式，例如“.+5”表示当前行往下的第 5 行。例如\n:345         将光标移到第 345 行\n:345w file   将第 345 行写入 file 文件\n:3,5w file   将第 3 行至第 5 行写入 file 文件\n:1,.w file   将第 1 行至当前行写入 file 文件\n:.,$w file   将当前行至最后一行写入 file 文件\n:.,.+5w file 从当前行开始将 6 行内容写入 file 文件\n:1,$w file   将所有内容写入 file 文件，相当于 :w file 命令\n\n在命令模式下，允许从文件中读取正文，或将正文写入文件\n:w         将编辑的内容写入原始文件，用来保存编辑的中间结果\n:wq        将编辑的内容写入原始文件并退出编辑程序（相当于 ZZ 命令）\n:w file    将编辑的内容写入 file 文件，保持原有文件的内容不变\n:a,bw file 将第 a 行至第 b 行的内容写入 file 文件\n:r file    读取 file 文件的内容，插入当前光标所在行的后面\n:e file    编辑新文件 file 代替原有内容\n:f file    将当前文件重命名为 file\n:f         打印当前文件名称和状态，如文件的行数、光标所在的行号等\n\n字符串搜索\n    在 编辑模式 讲过字符串的搜索，此处的 命令模式 也可以进行字符串搜索，给出一个字符串，可以通过搜索该字符串到达指定行。如果希望进行正向搜索，将待搜索的字符串置于两个 / 之间；如果希望反向搜索，则将字符串放在两个 ? 之间\n\n:/str/               正向搜索，将光标移到下一个包含字符串 str 的行\n:?str?               反向搜索，将光标移到上一个包含字符串 str 的行\n:/str/w file         正向搜索，并将第一个包含字符串 str 的行写入 file 文件\n:/str1/,/str2/w file 正向搜索，并将包含字符串 str1 的行至包含字符串 str2 的行写\n\nVim中的正则表达式\n:/struct/ 要搜索一行正文，这行正文的开头包含 struct 字\n因为它只找出在行中任意位置包含 struct的第一行，并不一定在行的开始包含 struct 。解决问题的办法是在搜索字符串前面加上特殊字符^\n:/^struct/\n也可以用类似办法在搜索字符串后面加上表示行的末尾的特殊字符 $ 来找出位于行末尾的字\n:/struct$/\n\n下表给出大多数特殊字符和它们的含义\n^                放在字符串前面，匹配行首的字；\n$                放在字符串后面，匹配行尾的字；\n\\&lt;               匹配一个字的字头；\n\\&gt;               匹配一个字的字尾；\n.                匹配任何单个正文字符；\n[str]            匹配 str 中的任何单个字符；\n[^str]           匹配任何不在 str 中的单个字符；\n[a-b]            匹配 a 到 b 之间的任一字符；\n*                匹配前一个字符的 0 次或多次出现；\n\\                转义后面的字符。\n\n正文替换\n    利用 :s 命令可以实现字符串的替换\n\n:%s/str1/str2/        用字符串 str2 替换行中首次出现的字符串 str1\n:s/str1/str2/g        用字符串 str2 替换行中所有出现的字符串 str1\n:.,$ s/str1/str2/g    用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1\n:1,$ s/str1/str2/g    用字符串 str2 替换正文中所有出现的字符串 str1\n:g/str1/s//str2/g     功能同上\n:m,ns/str1/str2/g     将从m行到n行的str1替换成str2\n\n从上述替换命令可以看到：\ng 放在命令末尾，表示对搜索字符串的每次出现进行替换,不止匹配每行中的第一次出现；不加 g，表示只对搜索字符串的首次出现进行替换；g 放在命令开头，表示对正文中所有包含搜索字符串的行进行替换操作\ns 表示后面跟着一串替换的命令\n% 表示替换范围是所有行，即全文\n统计当前文件中字符串 str1 出现的次数\n:%s/str1/&amp;/gn\n\n删除正文\nVim的初级删除命令是用 d ，高级删除命令可以用 正则替换 的方式执行\n:d                              删除光标所在行\n:3d                             删除 3 行\n:.,$d                           删除当前行至正文的末尾\n:/str1/,/str2/d                 删除从字符串 str1 到 str2 的所有行\n:g/^\\(.*\\)$\\n\\1$/d              删除连续相同的行，保留最后一行\n:g/\\%(^\\1$\\n\\)\\@&lt;=\\(.*\\)$/d     删除连续相同的行，保留最开始一行\n:g/^\\s*$\\n\\s*$/d                删除连续多个空行，只保留一行空行\n:5,20s/^#//g                    删除5到20行开头的 # 注释\n\n恢复文件\n    Vim 在编辑某个文件时，会另外生成一个临时文件，这个文件的名称通常以 . 开头，并以 .swp 结尾。Vim 在正常退出时，该文件被删除，若意外退出，而没有保存文件的最新修改内容，则可以使用恢复命令 :recover 来恢复文件，也可以在启动Vim时用 -r 选项\n\n选项设置\n    为控制不同的编辑功能，Vim 提供了很多内部选项。利用 :set 命令可以设置选项。基本语法为\n\n:set option 设置选项 option\n\n常见的功能选项包括：\nautoindent        设置该选项，则正文自动缩进\nignorecase        设置该选项，则忽略规则表达式中大小写字母的区别\nnumber            设置该选项，则显示正文行号\nruler             设置该选项，则在屏幕底部显示光标所在行、列的位置\ntabstop           设置按 Tab 键跳过的空格数。例如 :set tabstop=n，n 默认值为 8\nmk                将选项保存在当前目录的 .exrc 文件中\n\n分屏\n    :vsplit（可用缩写 :vsp） 左右分屏\n    :split（可用缩写 :sp） 上下分屏\n    ctrl + w + hjkl 窗口之间移动\n    ctrl + w + w 逆时针遍历\n    ctrl + w = 让所有的屏都有一样的高度；\n    ctrl + w + 增加高度；\n    ctrl + w - 减少高度。\n    另外，也可以在终端里启动vim时就开启分屏操作\n    vim -On file1 file2… 打开 file1 和 file2 ，垂直分屏\n    vim -on file1 file2… 打开 file1 和 file2 ，水平分屏\n\n标签页\n    Vim的标签（Tab）页，类似浏览器的标签页，一个标签页打开一个Vim的窗口，一个Vim的窗口可以支持N个分屏\n\n:tabnew 在Vim中新建一个标签\n:tabnew filename 如果要在新建标签页的同时打开一个文件，则可以在命令后面直接附带文件路径\n\nVim中的每个标签页有一个唯一的数字序号，第一个标签页的序号是0，从左向右依次加一。关于标签页有一系列操作命令，简介如下\n:tN[ext]                跳转到上一个匹配的标签\n:tabN[ext]              跳到上一个标签页\n:tabc[lose]             关闭当前标签页\n:tabdo                  为每个标签页执行命令\n:tabe[dit]              在新标签页里编辑文件\n:tabf[ind]              寻找 'path' 里的文件，在新标签页里编辑之\n:tabfir[st]             转到第一个标签页\n:tabl[ast]              转到最后一个标签页\n:tabm[ove]  N           把标签页移到序号为N位置\n:tabnew [filename]      在新标签页里编辑文件\n:tabn[ext]              转到下一个标签页\n:tabo[nly]              关闭所有除了当前标签页以外的所有标签页\n:tabp[revious]          转到前一个标签页\n:tabr[ewind]            转到第一个标签页\n\n外部工具集成\n    Vim可以与许多外部程序集成，功能十分强大，比如 diff , ctags , sort , xxd 等等\n\ndiff\n    Linux命令 diff 用来对比两个文件的内容，不过对比结果显示在终端里，可读性比较差。结合Vim，在终端里可以直接输入命令 vimdiff，后面跟两个文件名作为参数：\n    vimdiff file1 file2\n    即可在Vim里分屏显示两个文件内容的对比结果，对文件内容差异部分进行高亮标记，还可以同步滚动两个文件内容，更可以实时修改文件内容，方便程度和用户体验大大提高。\n    vimdiff a.txt b.txt\n    如果直接给 -d 选项是一样的\n    vim -d a.txt b.txt\n    除了在终端里开启vimdiff 功能，也可以在打开Vim后，在Vim的命令模式输入相关命令来开启 vimdiff 功能：\n    :diffsplit abc.txt\n    如果你现在已经开启了一个文件，想Vim帮你区分你的文件跟 abc.txt 有什么区别，可以在Vim中用 diffsplit 的方式打开第二个文件，这个时 候Vim会用 split（分上下两屏）的方式开启第二个文件，并且通过颜色，fold来显示两个文件的区别\n    这样Vim就会用颜色帮你区分开2个文件的区别。如果文件比较大（源码）重复的部分会帮你折叠起来。\n    :diffpatch filename\n    通过 :diffpatch 你的patch的文件名，就可以以当前文件加上你的patch来显示。vim会split一个新的屏，显示patch后的信息并且用颜色标明区别。\n    如果不喜欢上下对比，喜欢左右（比较符合视觉）可以在前面加 vert ，例如：\n    :vert diffsplit abc.txt\n    :vert diffpatch abc.txt\n    看完diff，用 :only 回到原本编辑的文件，觉得diff的讨厌颜色还是在哪里，只要用 :diffoff 关闭就好了。\n    还有个常用的diff中的就是 :diffu ,这个是 :diffupdate 的简写，更新的时候用\n\nsort\n    Linux命令 sort 可以对文本内容进行按行中的字符比较、排序，但在终端里使用 sort 命令处理文件，并不能实时查看文件内容。具体用法请自查手册。\n\nxxd\n    vim+xxd 是Linux下最常用的二进制文本编辑工具，xxd其实是Vim外部的一个转换程序，随Vim一起发布，在Vim里调用它来编辑二进制文本非常方便。\n    首先以二进制模式在终端里打开一个文件：\n    vim -b filename\n    Vim 的 -b 选项是告诉 Vim 打开的是一个二进制文件，不指定的话，会在后面加上 0x0a ，即一个换行符。\n    然后在Vim的命令模式下键入：\n    :%!xxd\n    即可看到二进制模式显示出来的文本，看起来像这样：\n\n0000000: 1f8b 0808 39d7 173b 0203 7474 002b 4e49  ....9..;..tt.+NI\n0000010: 4b2c 8660 eb9c ecac c462 eb94 345e 2e30  K,......b..4^.0\n0000020: 373b 2731 0b22 0ca6 c1a2 d669 1035 39d9  7;'1.&quot;.....i.59\n\n然后就可以在二进制模式下编辑该文件，编辑后保存，然后用下面命令从二进制模式转换到普通模式：\n:%!xxd -r\n\n另外，也可以调整二进制的显示模式，默认是 2 个字节为一组，可以通过 g 参数调整每组字节数：\n:%!xxd -g 1         表示每1个字节为1组\n:%!xxd -g 2         表示每2个字节为1组(默认)\n:%!xxd -g 4         表示每4个字节为1组\n\n","plink":"hanyuulu.github.io/vim/"},{"title":"Keras简单样例代码","date":"2019-02-26T20:30:33.000Z","updated":"2021-03-12T08:22:58.562Z","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# https://tensorflow.google.cn/guide/kerasimport numpy as npimport tensorflow as tffrom tensorflow.keras import layersprint('[tensorflow.version]:', tf.VERSION)print('[tensorflow.keras.version]:', tf.keras.__version__)# 序列模型# 在 Keras 中，您可以通过组合层来构建模型。模型（通常）是由层构成的图。最常见的模型类型是层的堆叠：tf.keras.Sequential 模型。model = tf.keras.Sequential()# adds a densely-connected layer with 64 units to the modelmodel.add(layers.Dense(64, activation='relu'))# add anothermodel.add(layers.Dense(64, activation='relu'))# add a softmax layer with 10 output unitsmodel.add(layers.Dense(10, activation='softmax'))# 配置层# 我们可以使用很多 tf.keras.layers，它们具有一些相同的构造函数参数：# activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。# kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。# kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。# Create a sigmoid layerlayers.Dense(64, activation='sigmoid')# Orlayers.Dense(64, activation=tf.sigmoid)# a liner layer with L1 regularization of factor 0.01 applied to the kernal matrixlayers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))# A linear layer with L2 regularization of factor 0.01 applied to the bias vectorlayers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))# A linear layer with a kernel initialized to a random orthogonal matrixlayers.Dense(64, kernel_initializer='orthogonal')# A linear layer with a bias vector initialized to 2.0s:layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))# 训练和评估# 设置训练流程# 构建好模型后，通过调用 compile 方法配置该模型的学习流程：model = tf.keras.Sequential([    # Adds a densely-connected layer with 64 units to the model:    layers.Dense(64, activation='relu'),    # Add another:    layers.Dense(64, activation='relu'),    # Add a softmax layer with 10 output units:    layers.Dense(10, activation='softmax')])model.compile(optimizer=tf.train.AdamOptimizer(0.001),              loss='categorical_crossentropy',              metrics=['accuracy'])# tf.keras.Model.compile 采用三个重要参数：# optimizer：此对象会指定训练过程。从 tf.train 模块向其传递优化器实例，例如 tf.train.AdamOptimizer、tf.train.RMSPropOptimizer 或 tf.train.GradientDescentOptimizer。# loss：要在优化期间最小化的函数。常见选择包括均方误差(mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。# metrics：用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象。# Configure a model for mean-squared error regression.model.compile(optimizer=tf.train.AdamOptimizer(0.01),              loss='mse',       # mean squared error              metrics=['mae'])  # mean absolute error# Configure a model for categorical classification.model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),              loss=tf.keras.losses.categorical_crossentropy,              metrics=[tf.keras.metrics.categorical_accuracy])data = np.random.random((1000, 32))labels = np.random.random((1000, 10))model.fit(data, labels, epochs=10, batch_size=32)# tf.keras.Model.fit 采用三个重要参数：# epochs：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。# batch_size：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。# validation_data：在对模型进行原型设计时，您需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。data = np.random.random((1000, 32))labels = np.random.random((1000, 10))val_data = np.random.random((100, 32))val_labels = np.random.random((100, 10))model.fit(data, labels, epochs=10, batch_size=32,          validation_data=(val_data, val_labels))","plink":"hanyuulu.github.io/keras/"},{"title":"Anaconda导出环境/从外部安装环境","date":"2019-02-25T00:00:00.000Z","updated":"2021-03-12T08:22:58.534Z","content":"\n填坑中…\n导出已有环境：\n\n1conda env export &gt; environment.yaml\n环境会被保存在 environment.yaml文件中。\n当我们想再次创建该环境，或根据别人提供的.yaml文件复现环境时，可以：\n1conda env create -f environment.yaml1","plink":"hanyuulu.github.io/anaconda_env/"},{"title":"再生核希尔伯特空间(RKHS)","date":"2019-02-17T00:00:00.000Z","updated":"2021-03-12T08:22:58.442Z","content":"\n【转载，文末有出处】\n\n 核函数\n每一个函数fff都可以看做一个无限维的向量，那么二元函数K(x,y)K(x,y)K(x,y) 就可以看做是一个无限维的矩阵。如果它满足：\n\n正定性\n\n∫∫f(x)K(x,y)f(y)dxdy≥0\\int \\int f(\\mathrm{x})K(\\mathrm{x},\\mathrm{y})f(\\mathrm{y})d \\mathrm{x} d\\mathrm{y} \\geq 0\n∫∫f(x)K(x,y)f(y)dxdy≥0\n\n对称性:\n\nK(x,y)=K(y,x)K(\\mathrm{x},\\mathrm{y}) = K(\\mathrm{y},\\mathrm{x})\nK(x,y)=K(y,x)\n那么它就是一个核函数。\n与矩阵特征值和特征向量类似，核函数存在特征值和特征函数（将函数看做无限维向量）。也就是，\n∫K(x,y)ψ(x)dx=λψ(y)\\int K(\\mathrm{x},\\mathrm{y}) \\psi (\\mathrm{x}) d\\mathrm{x} = \\lambda \\psi (\\mathrm{y})\n∫K(x,y)ψ(x)dx=λψ(y)\n对于不同的特征值 λ1\\lambda_1λ1​, λ2\\lambda_2λ2​及其对应的特征方程 ψ1(x)\\psi_1(\\mathrm{x})ψ1​(x) , ψ2(x)\\psi_2(\\mathrm{x})ψ2​(x) ,\n∫λ1ψ1(x)ψ2(x)dx=∫λ2ψ2(x)ψ1(x)dx\\int \\lambda_1 \\psi_1(\\mathrm{x}) \\psi_2(\\mathrm{x}) d \\mathrm{x} = \\int \\lambda_2 \\psi_2(\\mathrm{x}) \\psi_1(\\mathrm{x}) d \\mathrm{x}\n∫λ1​ψ1​(x)ψ2​(x)dx=∫λ2​ψ2​(x)ψ1​(x)dx\n因此，&lt;ψ1,ψ2&gt;=∫ψ1(x)ψ2(x)dx=0&lt;\\psi_1, \\psi_2&gt; = \\int \\psi_1(\\mathrm{x}) \\psi_2(\\mathrm{x}) d \\mathrm{x} = 0&lt;ψ1​,ψ2​&gt;=∫ψ1​(x)ψ2​(x)dx=0 。也就是说特征方程是正交的。\n一个核函数对应无穷个特征值 {λi}i=1∞\\{ \\lambda_i \\}_{i=1}^\\infty{λi​}i=1∞​ 和无穷个特征方程 {φi}i=1∞\\{ \\varphi_i \\}_{i=1}^\\infty{φi​}i=1∞​ 。和矩阵类似，\nK(x,y)=∑i=0∞λiψi(x)ψi(y)K(\\mathrm{x},\\mathrm{y}) = \\sum_{i=0}^{\\infty} \\lambda_i \\psi_i(\\mathrm{x}) \\psi_i(\\mathrm{y})\nK(x,y)=i=0∑∞​λi​ψi​(x)ψi​(y)\n这就是Mercer定理。这里， &lt;ψi,ψj&gt;=0,i≠j。{ψ}i=1∞&lt;\\psi_i, \\psi_j&gt;=0 , i \\ne j 。 \\{ \\psi \\}_{i=1}^{\\infty}&lt;ψi​,ψj​&gt;=0,i̸​=j。{ψ}i=1∞​ 是原来函数空间的一组正交基。\nRKHS\n将 {λiψi}i=1∞\\{\\sqrt{ \\lambda_i} \\psi_i \\}_{i=1}^\\infty{λi​​ψi​}i=1∞​ 作为一组正交基构建一个希尔伯特空间 H\\mathcal{H}H 。这个空间中的任何一个函数（向量）都可以表示为这组基的线性组合。如\nf=∑i=1∞fiλiψif= \\sum_{i=1}^{\\infty} f_i \\sqrt{\\lambda_i} \\psi_if=∑i=1∞​fi​λi​​ψi​\n那么 f 就可以表示为 H\\mathcal{H}H 中的一个无限维的向量：\nf=(f1,f2,...)HTf= (f_1,f_2,...)_{\\mathcal{H}}^T\nf=(f1​,f2​,...)HT​\nK(x,y)K(\\mathrm{x},\\mathrm{y})K(x,y) 表示二元函数或无限维矩阵， K(x,⋅)K(\\mathrm{x},\\cdot)K(x,⋅) 就可以表示矩阵第 x 行的一元函数或无限维向量，也就是固定核函数的一个参数为 x\\mathrm{x}x ，那么\nK(x,⋅)=∑i=0∞λiψi(x)ψiK(\\mathbf{x},\\cdot) = \\sum_{i=0}^{\\infty} \\lambda_i \\psi_i (\\mathbf{x}) \\psi_i\nK(x,⋅)=i=0∑∞​λi​ψi​(x)ψi​\n将每一项除去对应的基底，对应到空间 H\\mathcal{H}H中的向量就是\nK(x,⋅)=(λ1ψ1(x),λ2ψ2(x),...)HTK(\\mathrm{x},\\cdot) = ( \\sqrt{\\lambda_1} \\psi_1(\\mathrm{x}), \\sqrt{\\lambda_2} \\psi_2(\\mathrm{x}), ... )_{\\mathcal{H}}^T\nK(x,⋅)=(λ1​​ψ1​(x),λ2​​ψ2​(x),...)HT​\n同样的，\nK(y,⋅)=(λ1ψ1(y),λ2ψ2(y),...)HTK(\\mathrm{y},\\cdot) = ( \\sqrt{\\lambda_1} \\psi_1(\\mathrm{y}), \\sqrt{\\lambda_2} \\psi_2(\\mathrm{y}), ... )_{\\mathcal{H}}^T\nK(y,⋅)=(λ1​​ψ1​(y),λ2​​ψ2​(y),...)HT​\n因此，\n&lt;K(x,⋅),K(y,⋅)&gt;H=∑i=0∞λiψi(x)ψi(y)=K(x,y)。&lt; K(\\mathbf{x},\\cdot), K(\\mathbf{y},\\cdot) &gt;_\\mathcal{H} = \\sum_{i=0}^{\\infty} \\lambda_i \\psi_i (\\mathbf{x}) \\psi_i(\\mathbf{y}) = K(\\mathbf{x},\\mathbf{y}) 。\n&lt;K(x,⋅),K(y,⋅)&gt;H​=i=0∑∞​λi​ψi​(x)ψi​(y)=K(x,y)。\n以上就是核的可再生性(reproducing)，即用核函数来再生两个函数的内积。 H\\mathcal{H}H 也被叫做可再生核希尔伯特空间(RKHS, reproducing kernel Hilbert space)。\n如果定义了一个映射，\nΦ(x)=K(x,⋅)=(λ1ψ1(x),λ2ψ2(x),⋯&ThinSpace;)T\\boldsymbol{\\Phi} (\\mathbf{x}) = K(\\mathbf{x},\\cdot) = (\\sqrt{\\lambda_1} \\psi_1 (\\mathbf{x}), \\sqrt{\\lambda_2} \\psi_2 (\\mathbf{x}), \\cdots )^T\nΦ(x)=K(x,⋅)=(λ1​​ψ1​(x),λ2​​ψ2​(x),⋯)T\n将点 x\\mathrm{x}x 映射到空间 H\\mathcal{H}H 。那么，\n&lt;Φ(x),Φ(y)&gt;H=&lt;K(x,⋅),K(y,⋅)&gt;H=K(x,y)。&lt; \\boldsymbol{\\Phi} (\\mathbf{x}), \\boldsymbol{\\Phi} (\\mathbf{y}) &gt;_\\mathcal{H} = &lt; K(\\mathbf{x},\\cdot), K(\\mathbf{y},\\cdot) &gt;_\\mathcal{H} = K(\\mathbf{x},\\mathbf{y}) 。\n&lt;Φ(x),Φ(y)&gt;H​=&lt;K(x,⋅),K(y,⋅)&gt;H​=K(x,y)。\n因此，我们并不需要知道这个映射是什么，特征空间在哪里，只要是一个对称正定的函数 K ，就必然存在映射 Φ\\PhiΦ 和特征空间 H\\mathcal{H}H ,使得\n&lt;Φ(x),Φ(y)&gt;=K(x,y)。&lt; \\boldsymbol{\\Phi} (\\mathbf{x}), \\boldsymbol{\\Phi} (\\mathbf{y}) &gt; = K(\\mathbf{x},\\mathbf{y}) 。\n&lt;Φ(x),Φ(y)&gt;=K(x,y)。\n这就是所谓的核技巧(kernel trick)。\n\n转载:\n\n再生核希尔伯特空间-cplusplus \n所有权利归原作者所有，非盈利非商业用途，侵删\n\n\n","plink":"hanyuulu.github.io/RKHS/"},{"title":"将文件从git commit记录中抹除","date":"2019-02-15T00:00:00.000Z","updated":"2021-03-12T08:22:58.542Z","content":" 清理过大的git文件夹\n 列出git历史中最大的deepth个文件\n1git verify-pack -v .git/objects/pack/[fingerPoint].idx | sort -k [deepth] -n | tail -[deepth]\n\n\nexample:\n\ninput\n\n1git verify-pack -v .\\.git\\objects\\pack\\pack-f13f96d5194e9f568b7723e0427cbc343930bfbb.idx\n\noutput\n\n123451a1c62895eb17949c2dd60043e536d6a6afe3626 commit 656 515 122db819c543801fcc5ca910430f61d2532e880be0 tree   37 48 527ac3fb948a48f9164b91ca35264a077d001981ea7 blob   61 63 575non delta: 3 objects.\\.git\\objects\\pack\\pack-f13f96d5194e9f568b7723e0427cbc343930bfbb.pack: ok\n\n\n 查询对应的文件名\n1git rev-list --objects --all | grep [fileFingerPoint]\n\n\nexample:\n\ninput\n\n  1git rev-list --objects --all | grep ac3fb948a48f9164b91ca35264a077d001981ea7\noutput\n  1ac3fb948a48f9164b91ca35264a077d001981ea7 README.md\n 将文件从所有commit中（如果有，删除）\n  1git filter-branch -tree-filter 'rm -f [fileName]' HEAD\n 运行整理\n  1git gc\n 精简不存在的branch\n  1git remote prune [branchName]\n 查看所有分支的所有操作历史\n  1git rflog --all\n\n","plink":"hanyuulu.github.io/gitClear/"},{"title":"lagrange multiplier拉格朗日乘子法","date":"2019-02-13T15:05:58.000Z","updated":"2021-03-12T08:22:58.406Z","content":"基本的拉格朗日乘子法就是求函数f(x1,x2,…)在约束条件g(x1,x2,…)=0下的极值的方法。\n其主要思想是将约束条件函数与原函数联立，从而求出使原函数取得极值的各个变量的解。\n 定义\n对于具有l个等式约束的n维优化问题\nmin f(x1,x2,⋅⋅⋅), s.t. hk(x1,x2,⋅⋅⋅,xn) (k=1,2,⋅⋅⋅,l)min\\ f(x_1,x_2,\\cdot \\cdot \\cdot),\\ s.t. \\  h_k(x_1,x_2,\\cdot\\cdot\\cdot,x_n)\\ (k=1,2,\\cdot\\cdot\\cdot,l)\nmin f(x1​,x2​,⋅⋅⋅), s.t. hk​(x1​,x2​,⋅⋅⋅,xn​) (k=1,2,⋅⋅⋅,l)\n把原目标函数f(x)f(x)f(x)改造成为如下形式的新的目标函数\nF(x,λ)=f(x)+∑k=1lλkhk(x)F(x,\\lambda)=f(x)+\\sum_{k=1}^l\\lambda_kh_k(x)\nF(x,λ)=f(x)+k=1∑l​λk​hk​(x)\n式中的hk(x)h_k(x)hk​(x)就是原目标函数f(x)f(x)f(x)的等式约束条件，而待定系数λk\\lambda_kλk​称为拉格朗日乘子。这种方法称为拉格朗日乘子法。在极值点处，有\n∂F∂λxi=0 (i=1,2,⋅⋅⋅,n)\\frac{\\partial F}{\\partial \\lambda x_i}=0\\  (i=1,2,\\cdot\\cdot\\cdot,n)\n∂λxi​∂F​=0 (i=1,2,⋅⋅⋅,n)\n和\n∂F∂λk=0 (k=1,2,⋅⋅⋅,l)\\frac{\\partial F}{\\partial \\lambda_k}=0\\ (k=1,2,\\cdot\\cdot\\cdot,l)\n∂λk​∂F​=0 (k=1,2,⋅⋅⋅,l)\n，共有n+ln+ln+l个方程，足以算出这n+ln+ln+l个变量，此法也称为升维法。\n 基本原理\n拉格朗日乘子法是一种经典的求解条件极值的解析方法，可将所有约束的优化模型问题转化为无约束极值问题的求解。一般带不等式约束的最优化问题求解如下式：\n\\begin{equation}\n\\left\\{\n\t\\begin{array}{lr}\n\tmin\\  f(x) &amp; \\\\\n\ts.t.\\  g_i(x)\\leq0\\  (j=1,2,\\cdot\\cdot\\cdot,J)\n\t\\end{array}\n\\right.\n\\end{equation}\n\n拉格朗日乘子法是用于变量无关的是常数λi (j=1,2,⋅⋅⋅,J)\\lambda_i\\  (j=1,2,\\cdot\\cdot\\cdot,J)λi​ (j=1,2,⋅⋅⋅,J)分别乘各约束函数gi(x)≤0 (j=1,2,⋅⋅⋅J)g_i(x)\\leq0\\ (j=1,2,\\cdot\\cdot\\cdot J)gi​(x)≤0 (j=1,2,⋅⋅⋅J)并与目标函数相加得到如下的拉格朗日函数：\nL(x,λ,v)=f(x)+∑j=1Jλj[gj(x)+vj2]L(x,\\lambda,v)=f(x)+\\sum_{j=1}^{J}{\\lambda_j[g_j(x)+v^2_j]}\nL(x,λ,v)=f(x)+j=1∑J​λj​[gj​(x)+vj2​]\n，式中：x=[x1,x2,⋅⋅⋅,xj]Tx=[x_1,x_2,\\cdot\\cdot\\cdot,x_j]^Tx=[x1​,x2​,⋅⋅⋅,xj​]T为自变量；λ=[λ1,λ2,⋅⋅⋅,λj]T\\lambda=[\\lambda_1,\\lambda_2,\\cdot\\cdot\\cdot,\\lambda_j]^Tλ=[λ1​,λ2​,⋅⋅⋅,λj​]T为拉格朗日乘子量；v=[v1,v2,⋅⋅⋅,vj]Tv=[v_1,v_2,\\cdot\\cdot\\cdot,v_j]^Tv=[v1​,v2​,⋅⋅⋅,vj​]T为松弛变量。\n则L(x,λ,v)L(x,\\lambda ,v)L(x,λ,v)在x∗​x^*​x∗​处取极值的必要条件为：\n\\begin{equation}\n\\left\\{\n\t\\begin{array}{lr}\n\t\\frac{\\partial L}{\\partial x_k}=\\frac{\\partial f(x)}{\\partial x_k}+\\sum^J_{j=1}{\\lambda_j\\frac{\\partial g(x)}{\\partial x_k}}=0 &amp; \\\\\n\t\\frac{\\partial L}{\\partial \\lambda}=\\sum^J_{j=1}{(g_i(x)+v^2_j)}=0 &amp; \\\\\n\t\\frac{\\partial L}{\\partial v}=\\sum^J_{j=1}2\\lambda_jv_j=0\n\t\\end{array}\n\\right.\n\\end{equation}\n\n，依据上式求得x∗x^*x∗即为最优解。\n\n参考：\n\n拉格朗日乘子法\n拉格朗日乘子法：写得很通俗的文章\n非盈利非商业使用，侵删\n\n\n","plink":"hanyuulu.github.io/LagrangeMultiplier/"},{"title":"范数","date":"2019-02-12T23:00:00.000Z","updated":"2021-03-12T08:22:58.562Z","content":" L−PL-PL−P范数\n与闵可夫斯基距离的定义一样，L−PL-PL−P范数不是一个范数，而是一组范数，其定义如下\nLp=∑inxipp x=x1,x2,⋅⋅⋅,xnL_p=\\sqrt[p]{\\sum_i^n{x^p_i}}\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\nLp​=pi∑n​xip​​ x=x1​,x2​,⋅⋅⋅,xn​\n根据P​的变化，范数也有着不同的变化，一个经典的有关P​范数的变化图如下：\n\n\n上图表示了P从∞\\infty∞到000变化时，三维空间中到原点的距离（范数）为111的点构成的图形的变化情况。以常见的L−2L-2L−2范数（p=2p=2p=2）为例，此时的范数也即欧氏距离，空间中到原点的欧氏距离为111的点构成了一个球面。实际上，在0≤p≤10\\leq p\\leq10≤p≤1\n时，LpL_pLp​并不满足三角不等式的性质，也就不是严格意义下的范数。以p=0.5p=0.5p=0.5，二维坐标(1,4),(4,1),(1,9)(1,4),(4,1),(1,9)(1,4),(4,1),(1,9)为例，1+40.5+4+10.5&lt;1+90.5\\sqrt[0.5]{1+\\sqrt{4}}+\\sqrt [0.5]{\\sqrt{4}+1}&lt;\\sqrt[0.5]{1+\\sqrt{9}}0.51+4​​+0.54​+1​&lt;0.51+9​​。因此这里的L-P范数只是一个概念上的宽泛说法。\n L0L0L0范数\n当P=0P=0P=0时，也就是L0L0L0范数，由上面可知，L0L0L0范数并不是一个真正的范数，它主要被用来度量向量中非零元素的个数。用上面的L-P定义可以得到的L-0的定义为：\n∣∣x∣∣=∑1nxi00 x=x1,x2,⋅⋅⋅,xn||x||=\\sqrt[0]{\\sum_1^nx^0_i}\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\n∣∣x∣∣=01∑n​xi0​​ x=x1​,x2​,⋅⋅⋅,xn​\n这里就有点问题了，我们知道非零元素的零次方为1，但零的零次方，非零数开零次方都是什么鬼，很不好说明L0的意义，所以在通常情况下，大家都用的是：\n∣∣x∣∣0=#(i) with xi≠0||x||_0=\\#(i)\\  with\\  x_i \\neq 0\n∣∣x∣∣0​=#(i) with xi​̸​=0\n在实际应用中，由于L0L0L0范数本身不容易有一个好的数学表示形式，给出上面问题的形式化表示是一个很难(NP难)的问题。所以在实际情况中，L0的最优问题会被放宽到L1或L2下的最优化。\n (Lasso Regression)L1(Lasso\\ Regression)L1(Lasso Regression)L1范数\nL1范数是我们经常见到的一种范数，它的定义如下：\n∣∣x∣∣1=∑i=1n∣xi∣ x=x1,x2,⋅⋅⋅,xn||x||_1=\\sum _{i=1}^{n}|x_i|\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\n∣∣x∣∣1​=i=1∑n​∣xi​∣ x=x1​,x2​,⋅⋅⋅,xn​\n表示向量xix_ixi​中非零元素的绝对值之和。\nL1范数有很多的名字，例如我们熟悉的曼哈顿距离,最小绝对误差等。使用L1范数可以度量两个向量间的差异，如绝对误差和（Sum of Absolute Difference)。对于L1L1L1范数，它的优化问题如下：min∣∣x∣∣1min||x||_1min∣∣x∣∣1​ 由于L1范数的天然性质，对L1优化的解是一个稀疏解，因此L1L1L1范数也被叫做稀疏规则算子。通过L1L1L1可以实现特征的稀疏，去掉一些没有信息的特征，例如在对用户的电影爱好做分类的时候，用户有100个特征，可能只有十几个特征是对分类有用的，大部分特征如身高体重等可能都是无用的，利用L1L1L1范数就可以过滤掉。\n (Lasso Regression)L2(Lasso\\ Regression)L2(Lasso Regression)L2范数\nL2范数是我们最常见最常用的范数了，我们用的最多的度量距离欧氏距离就是一种L2范数，它的定义如下：\n∣∣x∣∣2=∑i=1nxi2||x||_2=\\sqrt{\\sum_{i=1}^{n}x^2_i}\n∣∣x∣∣2​=i=1∑n​xi2​​\n表示向量元素的平方和再开平方。 像L1L1L1范数一样，L2L2L2也可以度量两个向量间的差异，如平方差和（Sum of Squared Difference）。\n对于L2L2L2范数，它的优化问题如下：min∣∣x∣∣2min||x||_2min∣∣x∣∣2​L2L2L2范数通常会被用来做优化目标函数的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。\n L1L1L1与L2L2L2范数的比较\nL2范数越小，可以使得w的每个元素都很小，接近于0，但L1范数不同的是他不会让它等于0而是接近于0. /\n\n\n\n\n但由于L1范数并没有平滑的函数表示，起初L1最优化问题解决起来非常困难，但随着计算机技术的到来，利用很多凸优化算法使得L1最优化成为可能。\n 贝叶斯先验\n从贝叶斯先验的角度看，加入正则项相当于加入了一种先验。即当训练一个模型时，仅依靠当前的训练数据集是不够的，为了实现更好的泛化能力，往往需要加入先验项。\n\n\nL1范数相当于加入了一个Laplacean先验；\n\n\nL2范数相当于加入了一个Gaussian先验。\n如下图所示：\n\n\n\n\n L∞L\\inftyL∞范数\n当P=∞P=\\inftyP=∞时，也就是L−∞L-\\inftyL−∞范数，它主要被用来度量向量元素的最大值。用上面的L-P定义可以得到的L∞L\\inftyL∞的定义为：\n∣∣x∣∣∞=xi∞∞ x=x1,x2,⋅⋅⋅,xn||x||_\\infty=\\sqrt[\\infty]{x^\\infty_i}\\  x=x_1,x_2,\\cdot \\cdot \\cdot ,x_n\n∣∣x∣∣∞​=∞xi∞​​ x=x1​,x2​,⋅⋅⋅,xn​\n与L0L0L0一样，在通常情况下，大家都用的是：∣∣x∣∣∞=max(xi)||x||_\\infty=max(x_i)∣∣x∣∣∞​=max(xi​)来表示L∞L\\inftyL∞\n\n参考文章:\n\n\n几种范数的简单介绍 - Kobe Bryant的专栏 - CSDN博客\n\n\nL0/L1/L2范数的联系与区别\n\n\n机器学习中的范数规则化之（一）L0,L1与L2范数\n非盈利非商业性质，侵删。\n\n\n\n","plink":"hanyuulu.github.io/norm/"},{"title":"Python 依赖冲突","date":"2019-02-10T11:06:59.000Z","updated":"2021-03-12T08:22:58.570Z","content":"笔者在安装scikit-image包时发现tensorflow import时直接崩溃，后发现scikit-image(后简称skimage)和tensorflow-gpu(后简称tensorflow)都依赖于numpy包，不幸的是，最新版本的scikit-image和tensorflow依赖的numpy包版本不相同并且互相不兼容(　o=^•ェ•)o　┏━┓，笔者也曾经在各搜索引擎寻找解决方案……无非是重装或者更新numpy版本，（然而并没有啥用.jpg）\n如果您也遇到了相同的问题……（先为您默哀一秒）\n目前笔者收集到的的解决方案有如下几种：\n\n更新您的冲突依赖到最新版本（未必有效，笔者这种情况就无解，但是这是代价最小的一种方法，如果能用这种办法解决就再好不过了，所以请有限尝试此办法）\n寻找某个历史版本的包使两者使用相同的numpy版本（如果是其他包的其他依赖冲突则寻找使用冲突依赖的相同版本的包）（至于版本改动带来的功能差异……您只能对应的修改您的实现）\n将您的实现分开使用不同的环境跑（我知道这听起来很不爽但是如果您一定要用冲突的版本可能也只有这个办法了……手动修改实现的巨擘除外）\n使用其他包代替（听起来像废话但是这的确是个方法2333）\n自闭（简单粗暴）（逃）\n我没有发现而您觉得行之有效的任何方法，请务必赐教笔者，感激不尽，orz\n\n 举例说明\n笔者冲突的包是\n\nscipy 1.2.1\ntensorflow 1.12.0\n被依赖的冲突的包是\nnumpy\n报错现象\nRuntimeError: module compiled against API version 0xc but this version of numpy is 0xb\n解决方法\ntensorflow 1.12.0版本过高导致numpy兼容性问题(tensorflow-gpu 1.12.0还有其他已知bug,此处不表)逐级降低tensorflow版本到1.10.0之后发现问题消失可以正常使用\n兼容的一组包\nscipy 1.2.1\ntensorflow 1.10.0\n\n 写在最后\n配置环境一直都是比较玄学的问题(没有经验的情况下),如果您遇到了环境问题,请先保持冷静,保持冷静,冷静,然后,上网看看别人有没有类似的问题,如果没有的话,请耐心探索吧,这也是……一种经验吧……\n","plink":"hanyuulu.github.io/packageConflicts/"},{"title":"炼丹路上那些踩过的坑","date":"2019-02-10T00:00:00.000Z","updated":"2021-03-12T08:22:58.538Z","content":" 使用VSCode运行openCV劝退事宜\n您若使用VSCode尝试Debug openCV-Python，我们强烈建议您立刻放弃这样的尝试。因为目前VSCode插件pylint无法正常解析openCV-python.详情请见VSCode团队官方issue\n推荐使用PyCharm或者Vim(高级玩家限定)\n Why I have an error:cv2.waitkey(0) &amp; 0xff\n\n高位的2个字节由Shift, Control, Num lock等状态表示，为了消除他们的影响统一用&amp; 0xff清除这些信息。\n原文摘录，戳我跳转:\nThe answers which have already been posted suggest that some of the unusual values obtained by waitKey are due to platform differences. Below, I propose that (at least on some platforms) the apparently odd behaviour of waitKey is due to keyboard modifiers. This post looks similar to Tomasz’s answer because I initially wrote this as an edit, which was rejected.\nThe keycodes returned by waitKey change depending on which modifiers are enabled. NumLock, CapsLock, and the Shift, Ctrl, and Alt keys all modify the keycode returned by waitKey by enabling certain bits above the two Least Significant Bytes. The smallest of these flags is Shift at 0x10000.\nA modified version of the script Tomasz posted is given below:\n\n123456789101112131415#!/usr/bin/env pythonimport cv2import syscv2.imshow(sys.argv[1], cv2.imread(sys.argv[1]))res = cv2.waitKey(0)print('You pressed %d (0x%x), 2LSB: %d (%s)' % (res, res, res % 2**16,repr(chr(res%256)) if res%256 &lt; 128 else '?'))    # Which give the following results:    # q letter with NumLock:    # You pressed 1048689 (0x100071), 2LSB: 113 ('q')    # Escape key with CapsLock but not NumLock:    # You pressed 131099 (0x2001b), 2LSB: 27 ('\\x1b')    # Space with Shift and NumLock:    # You pressed 1114144 (0x110020), 2LSB: 32 (' ')    # Right Arrow Key with Control, NumLock off:    # You pressed 327507 (0x4ff53), 2LSB: 65363 ('S')\nI hope that helps to explain the unusual behaviour of waitKey and how to get the actual key pressed regardless of the state of NumLock and CapLock. From here it’s relatively simple to do something like:\n 1ctrlPressed = 0 != res &amp; (1 &lt;&lt; 18)\n…as the “control key” flag is bit 19. Shift is at bit 17, the state of CapsLock at bit 18, Alt is at bit 20, and NumLock is at bit 21.\n cuDNN 初始化失败\n\nError : Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\n如果您使用的Tensorflow版本是1.12.0…… \n这可能是个tensorflow的bug、建议回退版本观望， \nissue on github\n %matplotlib inline 报错 invalid syntax\n%matplotlib inline 是jupyter notebook/console的语法，当你调用matplotlib.pyplot绘图函数plot()或生成figure时，在python console里面生成图像。\n如果在其他地方运行，可直接注释。\n","plink":"hanyuulu.github.io/commomQuestion/"},{"title":"Medical image Data Processing","date":"2019-02-03T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":"\n转载自医疗影像数据处理–python处理nifti数据\n\n\ndicom\ndicom是由磁共振设备扫描产生的,一般是一个slice一个文件,\n分析格式: .img/.hdr\nnifti\n由fsl \\ afni \\ spm 共同确定的格式,支持3D,4D影响\n分析格式: img/hdr\ndicom -----&gt; nifti 影像处理流程\n\n\n利用spm将dicom原始数据转换为 分析格式:.img 和.hdr\n利用dcm2nifti工具将dicom数据转为nifti 3d数据\n利用spm进行3d转为4d\n处理nifti数据的可用工具：matlab\\ITK\\VTK\\python.\n我们使用python处理该类型的数据\n开发工具\n语言python2.7\npython module: nipy scipy nibabel matplotlib\n\n 获取数据形态信息及头信息\n123456789101112131415#-*- coding=utf8 -*-import nibabel as nib#import os#from nibabel.testing import data_path#d_path= os.path.join(data_path,\"1.nii\")#data1= nib.load(d_path)data1= nib.load(\"1.nii\")#数据形状print data1.shapeprint data1.affine.shapeimg = data1.get_data()#数据形状,矩阵数据每一维的数据尺寸print img.shape#数据头信息print data1.header\n 获取slice信息生成图像\n123456789101112131415161718#-*- coding=utf8 -*-import nibabel as nibimport matplotlib.pyplot as plt#把slice数据生成图片的方法def show_img(slices):fig, axes = plt.subplots(1, len(slices))for i, slice in enumerate(slices):axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")#读取nifti文件中的slice数据data1= nib.load(\"/home/lee/nifti/1.nii.gz\")img = data1.get_data()#获取单张slice数据slice_0 = img[26, :, :]slice_1 = img[:, 30, :]slice_2 = img[:, :, 16]#生成图表show_img([slice_0, slice_1, slice_2])plt.suptitle(\"show slice image\")","plink":"hanyuulu.github.io/MedicalimageDataProcessing/"},{"title":"terminology in deeplearning","date":"2019-01-31T23:36:20.000Z","updated":"2021-03-12T08:22:58.610Z","content":"\n交叉熵\nID3\nC4.5\n感知机\nSVM(支持向量机)\nSVM&amp;SVR\n再生核希尔伯特空间\n贝叶斯分类器\n极大似然估计\n图像语义分割\n卷积神经网络应用：基于Tensorflow的CNN/CRF图像分割技术\n运用图像处理解决基于MRI的脑肿瘤图像分割问题\nTensorflow实现FCN\nhttps://blog.csdn.net/taigw/article/details/51401448\nwaiting… (。・∀・)ノ\n\n","plink":"hanyuulu.github.io/terminology/"},{"title":"Python炼丹炉（maching learning）环境搭建常见问题","date":"2019-01-31T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":" Using Anaconda/Conda with Powershell\n\n\n在anaconda/conda中创建虚拟python环境：\nconda create -n env_name python=x.x\n\n\n在anaconda prompt 和 cmd中，激活一个环境：\nactivate env_name\n\n\nPowershell添加conda/anaconda支持：\n\n安装库： 1conda install -n root -c pscondaenvs pscondaenvs\n\n\n\n如果因为某些原因无法通过上述方案安装……请手动下载安装\nOffical Link： https://github.com/BCSharp/PSCondaEnvs\n\n\n\n更改PowerShell配置：\n以管理员身份启动PowerShell，并执行RemoteSigned```1234567``` powershellPS C:\\Hanyuu&gt; Set-ExecutionPolicy RemoteSigned执行策略更改执行策略可帮助你防止执行不信任的脚本。更改执行策略可能会产生安全风险，如http://go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies帮助主题所述。是否要更改执行策略?[Y] 是(Y)  [A] 全是(A)  [N] 否(N)  [L] 全否(L)  [S] 暂停(S)  [?] 帮助(默认值为“N”):Y\n\n\n此时可以正常使用Powershell切换到特定环境\n\n\n1activate [EnvironmentName]\n\n原理：其实……就是……加了个……ps1文件替换bat……（呵呵呵~）\n\n\n\n Using Jupyter with anaconda/conda\n\n\n原理：在虚拟环境下缺少kernel.json文件\n\n\nAdd a exists environment into Jupyter\n\n\nInstall ipykernel\n1conda install ipykernel\n\n\nCreate kernel files in virtual environment\n1conda install -n [EnvironmentName] ipykernel\n\n\nactivate virtual environment\n1activate [EnvironmentName]\n\n\nAdd your virtual environment into kernel for notebook\n1python -m ipykernel install --user --name [EnvironmentName] --display-name [EnvironmentDisplayName]\n\n\nopen your jupyter notebook and enjoy your pythoning : )\n1jupyter notebook\n\n\n\n\nIf your environment has not been created…\n1conda create -n [EnvironmentName] python=?.? ipykernel\n\n\nDelete a environment\n1jupyter kernelspec remote [EnvironmentName]\n\n\n Jupyter 自动补全和主题修改\nlink\n","plink":"hanyuulu.github.io/Conda/"},{"title":"Tensorflow卷积和池化","date":"2019-01-30T10:49:28.000Z","updated":"2021-03-12T08:22:58.534Z","content":" 构建基于MNSIT的多层卷积网络\n\n\n演示示例\n摘录自TensorFlow中文社区\n\n 权重初始化\n\n为了创建这个模型，我们需要创建大量的权重和偏置项。这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题（dead neurons）。为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。\n\n1234567def weight_variable(shape):  initial = tf.truncated_normal(shape, stddev=0.1)  return tf.Variable(initial)def bias_variable(shape):  initial = tf.constant(0.1, shape=shape)  return tf.Variable(initial)\n\n【Ps】：tf.truncated_normal(shape, mean, stddev) :shape表示生成张量的维度，mean是均值，stddev是标准差。这个函数产生正太分布，均值和标准差自己设定。这是一个截断的产生正太分布的函数，就是说产生正太分布的值如果与均值的差值大于两倍的标准差，那就重新生成。和一般的正太分布的产生随机数据比起来，这个函数产生的随机数与均值的差距不会超过两倍的标准差，但是一般的别的函数是可能的。\n【From】：CSDN\n\n 卷积和池化\n\nTensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。\n\n12345def conv2d(x, W):  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x):  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n 第一层卷积\n\n现在我们可以开始实现第一层了。它由一个卷积接一个max pooling完成。卷积在每个5x5的patch中算出32个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。 而对于每一个输出通道都有一个对应的偏置量。\n\n12W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])\n\n为了用这一层，我们把x变成一个4d向量，其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)。\n\n1x_image = tf.reshape(x, [-1,28,28,1])\n\nWe then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. 我们把x_image和权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pooling。\n\n12h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1)\n 第二层卷积\n\n为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5x5的patch会得到64个特征。\n\n12345W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2)\n 密集连接层\n现在，图片尺寸减小到7x7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。\n12345W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n Dropout\n\n为了减少过拟合，我们在输出层之前加入dropout。我们用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。 TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。\n\n12keep_prob = tf.placeholder(\"float\")h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n 输出层\n\n最后，我们添加一个softmax层，就像前面的单层softmax regression一样。\n\n1234W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n 训练和评估模型\n\n为了进行训练和评估，我们使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码，只是我们会用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。\n\n123456789101112131415cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))sess.run(tf.initialize_all_variables())for i in range(20000):  batch = mnist.train.next_batch(50)  if i%100 == 0:    train_accuracy = accuracy.eval(feed_dict=&#123;        x:batch[0], y_: batch[1], keep_prob: 1.0&#125;)    print \"step %d, training accuracy %g\"%(i, train_accuracy)  train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print \"test accuracy %g\"%accuracy.eval(feed_dict=&#123;    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)\n\n以上代码，在最终测试集上的准确率大概是99.2%。\n\n","plink":"hanyuulu.github.io/TensorflowConvandPool/"},{"title":"Tensorflow入坑试水","date":"2019-01-30T10:49:28.000Z","updated":"2021-03-12T08:22:58.534Z","content":" Leadin\n The computation graph\t计算图\n Building the graph\t建立一张图\n1234import tensorflow as tfmatrix1 = tf.constant([[3.,3.]]) # create a constantmatrix2 = tf.constant([[2.],[2.]])product = tf.matmul(matrix1,matrix2)  # create a matlum op(operation)\n Launching the graph in a session 在图中开启一个会话\n1234sess = tf.Session()  # create a session in tensorflowresult = sess.run(product)print(result)sess.close()   # DONT FORGET THIS!\nor\n12with tf.Session as sess:\t# Do something\n Tensors 张量\n Variables 变量\n Constant 常量\n1234567891011121314import tensorflow as tfstate = tf.Variable(0, name = 'Counter')ont = tf.constant(1)new_value = tf.add(state, one)update = tf.assign(state, new_value)init_op = tf.global_variables_initializer()# init_op = tf.initialize_all_variables()# not recommand for that will be disabled shrotly.with tf.Session() as sess:\tsess.run(init_op)\tprint(sess.run(state))\tfor _ in range(3):\t\tsess.run(update)\t\tprint(sess.run([state,one,new_value]))\n Fetch 取回\n Feed 供给\n\nPlaceholder 占位符\n\n12345input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.add(input1,input2)with tf.Session() as sess:\tprint(sess.run([output],feed_dict = &#123;input1:[7.], input2:[2.]&#125;))","plink":"hanyuulu.github.io/TensorflowLeadin/"},{"title":"Tensorflow参数参阅","date":"2019-01-30T10:49:28.000Z","updated":"2021-03-12T08:22:58.534Z","content":" Tensorflow变量类型\n\n\n\nName\nUseage\n\n\n\n\ntf.Variable\nTensor变量\n\n\ntf.constant\nTensor常量\n\n\ntf.placeholder\nTensor占位符\n\n\ntf.SparseTensor\nTensor稀疏张量\n\n\n\n 设备管理\n 查看设备列表\n1234import osfrom tensorflow.python.client import device_libos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"99\"print(device_lib.list_local_devices())\n样例输出：\n1234567891011121314151617[name: \"/device:CPU:0\"device_type: \"CPU\"memory_limit: 268435456locality &#123;&#125;incarnation: 16586473374130916263, name: \"/device:GPU:0\"device_type: \"GPU\"memory_limit: 1418693427locality &#123;  bus_id: 1  links &#123;  &#125;&#125;incarnation: 9802250829700710596physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]\n 指定某设备进行计算\n1234567891011import tensorflow as tf#选择设备 CPU-&gt;CPU:0with tf.device('/gpu:1'):    # '/gpu:0'    # '/cpu:0'    v1 = tf.constant([1.0, 2.0, 3.0], shape=[3], name='v1')    v2 = tf.constant([1.0, 2.0, 3.0], shape=[3], name='v2')    sumV12 = v1 + v2    #config=tf.ConfigProto(log_device_placement=True)打印执行操作所用的设备    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:        print sess.run(sumV12)\n 使用GPU计算要求\n若要使用Tensorflow-gpu，请检查您是否有算力大于3的NVIDIA显卡。\n\n查询显卡算力地址\n若要使用CUDA加速计算，请确保您已安装CUDA Toolkit,并且按需下载并配置您需要的Deep learning frameworks,目前，我们用到的frameworks有cuDNN,请确保您的framework和CUDA版本配套，否则无法使用。\n\n 使用交互式环境\n 查看Tensor详细情况\n123456789101112131415    #使用CPU进行计算    with tf.device(\"/cpu:0\"):        a = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0],shape=[2,3])        b = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0],shape=[3,2])        c = tf.matmul(a,b)        #查看计算时硬件的使用情况        sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))        print(sess.run(c))#设置运行时候的参数        options = tf.RunOptions(output_partition_graphs=True)        metadata = tf.RunMetadata()        c_val = sess.run(c,options=options,run_metadata=metadata)        print(metadata.partition_graphs)        #关闭session        sess.close()\n ImportError: No module named input_data\n由于版本更新，Tensorflow已经不建议再使用input_data.如果需要继续使用，请查看[input_data.py](../Example/input_data.py)\n\n TensorFlow结构\n\n使用图 (graph) 来表示计算任务.\n在被称之为 会话 (Session) 的上下文 (context) 中执行图.\n使用 tensor 表示数据.\n通过 变量 (Variable) 维护状态.\n使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n\n 基本操作符\n1import tensorflow as tf\n\n常量\n\n123import tensorflow as tfnode0 = tf.constant(3.0,dtype=tf.float32)node1 = tf.constant(3.0,dtype)# also tf.float32 implicitly\n\n会话\n\n12sess = tf.Session()print(sess.run([node0,node1]))\n\n相加计算\n\n12node2 = tf.add(node0, node1)print('node2', sess.run(node2))\n\n矩阵乘法\n\n1node2 = tf.matmul(node0,node1)\n\nPlaceholder占位符\n\n123a = tf.placeholder(tf.float32)b = tf.placeholder(tf.float32)adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n\nfeed_dict\n\n12print(sess.run(adder_node, &#123;a:3, b:4.5&#125;))print(sess.run(adder_node, &#123;a: [1,3], b: [2,4]&#125;))\n\n变量\n\n1234W = tf.Variable([.3], dtype=tf.float32)b = tf.Variable([-.3], dtype=tf.float32)x = tf.placeholder(tf.float32)linear_model = W*x + b\n\n初始化变量\n\n1init = tf.global_variables_initializer()\\\n\n求值\n\n1print(sess.run(linear_model, &#123;x: [1,2,3,4]&#125;))\n\n结束会话\n\n1sess.close()\n\n降维求和\n··· py\nloss = tf.reduce_sum()\n\n123456* 损失函数``` pyy = tf.placeholder(tf.float32)squared_deltas = tf.square(linear_model - y)    #损失函数(y(hat)-y)^2loss = tf.reduce_sum(squared_deltas)            #减小Lossprint(sess.run(loss, &#123;x: [1,2,3,4], y: [0, -1, -2, -3]&#125;))\n\n梯度下降\n\n1234567optimizer = tf.train.GradientDescentOptimizer(0.01) #梯度下降法train = optimizer.minimize(loss)                    #设定损失函数目标sess.run(init)# reset values to incorrect defaults. #初始化变量for i in range(1000):   sess.run(train, &#123;x: [1,2,3,4], y: [0, -1, -2, -3]&#125;)#迭代优化   #print(sess.run([W, b]))print(sess.run([W, b]))                             #现实更新后的W,b的值\n\n\ntf.argmax\n\n12&gt;tf.argmax(input, axis=None, name=None, dimension=None)&gt;\n\n\n此函数是对矩阵按行或列计算最大值\n 参数\n\ninput：输入Tensor\naxis：0表示按列，1表示按行\nname：名称\ndimension：和axis功能一样，默认axis取值优先。新加的字段\n返回：Tensor  一般是行或列的最大值下标向量\n\n\n\n\ntf.cast\n\n1234567&gt;   a = tf.Variable([1,0,0,1,1])&gt;   b = tf.cast(a,dtype=tf.bool)&gt;   sess = tf.Session()&gt;   sess.run(tf.initialize_all_variables())&gt;   print(sess.run(b))&gt;   [ True False False True True]&gt;\n\n\ncast(x, dtype, name=None)\n将x的数据格式转化成dtype.例如，原来x的数据格式是bool，\n那么将其转化成float以后，就能够将其转化成0和1的序列。反之也可以\n\n","plink":"hanyuulu.github.io/TensorflowRef/"},{"title":"工具链和工具索引","date":"2019-01-30T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":" Tech guide\n Coding\n\nleetcode\n\n Cpp online complier\n\ngcc.godbolt(a cpp online complier!)\ncoliru(a cpp online complier!)\n\n common website fast reference\n Version control\n\nGithub\nVisualStudioTeamService\n\n Others\n\nMSDN,I tell you\n\n Tools\n Boost\n\nboost\n\n Opencv\n\nOpenCV [Github Repo]\nOpenCV中文网站\nLearn OpenCV\n\n SQL\n\nMySQL\nMySQL workbench[SQL可视化工具]\nMySQL快速入门教程\nsqlite\n\n Python\n\nPython org\npython3教程【廖雪峰】\nrequests(爬虫)\nbase64-python\nPyQT5\nPyQT5\nxlrd (Excel文档读取)\n\n environment manager\n\nanaconda\nanaconda doc\nMiniconda&amp;doc\n\n node.js\n\nnode.js\nnode.js doc\nnode.js [cn]\n\n GUI tools\n\ncocos creator documentation\ncocos API\ncocos2d-x documentation\ncocos2d-x API\nfairygui\nfairygui_cocos2d-x SDK\nunity3d\n\n Documenting\n Markdown and components\n\nmarkdown\nshields\nmathjax\nreadthedocs\n\n HTML ,ui, color and components\n\n\nhttp://www.w3school.com.cn/xml/index.asp\n\n\nhttp://www.w3school.com.cn/htmldom/dom_intro.asp\n\n\nSAX\n\n\nnippon colors\n\n\n Latex\n\nLatex project\nLatex3 [Github repo]\nLatex with vsCode\n\n Else\n\nResilio Sync[同步工具]\nTranslucentTB[Windows任务栏美化]\nTranslucentTB[Windows任务栏美化，UWP]\nQuickLook[快速文件预览]\nQuickLook[快速文件预览，UWP]\n\n Machine Learning\n Numpy\n\nNumpy and Scipy Documentation\n\n OpenCV\n\nOpenCV Library\nOpenCV 3.4 Ref page\nOpenCV-Python doc\n\n Tensorflow\n\nTensorFlow\nTensorFlow cn\nTensorFlowTach google\nTensorFlow.js\nChainer doc\nkeras\nkeras cn google\nkeras cn\n\n Deep learning\n\nDeep Learning Book En\nDeep Learning Book Cn（github)\n Deep Learning\n Deep Learning MOOC\n Deep Learnign  MOOC_Q&amp;A_Sheet\n\n Cloud\n\nIntel AI DevCloud\n\n CUDA\n\nCUDA\nCUDnn cuda-toolkit\nTHE MNIST DATABASE of handwritten digits\n\n\n[*:These were not accessible because of GFW. : ( ]\n由旧版本主页迁移而来，\n\n","plink":"hanyuulu.github.io/Link/"},{"title":"Software Engineering Review","date":"2019-01-13T13:16:18.000Z","updated":"2021-03-12T08:22:58.458Z","content":" Chapter 00 Intorduction\n\n软件工程的概念、方法和技术：\n\n软件工程基本概念（软件产品、软件过程、软件开发模型）\n软件工程开发方法和技术\n\n传统的软件工程方法与技术\n面向对象的软件工程方法与技术\n\n\n软件测试策略和技术\n软件项目管理\n\n\n\n Chapter 01 Software and Software Engineering\n\n\nSoftware’s dual role\n\nSoftware is a product (软件即产品（服务）)\n\nTransforms information - produces, manages, acquires, modifies, displays or transmits information;\nDelivers computing potential of hardwora and networks.\n\n\nSoftware is a vehicle(载体) for delivering a product.\n\n\n\nHardware &amp; Software\n\n\nwear out vs. Deterioration 软件老化和变质\n\n\n\n\n\nComponent Based &amp; Custom Built\n\nThe software industry dose seem to be moving (slowly) toward component-based construction.\\\n\n\n\nSoftware Complexity\n\nNo Silver Bullet (智力密集型没有最优解不可预估bug不可避免)\n\n\n\n\nSoftware changeability 软件可更改性\n\nIt must be fixed to eliminate errors. 必须对其进行修复以消除错误。\nIt must be enhanced to implement new functional and non-functional requirements 必须对其进行改进, 以实现新的功能和非功能要求\nSoftware must be adapted to meet the needs of new computing environments or technology.软件必须进行调整, 以满足新的计算环境或技术的需要。\nSoftware must be enhanced to implement new business requirements.必须增强软件以实现新的业务需求。\nSoftware must be extended to make it interoperable with other more modern systems or databases.软件必须进行扩展, 以使其可与其他更现代的系统或数据库进行互操作。\nSoftware must be re-architected to make it viable(切实可行的) within a network environment.必须重新构建软件, 使其在网络环境中可行。\n\n\n\n\n\nSoftware Evolution[Lehman定律]（记标题就行）\n\nThe Law of Continuing Change [持续变化规律] (1974):  E-type systems must be continually adapted else they become progressively less satisfactory.\nThe Law of Increasing Complexity [复杂性增长规律] (1974):  As an E-type system evolves its complexity increases unless work is done to maintain or reduce it.\nThe Law of Self Regulation [自我调控规律] (1974):  The E-type system evolution process is self-regulating with distribution of product and process measures close to normal.\nThe Law of Conservation of Organizational Stability [组织稳定性守恒规律] (1980):  The average effective global activity rate in an evolving E-type system is invariant over product lifetime.\nThe Law of Conservation of Familiarity [保证通晓性规律] (1980): As an E-type system evolves all associated with it, developers, sales personnel, users, for example, must maintain mastery of(熟悉) its content and behavior to achieve satisfactory evolution.\nThe Law of Continuing Growth [持续增长规律] (1980):  The functional content of E-type systems must be continually increased to maintain user satisfaction over their lifetime.\nThe Law of Declining Quality [质量衰减规律] (1996): The quality of E-type systems will appear to be declining unless they are rigorously maintained and adapted to operational environment changes.\nThe Feedback System Law [反馈系统规律] (1996):  E-type evolution processes constitute multi-level, multi-loop, multi-agent feedback systems and must be treated as such to achieve significant improvement over any reasonable base.\n\n\n\n\nSoftware Myths 软件谬论\n\n\nSoftware Myths affect managers, customers (and other non-technical stakeholders) and practitioners\n\n\nSoftware Myths are believable because they often have elements of truth,\n\nbut …\n\nInvariably lead to bad decisions,\n\n\ntherefore …\n\nInsist on reality as you navigate your way through software engineering\n\n\n\n\n\nIf we get behind schedule, we can add more programmers and catch up.\n\n\nA general statement about objectives is sufficient to begin building programs.\n\n\nChange in project requirements can be easily accommodated because software is flexible.\n\n\nManagement Myths\n\n\n\n\n\n“We already have a book of standards and procedures for building software. It does provide my people with everything they need to know …”\n“If my project is behind the schedule, I always can add more programmers to it and catch up …”\n“If I decide to outsource the software project to a third party, I can just relax: Let them build it, and I will just pocket my profits …”\n\n\nCustomer Myths\n\n\n“A general statement of objectives is sufficient to begin writing programs - we can fill in the details later …”\n“Project requirements continually change but this change can easily be accommodated because software is flexible …”\n\n\nPractitioner’s Myths\n\n\n“Let’s start coding ASAP, because once we write the program and get it to work, our job is done …”\n“Until I get the program running, I have no way of assessing its quality …”\n“The only deliverable work product for a successful project is the working program …”\n“Software engineering is baloney[胡扯]. It makes us create tons of paperwork, only to slow us down …”\n\n Chapter 02 Process 软件过程（综述）\n\n\nOverview\n\n\nWhat? 过程是什么？当开发产品或构件系统时，遵循一系列可预测的步骤（即路线图）是非常重要的，它有助于及时交付高质量的产品。\n\n\nWho? 相关人员？管理人员、软件工程师和客户均应该参与过程的定义、建立和测试。\n\n\nWhy?重要性？提高了软件开发活动的稳定性、可控性和有组织性；否则软件活动会失控并变得混乱。\n\n\nSteps?有哪些步骤？ 具体步骤随着所构造的软件类型不同在细节方面有所变化，但对所有过程来讲有很多活动是相同的。\n\n\nWork product?有哪些工作产品？ 是指过程中定义的一系列活动和任务的结果，包括Programs, documents, and data.\n\n\nCorrect process?什么是正确的过程？ Assessment, quality deliverable.\n\n\nIEEE Definition\n\nSoftware Engineering: (1) The application of a systematic, disciplined, quantifiable[系统的、规范的和可量化的] approach to the development, operation, and maintenance of software; that is, the application of engineering to software. (2) The study of approaches as in (1).\n\n\n\n\n\n\n软件过程\n\n软件过程是一个为建造高质量软件所需完成的任务的框架，即形成软件产品的一系列步骤。包括中间产品、资源、角色及过程中采取的方法、工具等范畴。\n\n\n\nSoftware process model\n\nAttempt to organize the software life cycle by\n\ndefining activities involved in software production[软件生产]\ndefining order of activities and their relationships\n\n\nGoals of a software process\n\nstandardization, predictability, productivity, high product quality, ability to plan time and budget requirements\n\n\n\n\n\n早期做法： Code &amp; Fix\n&gt;The earliest approach\n&gt;\n&gt;*   Write code\n&gt;\n&gt;*   Fix it (修复) to eliminate any errors that have been detected, to enhance existing functionality, or to add new features\n&gt;\n&gt;*   Source of difficulties and deficiencies\n&gt;    *   impossible to predict（不可预测性）\n&gt;    *   impossible to manage\n\n\n\n软件危机 Symptoms of inadequacy: the software crisis\n\n\nscheduled time and cost exceeded\n\n\nuser expectations not met\n\n\npoor quality\n\n\nThe size and economic value of software applications require appropriate “process models”\n\n\nProcess model goals (B.Boehm 1988)\n\n\n\n\n\ndetermine the order of stages involved in software development and evolution, and to establish the transition criteria（标准尺度） for progressing from one stage to the next.  These include completion criteria for the current stage plus choice criteria and entrance criteria for the next stage. Thus a process model addresses the following software project questions:确定软件开发和进化所涉及的阶段的顺序, 并建立从一个阶段到下一个阶段的过渡标准。 其中包括当前阶段的完成标准加上选择标准和下一阶段的标准。因此, 流程模型解决了以下软件项目问题:\n\n\nWhat shall we do next?\n\n\nHow long shall we continue to do it?\n\n\n\n\n\n软件过程\n\n\n黑盒观点\n\n\n\n\n\nProblems\n\n\nThe assumption is that requirements can be fully understood prior to development\n\n\nInteraction with the customer occurs only at the beginning (requirements) and end (after delivery)\n\n\nUnfortunately the assumption almost never holds\n\n\n\n\n\n\n白盒观点\n\n\n\n\nAdvantages\n\nReduce risks by improving visibility\nAllow project changes as the project progresses\n\nbased on feedback from the customer\n\n\n\n\n\n\n\n软件开发活动\n\n线性过程模型\n非线性模型\n\n\n\n\n\n过程框架\n\n\n\n通用活动框架（非常重要）\n\n\n\n\n普适性活动 Umbrella Activities\n\nSoftware project management\nFormal technical reviews\nSoftware quality assurance\nSoftware configuration management\nWork product preparation and production\nReusability management\nMeasurement\nRisk management\n\n\n\n能力成熟度模型集成**(CMMI)\n\n\n过程评估 Process Assessment\n\n评估软件过程以确认满足了成功软件工程所必需的基本过程标准(basic\nprocess criteria**)**要求.The process should be assessed to ensure that it meets a set of basic process criteria that have been shown to be essential for a successful software engineering.\n\n\n\n\n Chapter 03 Process Models\n\n软件生命周期、概念、阶段\n软件过程模型\n\n\n\n\nPrescriptive Models[惯例模型]\n\n\nPrescriptive process models advocate an orderly approach to software engineering.\n\nquestion\n\nIf prescriptive process models strive for structure and order, are they inappropriate for a software world that thrives on change?\nYet, if we reject traditional process models (and the order they imply) and replace them with something less structured, do we make it impossible to achieve coordination and coherence in software work?\n\n\n\n\n\nThe waterfall Model 瀑布模型\n\n\n\n\n\n\n(适用于需求较为固定和明确的场景、不适应大量、频繁的更改)\n\nThe requirements are knowable in advance of implementation.\nThe requirements have no unresolved, high-risk implications.\n\n\nrisks due to COTS choices, cost, schedule, performance, safety, security, user interfaces, organizational impacts.\n\n\nThe nature of  the requirements will not change very much.\n\n\nDuring development; during evolution.\n\n\nThe requirements are compatible with all the key system stakeholders’ expectations.\n\ne.g., users, customer, developers, maintainers, investors.\n\n\nThe right architecture for implementing the requirements is well understood.\nThere is enough calendar time to proceed sequentially.~\n\n\n\n\nThe V Model V模型\n\n\n\n\n\nIncremental Models 增量模型\n\n\n\n\nRAD 模型\n\n\n\n\nEvolutionary Models 演化模型\n\n\n\n客户不确定要求 工程师对算法效率 可用性不确定\n帮助客户和工程师了解要构建的内容快速设计和实现\n\n\n\nPrototyping 原型\n\n\n\n\n\n\n原型范式中的问题\nsw 工程师尝试修改原型以用作工作版本\n一旦客户看到工作原型, 她希望很快就能得到工作产品\n\n\n\nThe Spiral 螺旋形\n\n\n\n\n\nFull Spiral Model\n\nRadial dimension[按射线方向]: cumulative cost to date\nAngular dimension[按螺旋方向]: progress through the spiral\n\n\n\n\nUP Unified Process Model 统一过程模型\n\n用例驱动\n以体系结构为中心\n迭代和增量\njia’gou\n\nLife cycle\n\n\n\n\n\n Chapter 04 Agile Development\n\n\n敏捷开发\n\n适应变更\n交流通畅\n客户参与\n有效控制\n原则\n\n尽早交付、持续交付\n欢迎变更、创造优势\n经常交付、间隔紧凑\n开发期间业务人员和开发人员在一起工作\n围绕受激励的个人、提供环境和支持并信任\n团队内部面对面交谈最有效率效果\n可持续开发、赞助人开发者用户长期稳定的开发速度\n关注优秀技能提升敏捷能力\n保持简单\n好的架构、需求、设计出自组织团队\n定时反省、及时调整\n\n\n\n\n\nIndividuals and interactions(交互) over processes and tools\nWorking software over comprehensive documentation\nCustomer collaboration over contract negotiation (谈判)\nResponding to change over following a plan\n​\t(No sliver bullet 自相矛盾而无可奈何)\n增量发布\\多生命周期\n交付产品\n\n可运行软件\n源代码\n\n使用权\n销售权\n\n\n\n\n\n\n极限编程 XP\n\n\nBegins with the creation of user stories\n\n\nAgile team assesses each story and assigns a cost\n\n\nStories are grouped to for a deliverable increment\n\n\nA commitment[承担义务] is made on delivery date[交货日期]\n\n\nAfter the first increment, project velocity is used to help define subsequent delivery dates for other                                                increments\n\n\n\n\n\n\n\n\n\n\n\n Chapter 06 系统工程\n\n系统工程中的概念\n\n元素    （软件生态系统）\n\n软件\n硬件\n人\n数据库（数据）\n文档\n规程\n\n\n层次体系\n\n\n\n\n\n\n系统建模\n\n定义在所考虑视图中满足需要的过程\n描述过程行为和该行为所依据的假设\n明确定义模型的外在和内在输入\n描述有助于工程师理解视图的全部联系\n\n\n系统建模分类\n\nBusiness Process Engineering(PBE)\n\n\n\n Chapter 07 需求工程\n\n\n需求工程任务\n\n\n初启Inception—Establish a basic understanding of the problem and the nature of the solution.\n\n\n启发Elicitation—Draw out the requirements from stakeholders.\n\n\n细化Elaboration—Create an analysis model that represents information, functional, and behavioral\naspects of the requirements.\n\n\n协商Negotiation—Agree on a deliverable system that is realistic for developers and customers.\n\n\n规范Specification—Describe the requirements formally or informally.\n\n\n验证Validation—Review the requirement specification for errors, ambiguities, omissions, and conflicts.\n\n\n需求管理Requirements management—Manage changing requirements.\n\n\n\n\n需求工程工作产品\n\n可行性和必要描述\n系统或产品的范围说明\n参与需求导出的客户、用户和其他利益共同者的列表\n系统技术环境的说明\n需求列表（含领域限制）\n一系列使用场景\n任何能更好的定义需求的原型\n\n\n\n需求开发方法\n\n需求获取：1 开始过程：与客户建立初步交流。2 导出过程：通过访问和调查，获得需求的描述\n需求分析：精化过程，通过分析建模，建立精确的技术模型，说明软件功能，特征和约束。\n需求处理：1 协商过程 2 形成规格说明 3 需求确认\n\n\n\n Chapter 08 模型分析\n\n分析模型的作用\n\nspecifies software’s operational characteristics\nindicates software’s interface with other system elements\nestablishes constraints that software must meet\n\n\n分析模型的构建原则（经验原则）\n\nThe model should focus on requirements that are visible within the problem or business domain. The level of abstraction should be relatively high.\nEach element of the analysis model should add to an overall understanding of software requirements and provide insight into the information domain, function and behavior of the system.\nDelay consideration of infrastructure and other non-functional models until design.\nMinimize coupling throughout the system.\nBe certain that the analysis model provides value to all stakeholders.\nKeep the model as simple as it can be.\n\n\n方法\n\n场景建模\n\n用况use-case\n部署图\n……\n\n\n类建模\n\nclass图\n协作图\n……\n\n\n行为建模\n\n状态转换图\n活动图\n顺序图\n\n\n\n\n\n Chapter 09 设计工程\n\n设计概念\n\n抽象abstraction\n体系结构architecture\n模式patterns\n逐步求精refinement\n模块化modularity\n信息隐藏information hiding\n模块独立functional independence\nRefactoring（重构）\n\n\n\n Chapter 10 架构设计\n\n\n为何进行体系结构设计\n\n体系结构是系统的表示形式, 使软件工程师能够:\n\n分析设计在满足其规定要求方面的有效性,\n在设计更改仍然相对容易的阶段考虑体系结构替代方案, 并且降低与软件建设相关的风险。\n\n\n\n\n\n体系结构风格（style）\n\nData-centered architecture\nData flow architecture\nCall and return architecture\nObject-oriented architecture\nLayered architecture\nEach style describes a system category that encompasses:\n\na set of components (e.g., a database, computational modules) that perform a function required by a system,\na set of connectors that enable “communication, coordination, and cooperation” among components\nconstraints that define how components can be integrated to form the system, and\nsemantic models that enable a designer to understand the overall properties of a system.\n\n\n\n\n\n\nEach style describes a system category that encompasses:\n\na set of components (e.g., a database, computational modules) that perform a function required by a system,\na set of connectors that enable “communication, coordination, and cooperation” among components,\nconstraints that define how components can be integrated to form the system, and\n\n\n\nusemantic models that enable a designer to understand the overall properties of a system.\n\n\n Chapter 11 组件设计\n\n构件\n\nA complete set of software components is defined during architectural design\nBut the internal data structures and processing details of each component are not represented at a level of abstraction that is close to code\nComponent-level design defines the data structures, algorithms, interface characteristics, and communication mechanisms allocated to each component\n\n\n构建设计原则：开关、替换、依赖倒置、接口分离、内聚性、耦合性\n构建设计方法：DPL、程序流程图、决策表\n\n Chapter 13~14 软件测试技术\n\n\nVerification 确保软件正确实现功能\n\n\nValidation 确保软件可追溯需求\n\n\n测试策略\n\n单元测试\n集成测试：big bang, top down, bottom up\n确认测试\n系统测试\n\n\n\n测试用例\n\n\n测试技术\n\n白盒、黑盒\n手工测试、自动化测试\n\n\n\n\n\n\n Chapter 15 软件产品度量\n\n\n\n软件质量\n\n\n一般来讲，软件质量是对明确陈述的功能和性能需求、明确记录的开发标准以及对所有专业化软件开发应具备的隐含特征的符合度。\n\n软件需求是质量测量的基础，不符合需求就是没有质量。\n若未能遵守开发准则，则肯定质量有问题。\n若软件符合显示需求，但未能满足其隐式需求，则软件质量仍然值得怀疑。\n\n\n\n\n\n\n度量框架\n\n\n软件产品：文档、代码、软件等\n度量手段:\n测度（measures）\n度量（metrics）\n指标（Indicators）\n度量原则\n\n•设定度量目标：The objectives of measurement should be established before data collection begins;\n•定义要明确：Each technical metric should be defined in an unambiguous manner;\n•有效理论支持：Metrics should be derived based on a theory that is valid for the domain of application (e.g., metrics for design should draw upon [利用] basic design concepts and principles and attempt to provide an indication of the presence of an attribute that is deemed desirable);\n•度量指标的选择要是最合适的：Metrics should be tailored to best accommodate specific products and processes.\n\n度量过程\n\n•Formulation【公式化】. The derivation of software measures and metrics appropriate for the representation of the software that is being considered.\n•Collection【收集数据】. The mechanism used to accumulate data required to derive the formulated metrics.\n•Analysis【分析结果】. The computation of metrics and the application of mathematical tools.\n•Interpretation【解释评估】. The evaluation of metrics results in an effort to gain insight into the quality of the representation.\n•Feedback【反馈】 Recommendations derived from the interpretation of product metrics transmitted to the software team.\n\n\n\n\n\n过程度量作用：提供能够引导长期的软件过程改进的一组过程指标。\n项目度量作用：使得软件管理者能够（1）评估正在进行中的项目的状态（2）跟踪潜在的分险（3） 在问题造成不良影响前发现他们（4）调整工作流程或任务（5）评估项目团队控制软件工作产品质 量的能力\n产品度量作用：为分析、设计、编码和测试能更客观的执行和更定量的评估提供基础\n\n Chapter 21 软件工程管理\n\n4P模型\n\nPeople — the most important element of a successful project\nProduct — the software to be built\nProcess — the set of framework activities and software engineering tasks to get the job done\nProject — all work required to make the product a reality\n\n\n\nW5HH\n\n Chapter 15，22 过程和项目度量\n\n\n\nMcCall质量因素\n\n\n\nWhy measure\n\nassess the status of an ongoing project\ntrack potential risks\nuncover problem areas before they go “critical”\nadjust work flow or tasks\nevaluate the project team’s ability to control quality of software work products.\n\n\n\n\nMeasures,Metrics,Indicators\n\n\nprocess\n\n\nprocess product\n\n\nproject\n\n\n\n\nmeasures of errors uncovered before release of the software\n\n\ndefects delivered to and reported by end-users\n\n\nwork products delivered (productivity)\n\n\nhuman effort expended\n\n\ncalendar time expended\n\n\nschedule conformance\n\n\nother measures.\n\n\n\n\n\n\n度量的作用\n\n\n Chapter 23 软件项目预算\n\n\n项目计划任务和内容\n\n\n软件项目计划\n\n建立一套务实的策略控制跟踪监视一个复杂的技术项目\n目的：保证最终结果按时高质量。\n\n\n\n属性\n\n\n项目规模\n\n\n项目工作量（人月）\n\n\n项目所需资源\n\n\n项目成本\n\n\n\n\n\n\n\nLOC&amp;FP\n\n\n\n\n\nFP:Function Point 功能点\n\n\n Chapter 24 项目进度安排和跟踪\n\n\n\n\n任务网络、关键路径的作用\n\n\n里程碑\n\n Chapter 25 风险管理\n\n风险具有不确定性和造成损失的特点\n\n\n被动风险和主动风险管理\n\nRisk Management Paradigm（风险过程管理）\n\n\n\nRMMM（Risk,Mitigation,Moritoring and Management）\n\nmitigation:如何避免/转移风险\nmonitoring:监视\nmanagement:管理\n\n\n\n Chapter 26 质量管理\n\n\nMcCall软件质量模型\n软件质量保证活动\n\n\n正式技术评审\n\n\n\n\n软件质量的成本\n\n Chapter 27 变更管理\n\n\n软件配置项、版本、基线etc.\n\n\n软件配置管理流程\n\n\n","plink":"hanyuulu.github.io/SoftwareEngineering/"},{"title":"Java 复习提纲","date":"2019-01-10T00:00:00.000Z","updated":"2021-03-12T08:22:58.406Z","content":"\n垃圾回收 System.gc()\n\n Chapter 01\n\n数据类型\n\n\n\n\n类型\n容量（bit）\n范围\n包装器\n\n\n\n\nboolean\n1\ntrue\\false\nBoolean\n\n\nchar\n16\nUnicode\nCharacter\n\n\nbyte\n8\n[−128,127][-128,127][−128,127]\nByte\n\n\nshort\n16\n[−215,215−1][-2^{15},2^{15}-1][−215,215−1]\nShort\n\n\nint\n32\n[−231,231−1][-2^{31},2^{31}-1][−231,231−1]\nInteger\n\n\nLong\n64\n[−263,263−1][-2^{63},2^{63}-1][−263,263−1]\nLong\n\n\nfloat\n32\n3.4∗10383.4*10^{38}3.4∗1038\nLong\n\n\ndouble\n64\n1.7∗103081.7*10^{308}1.7∗10308\nDouble\n\n\nvoid\n-\n-\nVoid\n\n\n\n\n\n自动类型转换\n\nbyte,short,char—&gt; int —&gt; long—&gt; float —&gt; double\n\n\n\n数据类型转换int a = (int)3.14159\n\n\nPackage\n\n\nImport\n\n\nClass\n\n\nField\n\n\nMethod\n\n\nObject\n\n\nConstract and Initialization\n\n\nAccess Control\n\n\nJava修饰符\n\n访问控制修饰符 : default, public , protected, private\n非访问控制修饰符 : final, abstract, static, synchronized\n\n\n\n继承\n\n在Java中，一个类可以由其他类派生。如果你要创建一个类，而且已经存在一个类具有你所需要的属性或方法，那么你可以将新创建的类继承该类。\n利用继承的方法，可以重用已存在类的方法和属性，而不用重写这些代码。被继承的类称为超类（super class），派生类称为子类（subclass）。\nJava 源程序与编译型运行区别\n\n一个类可以包含以下类型变量：\n\n局部变量：在方法、构造方法或者语句块中定义的变量被称为局部变量。变量声明和初始化都是在方法中，方法结束后，变量就会自动销毁。\n\n局部变量声明在方法、构造方法或者语句块中；\n\n局部变量在方法、构造方法、或者语句块被执行的时候创建，当它们执行完成后，变量将会被销毁；\n访问修饰符不能用于局部变量；\n局部变量只在声明它的方法、构造方法或者语句块中可见；\n局部变量是在栈上分配的。\n局部变量没有默认值，所以局部变量被声明后，必须经过初始化，才可以使用。\n\n\n\n\n成员变量：成员变量是定义在类中，方法体之外的变量。这种变量在创建对象的时候实例化。成员变量可以被类中方法、构造方法和特定类的语句块访问。\n类变量：类变量也声明在类中，方法体之外，但必须声明为static类型。\n\n类变量也称为静态变量，在类中以static关键字声明，但必须在方法构造方法和语句块之外。\n无论一个类创建了多少个对象，类只拥有类变量的一份拷贝。\n静态变量除了被声明为常量外很少使用。常量是指声明为public/private，final和static类型的变量。常量初始化后不可改变。\n静态变量储存在静态存储区。经常被声明为常量，很少单独使用static声明变量。\n静态变量在第一次被访问时创建，在程序结束时销毁。\n与实例变量具有相似的可见性。但为了对类的使用者可见，大多数静态变量声明为public类型。\n默认值和实例变量相似。数值型变量默认值是0，布尔型默认值是false，引用类型默认值是null。变量的值可以在声明的时候指定，也可以在构造方法中指定。此外，静态变量还可以在静态语句块中初始化。\n静态变量可以通过：ClassName.VariableName的方式访问。\n类变量被声明为public static final类型时，类变量名称一般建议使用大写字母。如果静态变量不是public和final类型，其命名方式与实例变量以及局部变量的命名方式一致。\n\n\n实例变量\n\n实例变量声明在一个类中，但在方法、构造方法和语句块之外；\n当一个对象被实例化之后，每个实例变量的值就跟着确定；\n实例变量在对象创建的时候创建，在对象被销毁的时候销毁；\n实例变量的值应该至少被一个方法、构造方法或者语句块引用，使得外部能够通过这些方式获取实例变量信息；\n实例变量可以声明在使用前或者使用后；\n访问修饰符可以修饰实例变量；\n实例变量对于类中的方法、构造方法或者语句块是可见的。一般情况下应该把实例变量设为私有。通过使用访问修饰符可以使实例变量对子类可见；\n实例变量具有默认值。数值型变量的默认值是0，布尔型变量的默认值是false，引用类型变量的默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定；\n实例变量可以直接通过变量名访问。但在静态方法以及其他类中，就应该使用完全限定名：ObejectReference.VariableName。\n\n\n一个类可以拥有多个方法，在上面的例子中：barking()、hungry()和sleeping()都是Dog类的方法。\n\n\n源文件声明规则\n\n一个源文件中只能有一个public类\n一个源文件可以有多个非public类\n源文件的名称应该和public类的类名保持一致。例如：源文件中public类的类名是Employee，那么源文件应该命名为Employee.java。\n如果一个类定义在某个包中，那么package语句应该在源文件的首行。\n如果源文件包含import语句，那么应该放在package语句和类定义之间。如果没有package语句，那么import语句应该在源文件中最前面。\nimport语句和package语句对源文件中定义的所有类都有效。在同一源文件中，不能给不同的类不同的包声明。\n\n\n\n\n\n接口\n\n在Java中，接口可理解为对象间相互通信的协议。接口在继承中扮演着很重要的角色。\n接口只定义派生要用到的方法，但是方法的具体实现完全取决于派生类。\n\n\n\n继承关键字\n\n继承可以使用 extends 和 implements 这两个关键字来实现继承，而且所有的类都是继承于 java.lang.Object，当一个类没有继承的两个关键字，则默认继承object（这个类在 java.lang 包中，所以不需要 import）祖先类。\nextends关键字\n\n在 Java 中，类的继承是单一继承，也就是说，一个子类只能拥有一个父类，所以 extends 只能继承一个类。\n\n\nimplements关键字\n\n使用 implements 关键字可以变相的使java具有多继承的特性，使用范围为类继承接口的情况，可以同时继承多个接口（接口跟接口之间采用逗号分隔）。\n\n\nsuper 与 this 关键字\n\nsuper关键字：我们可以通过super关键字来实现对父类成员的访问，用来引用当前对象的父类。\nthis关键字：指向自己的引用。\n\n\nfinal关键字\n\nfinal 关键字声明类可以把类定义为不能继承的，即最终类；或者用于修饰方法，该方法不能被子类重写：\n声明类：\n\nfinal class 类名 {//类体}\n\n\n声明方法：\n\n修饰符(public/private/default/protected) final 返回值类型 方法名(){//方法体}\n\n\n\n\n构造器\n\n子类是不继承父类的构造器（构造方法或者构造函数）的，它只是调用（隐式或显式）。如果父类的构造器带有参数，则必须在子类的构造器中显式地通过 super 关键字调用父类的构造器并配以适当的参数列表。\n如果父类构造器没有参数，则在子类的构造器中不需要使用 super 关键字调用父类构造器，系统会自动调用父类的无参构造器。\n\n\n\n\n\n\nJava 抽象类\n\n在面向对象的概念中，所有的对象都是通过类来描绘的，但是反过来，并不是所有的类都是用来描绘对象的，如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类。\n抽象类除了不能实例化对象之外，类的其它功能依然存在，成员变量、成员方法和构造方法的访问方式和普通类一样。\n由于抽象类不能实例化对象，所以抽象类必须被继承，才能被使用。也是因为这个原因，通常在设计阶段决定要不要设计抽象类。\n父类包含了子类集合的常见的方法，但是由于父类本身是抽象的，所以不能使用这些方法。\n在Java中抽象类表示的是一种继承关系，一个类只能继承一个抽象类，而一个类却可以实现多个接口。\n抽象方法\n\n如果你想设计这样一个类，该类包含一个特别的成员方法，该方法的具体实现由它的子类确定，那么你可以在父类中声明该方法为抽象方法。\nAbstract关键字同样可以用来声明抽象方法，抽象方法只包含一个方法名，而没有方法体。\n抽象方法没有定义，方法名后面直接跟一个分号，而不是花括号。\n声明抽象方法会造成以下两个结果：\n\n如果一个类包含抽象方法，那么该类必须是抽象类。\n任何子类必须重写父类的抽象方法，或者声明自身为抽象类。\n继承抽象方法的子类必须重写该方法。否则，该子类也必须声明为抽象类。最终，必须有子类实现该抽象方法，否则，从最初的父类到最终的子类都不能用来实例化对象。\n\n\n\n\n\n\n抽象类不能被实例化(初学者很容易犯的错)，如果被实例化，就会报错，编译无法通过。只有抽象类的非抽象子类可以创建对象。\n抽象类中不一定包含抽象方法，但是有抽象方法的类必定是抽象类。\n抽象类中的抽象方法只是声明，不包含方法体，就是不给出方法的具体实现也就是方法的具体功能。\n构造方法，类方法（用static修饰的方法）不能声明为抽象方法。\n抽象类的子类必须给出抽象类中的抽象方法的具体实现，除非该子类也是抽象类。\n\n\n\nJava 接口\n\n接口（英文：Interface），在JAVA编程语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法。\n接口并不是类，编写接口的方式和类很相似，但是它们属于不同的概念。类描述对象的属性和方法。接口则包含类要实现的方法。\n除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。\n接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。另外，在 Java 中，接口类型可用来声明一个变量，他们可以成为一个空指针，或是被绑定在一个以此接口实现的对象。\n接口与类相似点：\n一个接口可以有多个方法。\n\n接口文件保存在 .java 结尾的文件中，文件名使用接口名。\n接口的字节码文件保存在 .class 结尾的文件中。\n接口相应的字节码文件必须在与包名称相匹配的目录结构中。\n\n\n接口与类的区别：\n\n接口不能用于实例化对象。\n接口没有构造方法。\n接口中所有的方法必须是抽象方法。\n接口不能包含成员变量，除了 static 和 final 变量。\n接口不是被类继承了，而是要被类实现。\n接口支持多继承。\n\n\n接口特性\n\n接口中每一个方法也是隐式抽象的,接口中的方法会被隐式的指定为 public abstract（只能是 public abstract，其他修饰符都会报错）。\n接口中可以含有变量，但是接口中的变量会被隐式的指定为 public static final 变量（并且只能是 public，用 private 修饰会报编译错误）。\n接口中的方法是不能在接口中实现的，只能由实现接口的类来实现接口中的方法。\n\n\n抽象类和接口的区别\n\n\n抽象类中的方法可以有方法体，就是能实现方法的具体功能，但是接口中的方法不行。\n抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是 public static final 类型的。\n接口中不能含有静态代码块以及静态方法(用 static 修饰的方法)，而抽象类是可以有静态代码块和静态方法。\n一个类只能继承一个抽象类，而一个类却可以实现多个接口。\n\n Chapter 02 OOP\n\nObject\nClass\nAbstraction\nInheritance\nPolymorphism\nfinalilze();\nAbstraction\ninterface\nimplements\n\n Chapter 03 Exception\n\n检查性异常：最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。\n运行时异常： 运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。\n错误： 错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。\nException 类的层次\n\n所有的异常类是从 java.lang.Exception 类继承的子类。\nException 类是 Throwable 类的子类。除了Exception类外，Throwable还有一个子类Error 。\nJava 程序通常不捕获错误。错误一般发生在严重故障时，它们在Java程序处理的范畴之外。\nError 用来指示运行时环境发生的错误。\n\n\n\n\n Chapter 04 Java I/O\n123456File file = new File(\"filePath/fileName\");System.out.println(file.exists());System.out.println(file.isFile());File[] files = file.listFlies(filter);System.out.println(files.length);Arrays.sort(files,comparator);\n\n\nStream\n\nByte stream\n\njava.io.InputStream\n\nint read()\t//read a byte\n\n\njava.io.OutputStream\n\nvoid write(int b)\nvoid write(byte[] b)\n\n\nFileInputStream, FileOutputStream\nPipedInputStream, PipedOutputStream\nByteArrayInputStream, ByteArrayOutputStream\nBufferedInputStream, BufferedOutputStream\nObjectInputStreamm ObjectOutputStream\n\n\nCharacter stream\n\njava.io.Reader\n\nint read()\t//read a char\n\n\njava.io.Writer\n\nvoid write(int b)\nvoid write(char[] c)\n\n\nFileReader, FileWriter\nPipedReader, PipedWriter\nBufferedReader, BufferedWriter\nInpputStreamReader, OutputStreamWriter\n\n\nBridge\n\nInputStreamReader\nOutputStreamWriter\n\n\n\n\n\nFileInputStream\n\n\n1234FileInputStream fis = FileInputStream(file);int  res = fis.read();\t//IOExceptionfis.available();\t//是否可用fis.close();\n1\t\n\n\n\n\nFileOutputStream\n\n\n123 \tfile.createNewFile()fos.write(2);fos.write('a');\n1\t\n\n\n\n\nFileReader\n\n\nFileWriter\n\n\n123   FileWriter w = new FileWriter(new File(\"a.txt\"),true);w.write(\"Hanyuu\".toCharArray());w.flush();\n\n\n\n\nInputStreamReader\n\n\nOutputStreamReader\n\n\nPrintStream\n\n\nDataInputStream, DataOutputStream\n\n\nPrintWriter\n\n\nScanner\n\njava.util.Scanner\n\n\n\nBufferedInputStream, BufferedOutputStream\n\nBufferedInputStream bufferedInput = new BufferedInputStream(new FileInputStream(filename));\n\n123456789101112131415161718192021222324public void testBufferedInput() &#123; try &#123;     /**      * 建立输入流 BufferedInputStream, 缓冲区大小为8      * buffer.txt内容为      * abcdefghij      */     InputStream in = new BufferedInputStream(new FileInputStream(new File(\"buff.txt\")), 8);     /*从字节流中读取5个字节*/     byte [] tmp = new byte[5];     in.read(tmp, 0, 5);     System.out.println(\"字节流的前5个字节为: \" + new String(tmp));     /*标记测试*/     in.mark(6);     /*读取5个字节*/     in.read(tmp, 0, 5);     System.out.println(\"字节流中第6到10个字节为: \" +  new String(tmp));     /*reset*/     in.reset();     System.out.printf(\"reset后读取的第一个字节为: %c\" , in.read()); &#125; catch (Exception e) &#123;     e.printStackTrace(); &#125;&#125;\n\n\n1234567* InputStreamReader* OutputStreamReader* System.in* System.out* System.err* DataOutputStream* DataInputStream\n\n\n Chapter 05 Collection\n\n\nArrays\n\njava.util.Arrays\nArrays.sort()\nArrays.fill(String[],String)\nArray.hashCode(String)\n\n\n\nCollection\n\nSet&lt;E&gt; //non-repeat\n\nSortedSet&lt;E&gt;\n\n\nList&lt;E&gt;\nQuene&lt;E&gt;\n\n\n\nMap\n\n\nHashMap&lt;K,V&gt;\n1234567HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;();map.put(0,\"Hanyuu\");String name = map.get(0);map.remove(0);Set keySet = map.keySet();Collection valueSet = map.values();Set entrySet = map.entrySet();\n\n\nSortedMap&lt;K,V&gt;\n\n\n\n\nIterator\n\n\nSeqential and Linear\n\n\nUse Array as Backend\n\n\nVarible Length\n\n\nMethods\n123456789add(Object)add(int index,Object)remove(Object)get(int)set(int)indexOf(Objects)clear()Size()toArray()\n\n\nArrayList\n\nArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();\nArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(100);\nlist.ensureCapacity(1000)\n\n\n\nLinkedList\n123456LinkdList&lt;String&gt; list = new LinkedList&lt;String&gt;();list.add(\"Hanyuu\");Iterator&lt;String&gt; iterator = list.iterator();while(iterator.hasNext())&#123;  System.out.println(iterator.next());&#125;\n\n\n Chapter 07 UI\n\n\njava.jwt\n\n\njavax.swing\n\n\nJFrame frame = new JFrame(String //title);\n\nframe.getContentPane().add(BorderLayout.EAST,button);\nframe.setSize(300,400);\nframe.setVisible(true);\nframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\nContainer cp = frame.getContentPane();\ncp.setLayout(new FloatLayout());\ncp.add(new JPanel)();\n\n\n\nJButton button = new JButton(&quot;Okey&quot;);\n\n\nJComboBox\n\n\nJCheckBox\n\n\nJPanel\n\npnel.setLayout(new FLowLayout(FlowLayout.LEFT));\n\n\n\nJPanel //container\n\nJPanle = new JPanel();\npanel.add(new JTextField(&quot;Hanyuu&quot;));\n\n\n\nJSplistPane\n\n\nJScrollPane\n\n\nGraphics\n\n\nJLabel\n\ngetText();\nsetText();\nsetIcon();\n\n\n\nJTextField\n\n\nJCheckBox\n\n\nJTextArea\n\n\nJRadioButton\n\n\n事件侦听\n\nActionLinstener1234567public class Action implements ActionListener&#123;  public void actionPerformed(ActionEvent event)&#123;    //TODO...  &#125;&#125;JButton exp = new JButton();exp.addActionLintener(new Action());\n\n\n\n\n Chapter 08 Multi-thread\n\n\nrunnable interface\n123456789public class Task implements Runnable&#123;  public void run()&#123;    //TODO...  &#125;&#125;public static void main(String[] args)&#123;  Thread thread = new Thread(new Task(),\"Thread name\");  thread.start();&#125;\n\n\nThread\n\n\n   12345678910public class HanyuuThread extends Thread&#123;  public void run()&#123;    //TODO...  &#125;&#125;public static void main(String[] args)&#123;  HanyuuThread hanyuu = new HanyuuThread();  hanyuu.setName(\"Hanyuu\");  hanyuu.statrt();&#125;\n\nThread.sleep(int)\nString Thread.currentThread().getName();\njoin\ninterrupt()\nyield()\n\n\nyield意味着放手，放弃，投降。一个调用yield()方法的线程告 诉虚拟机它乐意让其他线程占用自己的位置。这表明该线程没 有在做一些紧急的事情。注意，这仅是一个暗示，并不能保证 不会产生任何影响。 \nYield告诉当前正在执行的线程把运行机会交给线程池中拥有相 同优先级的线程。\nYield不能保证使得当前正在运行的线程迅速转换到可运行的状态。\n它仅能使一个线程从运行状态转到可运行状态，而不是等待或阻塞状态\n\n\nnotify()/notifyAll()\n\nnotifyAll() wakes all waiting thread, thus, all waiting thread turn to Ready\nnotify() only wakes one of waiting thread, others remain blocked\n\n\nsleep()\n\njava.lang.Thread`\n\n\nwait()\n\njava.lang.Object\nEach object has a wait method, inherited from java.lang.Object\nwait() method ask current thread to give up exclusive control\nwait() method give other thread a chance to visit the object\nwait() / wait(long timeout)\n\n\nwait() / notifyAll() / notify()\n\nThe object must be locked before visit these methods\nThey can be used in synchronized method of an object\nOr obj.wait() / obj.notifyAll() / obj.notify() in synchorized(obj){…}\nOtherwise: java.lang.IllegalMonitorStateException\n\n\nsynchronized\n\n12345678public class Hanyuu&#123;  public synchronized void onlyOne()&#123;    //TODO...  &#125;  public synchronized void threadSafty()&#123;    //TODO...  &#125;&#125;\n\n Chapter 09 Java &amp; XML\n Chapter 10 JDBC\n\n\nRecord\n\n\nField\n\n\nTable\n\n\nEntity\n\n\nRelations\n\n\nDataBase\n\n\nPrimary key\n\n\nForeign key\n\n\nSelect\n\nSELECT nameA FROM tableA\nSELECT nameA FROM tableA WHERE name &gt; 2\nSELECT nameA FROM tableA WHERE (name &gt; 2 AND name &lt; 10) OR name &gt;300\nSELECT * FROM tableA WHERE name IN ('Hanyuu','Inari')\nSELECT * FROM tableA WHERE date BETWEEN 'Jan-01-2019' AND 'Jan-02-2019'\nSELECT * FROM tableA WHERE name LIKE '%an%'\nSELECT * FROM tableA ORDER BY name DESC/ASC\nSELECT COUNT(DISTINCT name) FROM tableA\n\n\n\nInsert\n\nINSERT INTO tableA (name,Date) VALUES ('Inari','Jan-01-2019')\n\n\n\nRetireval\n\n\nUpdate\n\nUPDATE tableA SET date = 'Jan-01-2019' WEHERE name = 'Hanyuu'\n\n\n\nDelete\n\nDELETE FROM tableA WHERE name = 'Inari'\n\n\n你知道为什么SQL语句大家都选择大写嘛？（hhh）\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546package SQL;import java.sql.*;import javax.sql.*;public class SQL &#123;\tpublic static void main(String[] args) &#123;//\t\tResultSet rs;//\t\tStatement statement;//\t\tConnection connection;\t\tConnection connection = null;\t\tStatement statement = null;\t\tResultSet rs = null;\t\ttry &#123;      //注册驱动程序\t\t\tClass.forName(\"com.mysql.cj.jdbc.Driver\");      //创建JDBC连接\t\t\tString dbURL = \"jdbc:mysql://localhost:3306/Hanyuu?user=Hanyuu&amp;password=Hanyuu&amp;useSSL=false&amp;serverTimezone=GMT\";\t\t\tconnection = DriverManager.getConnection(dbURL);      //创建statement\t\t\tString sqlQuery = \"SELECT DISTINCT bookname FROM bookstore\";\t\t\tstatement = connection.createStatement();\t\t\trs = statement.executeQuery(sqlQuery);\t\t\twhile (rs.next()) &#123;\t\t\t\tSystem.out.println(rs.getString(\"bookname\"));\t\t\t&#125;\t\t\tString nsqlQuery = \"SELECT * FROM bookstore\";\t\t\trs = statement.executeQuery(nsqlQuery);      //执行查询语句\t\t\tResultSetMetaData rsmd = rs.getMetaData();\t\t\tfor (int i = 1; i &lt;= rsmd.getColumnCount(); ++i) &#123;\t\t\t\tSystem.out.println(rsmd.getColumnName(i)+'\\t');\t\t\t&#125;\t\t&#125; catch (ClassNotFoundException e) &#123;\t\t\tSystem.out.println(\"无驱动类\");\t\t&#125; catch (SQLException e) &#123;\t\t\te.printStackTrace();\t\t&#125; finally &#123;\t\t\ttry &#123;\t\t\t\trs.close();\t\t\t\tstatement.close();\t\t\t\tconnection.close();\t\t\t&#125; catch (Exception e) &#123;\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n\n\n构建Prepared statement\n12345678910String sql = \"INSERT INTO tableA (id,name,sorce) VALUES (?,?,?)\";PreparedStatement s =connection.prepareStatement(sql);//add a records.setInt(1,0000);s.setString(2,\"Hanyuu\");s.setInt(3,60);s.addBatch();s.clearParameters();s.executeBatch();s.cleatBatch();\n\n\n Chapter 11 Java network Programming\n\nIP address\nIPv4\nIPv6\nIP\nHost name\nDomain Name\nDNS\n\n123456789101112131415try&#123;  //get InetAddress  InetAddress iAddress = InetAddress.getLocalHost();  //get local IP  String IP = iAddress.getHostAddress().toString();  //get local host name  String hostName = iAddress.getHostName().toString();  System.out.println(\"IP address\"+IP);  System.out.println(\"Host name\"+hostName);&#125;catch (UnknownHostException e)&#123;  e.printStackTrace();&#125;catch(Exception e)&#123;  e.printStackTrace();&#125;\n\n通过主机名获取所有IP\n\n1234567891011121314151617181920212223242526272829303132import java.net.InetAddress;import java.net.UnknownHostException;import java.util.ArrayList;import java.util.Iterator;public class getLocal &#123;\tpublic static void main(String[] args) &#123;\t\ttry &#123;\t\t\tInetAddress ia=InetAddress.getLocalHost();\t\t\tSystem.out.println(ia.getHostAddress());\t\t\tSystem.out.println(ia.getAddress());\t\t\tSystem.out.println(ia.getHostName());\t\t\tString hostName=InetAddress.getLocalHost().getHostName();\t\t\tArrayList&lt;String&gt; allIP=new ArrayList&lt;String&gt;();\t\t\tif (hostName.length()&gt;0)\t\t\t&#123;\t\t\t\tInetAddress[] addresses=InetAddress.getAllByName(hostName);\t\t\t\tfor (int i=0;i&lt;addresses.length;i++)&#123;\t\t\t\t\tallIP.add(addresses[i].getHostAddress().toString());\t\t\t\t&#125;\t\t\t&#125;\t\t\tfor (Iterator iter=allIP.iterator();((Iterator) iter).hasNext();)&#123;\t\t\t\tSystem.out.println(ier.next().toString());\t\t\t&#125;\t\t&#125; catch (UnknownHostException e) &#123;\t\t\te.printStackTrace();\t\t&#125;\t&#125;&#125;\n\nConstructor localhost InetAddress\n\n12345InetAddress addr = InetAddress.getByName(null);InetAddress addr = InetAddress.getByName(\"127.0.0.1\");InetAddress addr = InetAddress.getByName(\"localhost\");InetAddress addr = InetAddress.getLocalHost();byte[] IP = &#123;(byte)127,(byte)0,(byte)0,(byte)1&#125;;\n\nWeb server\nFTP server\nMail server\nPort 1-1024 is occupied by system\nclient\n\n123456789//构建客户端socketSocket client = new Socket(\"hanyuu.ml\",8080);//构建客户端socket（通过InetAddress）InetAddress address = InetAddress.getByName(\"Hanyuu.ml\");Socket client = new Socket(address,8080);InputStream is = socket.getInputStream();OutputStream os = socket.getOutputStream();is.close();os.close();\nExample\n123456Socket socket = new Socket(ip,8008);BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()),true);out.print(\"Hi\");Thread.sleep(1000);out.println(\"Hello\");socket.close();\n\nserver\n\n1234//创建服务端的ServerSocket监听客户请求ServerSocket server = new ServerSocket(8080);//客户端阻塞，等待连接Socket serverSocket = server.accept();\nExample\n12345678910111213try&#123;  ButteredReader in =new BufferedReader(new InputStreamReader(socket.getInputStream()));  PrintWriter out = new PrintWriter(new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()),true);  while(true)&#123;    String str = in.readLine();    if (str!=null &amp;&amp; str.equals(\"Hi\")) out.println(\"Hi, here is server.\");  &#125;catch(Exception e)&#123;    e.printStackTrace();  &#125;finally&#123;    socket.close();    server.close();  &#125;&#125;\n\nTCP\nUDP\nread a web page\n\n12345678910111213141516171819202122import java.io.BufferedReader;import java.io.InputStreamReader;import java.net.URL;import java.net.URLConnection;public class conn &#123;\tpublic static void main(String[] args) &#123;\t\ttry&#123;\t\t\tURL coseURL = new URL(\"http://cose.seu.edu.cn\");\t\t\tURLConnection connection =coseURL.openConnection();\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(connection.getInputStream()));\t\t\tString html = in.readLine();\t\t\twhile(html!=null)&#123;\t\t\t\tSystem.out.println(html);\t\t\t\thtml=in.readLine();\t\t\t&#125;\t\t&#125;catch (Exception e)&#123;\t\t&#125;\t&#125;&#125;\n","plink":"hanyuulu.github.io/Java/"},{"title":"数据结构小结","date":"2019-01-08T11:47:06.000Z","updated":"2021-03-12T08:22:58.538Z","content":" 性能度量\n\n算法的时间复杂度和空间复杂度合称为算法的复杂度。\n\n 时间复杂度\n\n\n时间频度 一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)。\n\n\n时间复杂度 一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)T(n)T(n)表示，若有某个辅助函数f(n)f(n)f(n),使得当nnn趋近于无穷大时，T(n)f(n){\\frac{T(n)}{f(n)}}f(n)T(n)​的极限值为不等于零的常数，则称f(n)f(n)f(n)是T(n)T(n)T(n)的同数量级函数。记作T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n)),称O(f(n))O(f(n))O(f(n))为算法的渐进时间复杂度，简称时间复杂度。\n常见的时间复杂度有：常数阶O(1)O(1)O(1),对数阶O(log2n)O(log_{2}n)O(log2​n),线性阶O(n)O(n)O(n), 线性对数阶O(n⋅log2n)O(n\\cdot log_{2}n)O(n⋅log2​n),平方阶O(n2)O(n^{2})O(n2)，立方阶O(n3)O(n^{3})O(n3),…， k次方阶O(nk)O(n^{k})O(nk) ,指数阶O(kn)O(k^{n})O(kn)。\n\n\n最坏时间复杂度和平均时间复杂度 　最坏情况下的时间复杂度称最坏时间复杂度。一般不特别说明，讨论的时间复杂度均是最坏情况下的时间复杂度。\n\n\n记号\n渐进精确记号Θ(n)\\Theta(n)Θ(n)\n渐进上界记号O(n)O(n)O(n)\n渐进下界记号Ω(n)\\Omega(n)Ω(n)\n\n\n求时间复杂度\n\n\n如果算法的执行时间不随着问题规模n的增加而增长,此类算法的时间复杂度是O(1)。\n 12345678910x=91;y=100;while(y&gt;0)    if(x&gt;100) &#123;    x=x-10;    y--;&#125;else &#123;    x++;&#125;\n解答： T(n)=O(1)T(n)=O(1)T(n)=O(1)，\n\n\n当有若干个循环语句时，算法的时间复杂度是由嵌套层数最多的循环语句中最内层语句的频度f(n)决定的。\n 12345x=1;for(i=1;i&lt;=n;i++)   for(j=1;j&lt;=i;j++)      for(k=1;k&lt;=j;k++)          x++;\n该程序段中频度最大的语句是x++，则该程序段的时间复杂度为T(n)=O(n3/6+T(n)=O(n3/6+T(n)=O(n3/6+ 低次项 )=O(n3))=O(n3))=O(n3)\n\n\n算法的时间复杂度不仅仅依赖于问题的规模，还与输入实例的初始状态有关。\n\n\n时间复杂度评价性能\n一般将渐近时间复杂度T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n))简称为时间复杂度，其中的f(n)f(n)f(n)一般是算法中频度最大的语句频度。\n\n\n\n\n 空间复杂度\n一个程序的空间复杂度是指运行完一个程序所需内存的大小。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。　　\n1. 固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。\n2. 可变空间，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。\n\t&gt; 一个算法所需的存储空间用$f(n)$表示。$S(n)=O(f(n))　$　其中$n$为问题的规模，$S(n)$表示空间复杂度。\n\n 数组\n抽象数据类型（Abstract Data Type，ADT）\n1234567891011class  GeneralArray &#123;// a set of pairs &lt;index, value&gt; where for each value ofindex in IndexSet there is a value of type float. IndexSet is a finite ordered set of one or more dimensions.public:    GeneralArray(int j, RangeList list, float initValue = defaultValue);// This constructor creates a j dimensional array of floats; the range of the kth dimension is given by the kth element of list. For all i∈IndexSet, insert &lt;i, initValue&gt; into the array.    float  Retrieve(index i);// if (i∈IndexSet) return the float associated with i in the array;else throw an exception.    void Store(index i, float x);// if (i∈IndexSet) replace the old value associated with i by x;  else throw an exception.&#125;; //end of GeneralArray\n 顺序表\n\n多项式\n\n基本操作：求长度、遍历、取数、存数、插入、删除\n基本结构\n\n\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Polynomial; // forward declarationclass Term &#123;friend Polynomial;private:     float coef; // coefficient     int exp;     // exponent&#125;;class Polynomial &#123;public:\t///...  private:   Term *termArray;   int capacity; // size of termArray   int terms; // number of nonzero terms&#125;Polynomial Polynomial::Add(Polynomial b)&#123; // return the sum of the polynomials *this and b.\tPolynomial c;\tint aPos = 0, bPos = 0;\twhile ((aPos &lt; terms) &amp;&amp; (b &lt; b.terms))\t\tif (termArray[aPos].exp == b.termArray[bPos].exp)\t\t&#123;\t\t\tfloat t = termArray[aPos].coef + termArray[bPos].coef;\t\t\tif (t)\t\t\t\tc.NewTerm(t, termArray[aPos].exp);\t\t\taPos++;\t\t\tbPos++;\t\t&#125;\t\telse if (termArray[aPos].exp &lt; b.termArray[bPos].exp)\t\t&#123;\t\t\tc.NewTerm(b.termArray[bPos].coef,b.termArray[bPos].exp);\t\t\tbPos++;\t\t&#125;\t\telse\t\t&#123;\t\t\tc.NewTerm(termArray[aPos].coef, termArray[aPos].exp);\t\t\taPos++;\t\t&#125;\t// add in the remaining terms of *this\tfor (; aPos &lt; terms; aPos++)\t\tc.NewTerm(termArray[aPos].coef, termArray[aPos].exp);\t// add in the remaining terms of b\tfor (; bPos &lt; b.terms; bPos++)\t\tc.NewTerm(b.termArray[bPos].coef, b.termArray[bPos].exp);\treturn c;&#125;void Polynomial::NewTerm(const float theCoeff,const int theExp)&#123; // add a new term to the end of termArray.\tif (terms == capacity)\t&#123; // double capacity of termArray\t\tcapacity *= 2;\t\tterm *temp = new term[capacity]; // new array\t\tcopy(termArray, termAarry + terms, temp);\t\tdelete[] termArray; // deallocate old memory\t\ttermArray = temp;\t&#125;\ttermArray[terms].coef = theCoeff;\ttermArray[terms++].exp = theExp;&#125;\n\n时间复杂度分析：\n\n插入：\n\n无需翻倍时：O(1)O(1)O(1)\n翻倍时（内存不足）:O(m+n+O(m + n +O(m+n+ 在数组加倍中花费的时间 )))\n\n\n翻倍（内存扩容）：\n\n\nO(∑i=1k2i)=O(2k+1)=O(2k)O(\\sum_{i=1}^{k}{2^{i}})=O(2^{k+1})=O(2^{k})\nO(i=1∑k​2i)=O(2k+1)=O(2k)\n\n由于 c.terms&gt;2k−1c.terms&gt;2^{k-1}c.terms&gt;2k−1 , m+n∈c.termsm+n\\in c.termsm+n∈c.terms实际使用时间为O(c.terms)=O(m+n)O(c.terms)=O(m+n)O(c.terms)=O(m+n)\n\n\n\n\n\n 稀疏矩阵\n12345678910class SparseMatrix &#123; // a set of &lt;row, column, value&gt;, where row, column are non-negative integers and form a unique combination; value is also an integer. public:      SparseMatrix ( int r, int c, int t);      // creates a r∈c SparseMatrix with a capacity of t nonzero terms      SparseMatrix Transpose ( );      // return the SparseMatrix obtained by transposing *this      SparseMatrix  Add ( SparseMatrix b);      SparseMatrix  Multiply ( SparseMatrix b); &#125;;\n123456class  SparseMatrix;class  MatrixTerm &#123;friend class SparseMatrix;Private:    int row, col, value;&#125;;\n\n转置\n\n 1234567891011121314151617 SparseMatrix SparseMatrix::Transpose()&#123; // return the transpose of *this\tSparseMatrix b(cols, rows, terms);\tif (terms &gt; 0)\t&#123; //nonzero matrix\t\tint currentB = 0;\t\tfor (int c = 0; c &lt; cols; c++)\t\t// transpose by columns\t\t\tfor (int i = 0; i &lt; terms; i++) // find and move terms in column c\t\t\t\tif (smArray[i].col == c)\t\t\t\t&#123;\t\t\t\t\tb.smArray[CurrentB].row = c;\t\t\t\t\tb.smArray[CurrentB].col = smArray[i].row;\t\t\t\t\tb.smArray[CurrentB++].value = smArray[i].value;\t\t\t\t&#125;\t&#125; // end of if (terms &gt; 0)\treturn b;&#125;\n\n快速转置\n\n12345678910111213141516171819202122232425262728 SparseMatrix SparseMatrix::FastTranspose()&#123; // return the transpose of *this in O(terms+cols) time.\tSparseMatrix b(cols, rows, terms);\tif (terms &gt; 0)\t&#123; // nonzero matrix\t\tint *rowSize = new int[cols];\t\t7int *rowStart = new int[cols];\t\t// compute rowSize[i] = number of terms in row i of b\t\tfill(rowSize, rowSize + cols, 0); // initialze\t\tfor (i = 0; i &lt; terms; i++)\t\t\trowSize[smArray[i].col]++;\t\t// rowStart[i] = starting position of row i in b\t\trowStart[0] = 0;\t\tfor (i = 1; i &lt; cols; i++)\t\t\trowStart[i] = rowStart[i - 1] + rowSize[i - 1];\t\tfor (i = 0; i &lt; terms; i++)\t\t&#123; // copy from *this to b\t\t\tint j = rowStart[smArray[i].col];\t\t\tb.smArray[j].row = smArray[i].col;\t\t\tb.smArray[j].col = smArray[i].row;\t\t\tb.smArray[j].value = smArray[i].value;\t\t\trowStart[smArray[i].col]++;\t\t&#125; // end of for\t\tdelete[] rowSize;\t\tdelete[] rowStart;\t&#125; // end of if\treturn b;&#125;\n\n时间复杂度\nO(cols+terms)O(cols+terms)O(cols+terms)\n\n 字符串匹配算法\n 1. 暴力匹配法\n定义现有文本串S模式串P，假设现在文本串S匹配到i位置，模式串P匹配到j位置，则有：\n\n如果当前字符匹配成功（即S[i] == P[j]），则i++，j++，继续匹配下一个字符；\n*如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0。相当于每次匹配失败时，i 回溯，j 被置为0。\n\n12345678910111213141516171819202122232425262728int ViolentMatch(char* s, char* p)&#123;\tint sLen = strlen(s);\tint pLen = strlen(p);\tint i = 0;\tint j = 0;\twhile (i &lt; sLen &amp;&amp; j &lt; pLen)\t&#123;\t\tif (s[i] == p[j])\t\t&#123;\t\t\t//当前字符匹配成功（即S[i] == P[j]），则i++，j++\t\t\ti++;\t\t\tj++;\t\t&#125;\t\telse\t\t&#123;\t\t\t//失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0\t\t\ti = i - j + 1;\t\t\tj = 0;\t\t&#125;\t&#125;\t//匹配成功，返回模式串p在文本串s中的位置，否则返回-1\tif (j == pLen)\t\treturn i - j;\telse\t\treturn -1;&#125;\n\n  暴力匹配法没有利用已经匹配过的信息，实现简单但是效率低下。\n\n\n\n 2.KMP算法\n\n算法流程\n\n假设现在文本串S匹配到i位置，模式串P匹配到j位置\n\n如果j=-1，或者当前字符匹配成功（S[i]==P[j]），都令i++，j++，继续匹配下一个字符；\n如果j!=-1，且当前字符匹配失败（S[i]!=P[j]），则令i不变，j =next[j]。此举意味着失配时，模式串P相对于文本串S向右移动了j-next[j] 位。\n（当匹配失败时，模式串向右移动的位数为：失配字符所在位置 - 失配字符对应的next 值（next 数组的求解会在下文阐述），即移动的实际位数为j-next[j]，且此值大于等于1。next数组的值代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next[j]=k，代表j之前的字符串中有最大长度为k 的相同前缀后缀。此也意味着在某个字符失配时，该字符对应的next值会告诉你下一步匹配中，模式串应该跳到哪个位置（跳到next[j]的位置）。如果next[j]等于0或-1，则跳到模式串的开头字符，若next[j]=k且k&gt;0，代表下次匹配跳到j之前的某个字符，而不是跳到开头，且具体跳过了k个字符。)\n\n\n\n\n\n123456789101112131415161718192021222324252627int KmpSearch(char* s, char* p)&#123;\tint i = 0;\tint j = 0;\tint sLen = strlen(s);\tint pLen = strlen(p);\twhile (i &lt; sLen &amp;&amp; j &lt; pLen)\t&#123;\t\t//如果j = -1，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++\t\tif (j == -1 || s[i] == p[j])\t\t&#123;\t\t\ti++;\t\t\tj++;\t\t&#125;\t\telse\t\t&#123;\t\t\t//如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j]\t\t\t//next[j]即为j所对应的next值\t\t\tj = next[j];\t\t&#125;\t&#125;\tif (j == pLen)\t\treturn i - j;\telse\t\treturn -1;&#125;\n\n步骤\n\n\n寻找前缀后缀最长公共元素长度\n对于P = p0 p1 …pj-1 pj，寻找模式串P中长度最大且相等的前缀和后缀。如果存在p0 p1 …pk-1 pk = pj- k pj-k+1…pj-1 pj，那么在包含pj的模式串中有最大长度为k+1的相同前缀后缀。举个例子，如果给定的模式串为“abab”，那么它的各个子串的前缀后缀的公共元素的最大长度如下表格所示：\n\n\n\n\n模式串\na\nb\na\nb\n\n\n\n\n最大前缀后缀公共元素长度\n0\n0\n1\n2\n\n\n\n\n比如对于字符串aba来说，它有长度为1的相同前缀后缀a；而对于字符串abab来说，它有长度为2的相同前缀后缀ab（相同前缀后缀的长度为k+1，k+1=2）。\n\n\n求next数组\nnext数组考虑的是除当前字符外的最长相同前缀后缀，所以通过第①步骤求得各个前缀后缀的公共元素的最大长度后，只要稍作变形即可：将第①步骤中求得的值整体右移一位，然后初值赋为-1，如下表格所示：\n\n\n\n\n模式串\na\nb\na\nb\n\n\n\n\nnext数组\n-1\n0\n0\n1\n\n\n\n\n\n根据next数组进行匹配\n匹配失配，j=next[j]j=next[j]j=next[j]，模式串向右移动的位数为：j−next[j]j-next[j]j−next[j]。换言之，当模式串的后缀pj−kpj−k+1,...,pj−1pj-kpj-k+1,...,pj-1pj−kpj−k+1,...,pj−1跟文本串si−ksi−k+1,...,si−1si-ksi-k+1,...,si-1si−ksi−k+1,...,si−1匹配成功，但pjpjpj跟sisisi匹配失败时，因为next[j]=knext[j]=knext[j]=k，相当于在不包含pj的模式串中有最大长度为k的相同前缀后缀，即p0p1...pk−1=pj−kpj−k+1...pj−1p0p1...pk-1=pj-kpj-k+1...pj-1p0p1...pk−1=pj−kpj−k+1...pj−1，故令j=next[j]j=next[j]j=next[j]，从而让模式串右移j−next[j]j-next[j]j−next[j]位，使得模式串的前缀p0p1,...,pk−1p0p1,...,pk-1p0p1,...,pk−1对应着文本串si−ksi−k+1,...,si−1si-ksi-k+1,...,si-1si−ksi−k+1,...,si−1，而后让pkpkpk跟sssi继续匹配。如下图所示：\n​\t\n\n\n 解释\n\n\n寻找最长前缀后缀\n\n如果给定的模式串是：“ABCDABD”，从左至右遍历整个模式串，其各个子串的前缀后缀分别如下表格所示： \n\n也就是说，原模式串子串对应的各个前缀后缀的公共元素的最大长度表为：\n\n\n\n123456789101112131415161718192021void GetNext(char* p,int next[])&#123;\tint pLen = strlen(p);\tnext[0] = -1;\tint k = -1;\tint j = 0;\twhile (j &lt; pLen - 1)\t&#123;\t\t//p[k]表示前缀，p[j]表示后缀\t\tif (k == -1 || p[j] == p[k])\t\t&#123;\t\t\t++k;\t\t\t++j;\t\t\tnext[j] = k;\t\t&#125;\t\telse\t\t&#123;\t\t\tk = next[k];\t\t&#125;\t&#125;&#125;\n 波兰式、逆波兰式实现\n 简单技巧：\n中序表达式转后序表式式：\n将中序表达式所有括号补全，然后将所有运算符向右移出无匹配的第一个右括号，去掉括号即为后序表式式\n\n举例：\n​\t原式：a+b*(c+d/e)\n​\t补全括号：(a+(b*(c+(d/e))))\n​\t操作符右移：(a(b(c(de)/)+))+\n​\t去掉括号：abcde/++\n中序表达式转前序表式式：\n将中序表达式所有括号补全，然后将所有运算符向左移出无匹配的第一个左括号，去掉括号即为前序表式式\n\n举例：\n​    原式：a+b*(c+d/e)\n​    补全括号：(a+(b*(c+(d/e))))\n​    操作符右移：+(a*(b+(c/(de))))\n​    去掉括号：+a*b+c/de\n 算法：\n利用运算符栈(OPTR)和数据栈(OPND)将中缀表达式转化为后缀表达式。\n将结束标志字符’#’放入操作符栈（OPTR）；\n从中缀表达式pre左端依次读取pre[i]：\n1.若pre[i]为操作数，压入数据栈（OPND）；\n2.若pre[i]为左括号，压入操作符栈（OPTR）；\n3.若pre[i]为右括号，则将操作符栈（OPTR）中的运算符依次出栈并压入数据栈（OPND），直到遇到左括号为止，但是该左括号出栈但不压入数据栈（OPND）\n4.若pre[i]为操作符:\n（1）若操作符栈（OPTR）为空，将此操作符pre[i]压入数据栈（OPND）；\n（2）若pre[i]的优先级大于操作符栈（OPTR）顶的优先级，将此操作符pre[i]压入数据栈（OPND）；\n（3）若操作符栈（OPTR）不为空且pre[i]的优先级小于等于操作符栈（OPTR）顶的优先级，将操作符栈（OPTR）中的运算符依次出栈并压入数据栈（OPND），直到不满足条件，此操作符pre[i]压入数据栈（OPND）\n\n直到遍历完整个中序表达式之后，操作符栈（OPTR）中仍然存在运算符，那么将这些运算符依次出栈加入到数据栈（OPND）中，直到栈为空。\n按照上述步骤完成后，将操作符栈（OPTR）逆序即可得到逆波兰表达式。\n 实现\n1234567891011121314151617181920212223242526272829303132333435363738//把中缀表达式转换为后缀表达式void postfix(char pre[])&#123;    int i = 0;    stack&lt;char&gt; OPTR; //运算符栈    stack&lt;char&gt; OPND; //数据栈    OPTR.push('#'); // 首先把结束标志‘#’放入栈底    while(pre[i]!='#')    &#123;        if((pre[i]&gt;='a' &amp;&amp; pre[i] &lt;='z')) // 遇到点直接写入后缀表达式        &#123; OPND.push(pre[i]); &#125;        else if (pre[i]=='(') // 遇到“（”不用比较直接入栈            OPTR.push(pre[i]); else if(pre[i] ==')') // 遇到右括号将其对应左括号后的操作符（操作符栈中的）全部写入后缀表达式        &#123;            while(OPTR.top()!='(')            &#123;                OPND.push(OPTR.top()); OPTR.pop();            &#125;            OPTR.pop(); // 将“（”出栈，后缀表达式中不含小括号 &#125;            else if (isoperator(pre[i]))            &#123;                while(!OPTR.empty() &amp;&amp; priority(pre[i]) &lt;= priority(OPTR.top()))                &#123; // 当前的操作符小于等于栈顶操作符的优先级时，将栈顶操作符写入到后缀表达式，重复此过程                    OPND.push(OPTR.top()); OPTR.pop();                &#125;                OPTR.push(pre[i]); // 当前操作符栈为空或者当前操作符优先级大于栈顶操作符的优先级，将该操作符入栈            &#125;            i++;        &#125;        while(OPTR.top() != '#') // 将所有的操作符加入后缀表达式        &#123; OPND.push(OPTR.top()); OPTR.pop(); &#125;        OPTR.pop(); //利用操作符栈逆序即可得到后缀表达式        while(!OPND.empty())        &#123; OPTR.push(OPND.top()); OPND.pop(); &#125;        while(!OPTR.empty())        &#123; cout &lt;&lt; OPTR.top(); OPTR.pop(); &#125;        cout &lt;&lt; endl;    &#125;\n\n 二叉树\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140    tree *root;    Btree()    &#123;        root=NULL;    &#125;    void create_Btree(int);    void Preorder(tree *);                  //先序遍历    void inorder(tree *);                   //中序遍历    void Postorder(tree *);                 //后序遍历    void display1() &#123;Preorder(root); cout&lt;&lt;endl;&#125;    void display2() &#123;inorder(root);cout&lt;&lt;endl;&#125;    void display3() &#123;Postorder(root); cout&lt;&lt;endl;&#125;    int count(tree *);                      //计算二叉树的个数    int findleaf(tree *);                   //求二叉树叶子的个数    int findnode(tree *);                   //求二叉树中度数为1的结点数量,这是当初考数据结构时候的最后一道题目&#125;;int Btree::n=0;int Btree::m=0;void Btree::create_Btree(int x)&#123;    tree *newnode=new tree;    newnode-&gt;data=x;    newnode-&gt;right=newnode-&gt;left=NULL;    if(root==NULL)        root=newnode;    else    &#123;        tree *back;        tree *current=root;        while(current!=NULL)        &#123;            back=current;            if(current-&gt;data&gt;x)                current=current-&gt;left;            else                current=current-&gt;right;        &#125;        if(back-&gt;data&gt;x)            back-&gt;left=newnode;        else            back-&gt;right=newnode;    &#125;&#125;int Btree::count(tree *p)&#123;    if(p==NULL)        return 0;    else        return count(p-&gt;left)+count(p-&gt;right)+1;      //这是运用了函数嵌套即递归的方法。&#125;void Btree::Preorder(tree *temp)    //这是先序遍历二叉树，采用了递归的方法。&#123;    if(temp!=NULL)    &#123;        cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";        Preorder(temp-&gt;left);        Preorder(temp-&gt;right);    &#125;&#125;void Btree::inorder(tree *temp)      //这是中序遍历二叉树，采用了递归的方法。&#123;    if(temp!=NULL)    &#123;        inorder(temp-&gt;left);        cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";        inorder(temp-&gt;right);    &#125;&#125;void Btree::Postorder(tree *temp)     //这是后序遍历二叉树，采用了递归的方法。&#123;    if(temp!=NULL)    &#123;        Postorder(temp-&gt;left);        Postorder(temp-&gt;right);        cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";    &#125;&#125;int Btree::findleaf(tree *temp)&#123;    if(temp==NULL)return 0;    else    &#123;        if(temp-&gt;left==NULL&amp;&amp;temp-&gt;right==NULL)return n+=1;        else        &#123;            findleaf(temp-&gt;left);            findleaf(temp-&gt;right);        &#125;        return n;    &#125;&#125;int Btree::findnode(tree *temp)&#123;    if(temp==NULL)return 0;    else    &#123;        if(temp-&gt;left!=NULL&amp;&amp;temp-&gt;right!=NULL)        &#123;            findnode(temp-&gt;left);            findnode(temp-&gt;right);        &#125;        if(temp-&gt;left!=NULL&amp;&amp;temp-&gt;right==NULL)        &#123;            m+=1;            findnode(temp-&gt;left);        &#125;        if(temp-&gt;left==NULL&amp;&amp;temp-&gt;right!=NULL)        &#123;            m+=1;            findnode(temp-&gt;right);        &#125;    &#125;    return m;&#125;void main()&#123;    Btree A;    int array[]=&#123;7,4,2,3,15,35,6,45,55,20,1,14,56,57,58&#125;;    int k;    k=sizeof(array)/sizeof(array[0]);    cout&lt;&lt;\"建立排序二叉树顺序: \"&lt;&lt;endl;    for(int i=0;i&lt;k;i++)    &#123;        cout&lt;&lt;array[i]&lt;&lt;\" \";        A.create_Btree(array[i]);    &#125;    cout&lt;&lt;endl;    cout&lt;&lt;\"二叉树节点个数： \"&lt;&lt;A.count(A.root)&lt;&lt;endl;    cout&lt;&lt;\"二叉树叶子个数：\"&lt;&lt;A.findleaf(A.root)&lt;&lt;endl;    cout&lt;&lt;\"二叉树中度数为1的结点的数量为：\"&lt;&lt;A.findnode(A.root)&lt;&lt;endl;    cout&lt;&lt;endl&lt;&lt;\"先序遍历序列: \"&lt;&lt;endl;    A.display1();    cout&lt;&lt;endl&lt;&lt;\"中序遍历序列: \"&lt;&lt;endl;    A.display2();    cout&lt;&lt;endl&lt;&lt;\"后序遍历序列: \"&lt;&lt;endl;    A.display3();&#125;\n 堆\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;vector&gt;#include &lt;cassert&gt; using namespace std;class MaxHeap&#123;  private:\tvector&lt;int&gt; heap;\tint size;  public:\tvoid make_heap(vector&lt;int&gt; &amp; nums, int s)\t&#123; //构建堆\t\theap.assign(nums.begin(), nums.end());\t\tsize = s;\t\tfor (int i = size / 2 - 1; i &gt;= 0; i--)\t\t\tdown(i);\t&#125;\tvoid push(int num)\t&#123; //插入元素\t\theap.push_back(num);\t\tsize++;\t\tup(size - 1);\t&#125;\tint pop()\t&#123; //删除元素\t\tassert(size &gt; 0);\t\tint result = heap[0];\t\theap[0] = heap[size - 1];\t\theap.pop_back();\t\tsize--;\t\tdown(0);\t\treturn result;\t&#125;\tvoid down(int index)\t&#123;\t\tassert(index &gt;= 0);\t\tint temp = heap[index];\t\tindex = index * 2 + 1;\t\twhile (index &lt; size)\t\t&#123;\t\t\tif (index + 1 &lt; size &amp;&amp; heap[index] &lt; heap[index + 1])\t\t\t\tindex++;\t\t\tif (heap[index] &lt; temp)\t\t\t\tbreak;\t\t\telse\t\t\t&#123;\t\t\t\theap[(index - 1) / 2] = heap[index];\t\t\t\tindex = index * 2 + 1;\t\t\t&#125;\t\t&#125;\t\theap[(index - 1) / 2] = temp;\t&#125;\tvoid up(int index)\t&#123;\t\tassert(index &lt; size);\t\tint temp = heap[index];\t\twhile (index &gt; 0 &amp;&amp; temp &gt; heap[(index - 1) / 2])\t\t&#123;\t\t\theap[index] = heap[(index - 1) / 2];\t\t\tindex = (index - 1) / 2;\t\t&#125;\t\theap[index] = temp;\t&#125;&#125;;\n 胜者树\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt; #define K 10 #define MAX 65535 int leaves[K+1]; int successTree[K]; /* 对于单个内部节点进行调整 */ void adjust(int i) &#123;     int m,n;     if(2 * i &lt; K)               /* 获取它的左孩子结点 */         m = successTree[2 * i];     else         m = 2 * i - K + 1;     if(2*i+1&lt;K)                 /* 获取它的右孩子节点 */         n = successTree[2*i+1];     else         n = 2 * i + - K + 2;     successTree[i] = leaves[m] &gt; leaves[n] ? n : m; /* 进行胜负判定 */ &#125; /* 初始化叶子节点并对内部节点进行类似于堆的调整 */ void initTree() &#123;     for(int i=1;i&lt;K+1;i++)         scanf(\"%d\", &amp;leaves[i]);     for(int i=K-1;i&gt;0;i--)         adjust(i); &#125; /* 自下而上对胜者树进行调整 */ void adjustToRoot(int i) &#123;     int parent = (i + K - 1) / 2; /* 对从当前节点到根节点路径上的所有                                    * 节点进行调整 */     while(parent&gt;0)     &#123;         adjust(parent);         parent = parent / 2;     &#125; &#125; int main() &#123;     freopen(\"in\",\"r\",stdin);     initTree();     for(int i=1;i&lt;K+1;i++)      /* 每次用最大值替换掉冠军节点，并对树                                  * 进行调整,最终得到升序排序的序列 */     &#123;         printf(\"%d \", leaves[successTree[1]]);         leaves[successTree[1]]=MAX;         adjustToRoot(successTree[1]);     &#125;     return 0; &#125;\n 败者树\n12345678910111213141516171819202122232425262728293031int loserTree[K];               /* 存储中间节点值，下标0处存储冠军节点 */int leaves[K+1];                /* 从下标1开始存储叶子节点值，下标0处存储一个最小值节点 */void adjust(int i)&#123;    int parent=(i+K-1)/2;      /* 求出父节点的下标 */    while(parent&gt;0)    &#123;        if(leaves[i]&gt;leaves[loserTree[parent]])        &#123;            int temp=loserTree[parent];            loserTree[parent]=i;            /* i指向的是优胜者 */            i= temp;        &#125;        parent = parent / 2;    &#125;    loserTree[0]=i;&#125;void initLoserTree()&#123;    int i;    for(i=1;i&lt;K+1;i++)        scanf(\"%d\",&amp;leaves[i]);    leaves[0]=MIN;    for(int i=0;i&lt;K;i++)        loserTree[i]=0;    for(int i=K;i&gt;0;i--)        adjust(i);&#125;\n 最小生成树\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859typedef struct&#123;    char vertex[VertexNum];                                //顶点表    int edges[VertexNum][VertexNum];                       //邻接矩阵,可看做边表    int n,e;                                               //图中当前的顶点数和边数&#125;MGraph;typedef struct node&#123;    int u;                                                 //边的起始顶点    int v;                                                 //边的终止顶点    int w;                                                 //边的权值&#125;Edge;void kruskal(MGraph G)&#123;    int i,j,u1,v1,sn1,sn2,k;    int vset[VertexNum];                                    //辅助数组，判定两个顶点是否连通    int E[EdgeNum];                                         //存放所有的边    k=0;                                                    //E数组的下标从0开始    for (i=0;i&lt;G.n;i++)    &#123;        for (j=0;j&lt;G.n;j++)        &#123;            if (G.edges[i][j]!=0 &amp;&amp; G.edges[i][j]!=INF)            &#123;                E[k].u=i;                E[k].v=j;                E[k].w=G.edges[i][j];                k++;            &#125;        &#125;    &#125;    heapsort(E,k,sizeof(E[0]));                            //堆排序，按权值从小到大排列    for (i=0;i&lt;G.n;i++)                                    //初始化辅助数组    &#123;        vset[i]=i;    &#125;    k=1;                                                   //生成的边数，最后要刚好为总边数    j=0;                                                   //E中的下标    while (k&lt;G.n)    &#123;        sn1=vset[E[j].u];        sn2=vset[E[j].v];                                  //得到两顶点属于的集合编号        if (sn1!=sn2)                                      //不在同一集合编号内的话，把边加入最小生成树        &#123;            printf(\"%d ---&gt; %d, %d\",E[j].u,E[j].v,E[j].w);            k++;            for (i=0;i&lt;G.n;i++)            &#123;                if (vset[i]==sn2)                &#123;                    vset[i]=sn1;                &#125;            &#125;        &#125;        j++;    &#125;&#125;\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178// 单源最短路径Dijkstra算法实现.cpp : Defines the entry point for the console application.//#include \"stdafx.h\"#include&lt;iostream&gt;#define MAX 200#define Infinity 65535using namespace std;//边尾节点信息结构体struct edgeNode&#123; int no;   //尾接点序号 int cost;  //边权值 edgeNode *next; //其下一条邻接边尾节点指针&#125;;//节点信息结构体struct vexNode&#123; char info;  //节点名称 edgeNode *link; //与其相连的边的尾节点链表指针&#125;;struct Queue&#123; int no; //队列中节点序号 int cost; //以此为尾节点的边的权值&#125;;//优先队列Queue priQue[MAX];//节点数组vexNode adjlist[MAX];//指定源点到节点i的最短路径花费int lowcost[MAX];//指定源点到节点i路径中，节点i的前驱节点序号int parent[MAX];//建立图邻接表void createGraph(vexNode *adjlist,int *parent,int * lowcost,const int n,const int e)&#123; int i; for(i=1;i&lt;=n;i++) &#123;  cout&lt;&lt;\"请输入节点\"&lt;&lt;i&lt;&lt;\"的名称：\";  cin&gt;&gt;adjlist[i].info;  adjlist[i].link = NULL;  lowcost[i] = Infinity;  parent[i] = i; &#125; edgeNode *p1;   int v1,v2; for(i=1;i&lt;=e;i++) &#123;  cout&lt;&lt;\"请输入边\"&lt;&lt;i&lt;&lt;\"的起始节点与尾节点序号：\";  cin&gt;&gt;v1&gt;&gt;v2;  p1 = (edgeNode*)malloc(sizeof(edgeNode));  p1-&gt;no = v2;  cout&lt;&lt;\"此边的权值：\";  cin&gt;&gt;p1-&gt;cost;  p1-&gt;next = adjlist[v1].link;  adjlist[v1].link = p1; &#125;&#125;//当插入节点到优先队列时，保持队列优先性void keep_min_heap(Queue *priQue,int &amp;num,const int k)&#123; int l = 2*k; int r = 2*k + 1; int smallest = k; if(l&lt;=num&amp;&amp;priQue[l].cost&lt;priQue[k].cost)  smallest = l; if(r&lt;=num&amp;&amp;priQue[r].cost&lt;priQue[smallest].cost)  smallest = r; if(smallest != k) &#123;  Queue temp = priQue[smallest];  priQue[smallest] = priQue[k];  priQue[k] = temp;  keep_min_heap(priQue,num,smallest); &#125;&#125;//插入节点到优先队列时并且保持队列优先性void heap_insert(Queue *priQue,int &amp;num,int no,int cost)&#123; num +=1; priQue[num].no = no; priQue[num].cost = cost; int i = num; while(i&gt;1&amp;&amp;priQue[i/2].cost&gt;priQue[i].cost) &#123;  Queue temp = priQue[i];  priQue[i] = priQue[i/2];  priQue[i/2] = temp;  i = i/2; &#125;&#125;//取出优先队列的队头元素Queue heap_extract_min(Queue *priQue,int &amp;num)&#123; if(num&lt;1)  return priQue[0]; Queue min = priQue[1]; priQue[1] = priQue[num]; num -=1; keep_min_heap(priQue,num,1); return min;&#125;//打印指定源点带序号为i的点的最短路径void print_it(int *parent,vexNode *adjlist,int v)&#123; if(parent[v] == v)  cout&lt;&lt;\"(\"&lt;&lt;v&lt;&lt;\":\"&lt;&lt;adjlist[v].info&lt;&lt;\") \"; else &#123;  print_it(parent,adjlist,parent[v]);  cout&lt;&lt;\"(\"&lt;&lt;v&lt;&lt;\":\"&lt;&lt;adjlist[v].info&lt;&lt;\") \"; &#125;&#125;int _tmain(int argc, _TCHAR* argv[])&#123;int cases; cout&lt;&lt;\"请输入案例的个数：\"; cin&gt;&gt;cases; while(cases--) &#123;  int n,e;  cout&lt;&lt;\"请输入节点数：\";  cin&gt;&gt;n;  cout&lt;&lt;\"请输入边数：\";  cin&gt;&gt;e;  //队列中的元素，初始为0  int num = 0;  int i;  //创建邻接表  createGraph(adjlist,parent,lowcost,n,e);  cout&lt;&lt;endl;  cout&lt;&lt;\"从哪个节点开始：\";  int v0;  cin&gt;&gt;v0;  int v =v0;  lowcost[v0] = 0;  cout&lt;&lt;endl;  Queue queue;  for(i=1;i&lt;n;i++)  &#123;   edgeNode *p = adjlist[v0].link;   while(p != NULL)   &#123;    if(lowcost[v0] + p-&gt;cost&lt;lowcost[p-&gt;no])    &#123;     lowcost[p-&gt;no] = lowcost[v0] + p-&gt;cost;     parent[p-&gt;no] = v0;     heap_insert(priQue,num,p-&gt;no,lowcost[p-&gt;no]);    &#125;    p = p-&gt;next;   &#125;   queue = heap_extract_min(priQue,num);   v0 = queue.no;  &#125;  for(i=1;i&lt;=n;i++)  &#123;   mincost = 0;   cout&lt;&lt;\"从点\"&lt;&lt;adjlist[v].info&lt;&lt;\"开始到\"&lt;&lt;adjlist[i].info&lt;&lt;\"的最短路径为：\"&lt;&lt;endl;   print_it(parent,adjlist,i);   cout&lt;&lt;endl;   cout&lt;&lt;\"距离为：\"&lt;&lt;lowcost[i]&lt;&lt;endl;  &#125; &#125; system(\"pause\"); return 0;&#125;\n AOV\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;stdio.h&gt;#include &lt;malloc.h&gt;#define max 100typedef struct arcnode&#123;\tint adjvex;\tstruct arcnode *next;&#125; arcnode;typedef struct&#123;\tint vertex;\tarcnode *firstarc;&#125; vexnode;vexnode adjlist[max];int creatadjlist()&#123;\tarcnode *ptr;\tint arcnum, vexnum, k, v1, v2;\tprintf(\"input vexnum and arcnum:\");\tscanf(\"%d,%d\", &amp;vexnum, &amp;arcnum);\tfor (k = 1; k &lt;= vexnum; k++)\t&#123;\t\tadjlist[k].firstarc = NULL;\t\tadjlist[k].vertex = 0;\t&#125;\tfor (k = 1; k &lt;= arcnum; k++)\t&#123;\t\tprintf(\"v1,v2=\");\t\tscanf(\"%d,%d\", &amp;v1, &amp;v2);\t\tptr = (arcnode *)malloc(sizeof(arcnode));\t\tptr-&gt;adjvex = v2;\t\tptr-&gt;next = adjlist[v1].firstarc;\t\tadjlist[v1].firstarc = ptr;\t\tadjlist[v2].vertex++;\t&#125;\treturn vexnum;&#125;toposort(int n)&#123;\tint queue[max];\tint front = 0, rear = 0;\tint v, w, m;\tarcnode *p;\tm = 0;\tfor (v = 1; v &lt;= n; v++)\t\tif (adjlist[v].vertex == 0)\t\t&#123;\t\t\trear = (rear + 1) % max;\t\t\tqueue[rear] = v;\t\t&#125;\tprintf(\"the toposort:\\n\");\twhile (front != rear)\t&#123;\t\tfront = (front + 1) % max;\t\tv = queue[front];\t\tprintf(\"%d \", v);\t\tm++;\t\tp = adjlist[v].firstarc;\t\twhile (p != NULL)\t\t&#123;\t\t\tw = p-&gt;adjvex;\t\t\tadjlist[w].vertex--;\t\t\tif (adjlist[w].vertex == 0)\t\t\t&#123;\t\t\t\trear = (rear + 1) % max;\t\t\t\tqueue[rear] = w;\t\t\t&#125;\t\t\tp = p-&gt;next;\t\t&#125;\t&#125;\tif (m &lt; n)\t\tprintf(\"the toposort is fail.\");&#125;int main()&#123;\tint n;\tn = creatadjlist();\ttoposort(n);\treturn 0;&#125;\n AOE\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include&lt;iostream&gt;using namespace std;#define MAXN 100\t\t//顶点个数最大值#define MAXM 200\t\t//边数的最大值struct ArcNode&#123;\tint to, dur, no;\t//边的另一个顶点、持续时间、活动序号\tArcNode *next;&#125;;int n, m;\t\t\t\t//顶点个数、边数ArcNode *List1[MAXN];\t//每个顶点的边链表表头指针（出边表）ArcNode *List2[MAXM];\t//每个顶点的边链表表头指针（入边表）int count1[MAXN];\t\t//各顶点的入度int count2[MAXM];\t\t//各顶点的出度int Ee[MAXN];\t\t\t//各事件的最早可能开始时间int El[MAXN];\t\t\t//各事件的最迟允许开始时间int e[MAXM];\t\t\t//各活动的最早可能开始时间int L[MAXM];\t\t\t//各活动的最迟允许开始时间void CriticalPath()\t\t//求关键路径&#123;\t//拓扑排序求Ee\tint i, j, k;\tint top1 = -1;\tArcNode *temp1;\tmemset(Ee, 0, sizeof(Ee));\tfor(i = 0; i &lt; n; i++)\t\tif(count1[i] == 0) &#123; count1[i] = top1; top1 = i; &#125;\tfor(i = 0; i &lt; n; i++)\t&#123;\t\tif(top1 == -1) &#123; printf(\"Network has a cycle!\\n\"); return; &#125;\t\telse\t\t&#123;\t\t\tj = top1; top1 = count1[top1];\t\t\ttemp1 = List1[j];\t\t\twhile(temp1 != NULL)\t\t\t&#123;\t\t\t\tk = temp1-&gt;to;\t\t\t\tif(--count1[k] == 0) &#123; count1[k] = top1; top1 = k; &#125;\t\t\t\tif(Ee[j]+temp1-&gt;dur &gt; Ee[k]) Ee[k] = Ee[j] + temp1-&gt;dur;//有向边&lt;j, k&gt;\t\t\t\ttemp1 = temp1-&gt;next;\t\t\t&#125;\t\t&#125;\t&#125;\t//逆拓扑排序求El\tint top2 = -1;\tArcNode *temp2;\tfor(i = 0; i &lt; n; i++)\t&#123;\t\tEl[i] = Ee[n-1];\t\tif(count2[i] == 0) &#123; count2[i] = top2; top2 = i; &#125;\t&#125;\tfor(i = 0; i &lt; n; i++)\t&#123;\t\tj = top2; top2 = count2[top2];\t\ttemp2 = List2[j];\t\twhile(temp2 != NULL)\t\t&#123;\t\t\tk = temp2-&gt;to;\t\t\tif(--count2[k] == 0) &#123; count2[k] = top2; top2 = k; &#125;\t\t\tif(El[j]-temp2-&gt;dur &lt; El[k]) El[k] = El[j] - temp2-&gt;dur;//有向边&lt;k, j&gt;\t\t\ttemp2 = temp2-&gt;next;\t\t&#125;\t&#125;\t//求各活动的e[k]和L[k]\tmemset(e, 0, sizeof(e)); memset(L, 0, sizeof(L));\tprintf(\"The Critical activities are:\\n\");\tfor(i = 0; i &lt; n; i++)\t&#123;\t\ttemp1 = List1[i];\t\twhile(temp1 != NULL)\t\t&#123;\t\t\tj = temp1-&gt;to; k = temp1-&gt;no;\t//有向边&lt;i, j&gt;\t\t\te[k] = Ee[i]; L[k] = El[j] - temp1-&gt;dur;\t\t\tif(e[k] == L[k]) printf(\"a%d : %d-&gt;%d\\n\", k, i, j);\t\t\ttemp1 = temp1-&gt;next;\t\t&#125;\t&#125;&#125;int main()&#123;\tint i, u, v, w;\t//循环变量、边的起点和终点\tscanf(\"%d%d\", &amp;n, &amp;m);\t//读入顶点个数和边数\tmemset(List1, 0, sizeof(List1)); memset(List2, 0, sizeof(List2));\tmemset(count1, 0, sizeof(count1)); memset(count2, 0, sizeof(count2));\tArcNode *temp1, *temp2;\tfor(i = 0; i &lt; m; i++)\t&#123;\t\tscanf(\"%d%d%d\", &amp;u, &amp;v, &amp;w);\t//读入边的起点和终点\t\tcount1[v]++;\t\ttemp1 = new ArcNode;\t\t\t//构造邻接表\t\ttemp1-&gt;to = v; temp1-&gt;dur = w;\t\ttemp1-&gt;no = i + 1; temp1-&gt;next = NULL;\t\tif(List1[u] == NULL) List1[u] = temp1;\t\telse &#123; temp1-&gt;next = List1[u]; List1[u] = temp1; &#125;\t\tcount2[u]++;\t\ttemp2 = new ArcNode;\t\t\t//构造逆邻接表\t\ttemp2-&gt;to = u; temp2-&gt;dur = w;\t\ttemp2-&gt;no = i + 1; temp2-&gt;next = NULL;\t\tif(List2[v] == NULL) List2[v] = temp2;\t\telse &#123; temp2-&gt;next = List2[v]; List2[v] = temp2; &#125;\t&#125;\tCriticalPath();\tfor(i = 0; i &lt; n; i++)\t\t\t\t//释放边链表上各边结点所占用的存储空间\t&#123;\t\ttemp1 = List1[i]; temp2 = List2[i];\t\twhile(temp1 != NULL) &#123; List1[i] = temp1-&gt;next; delete temp1; temp1 = List1[i]; &#125;\t\twhile(temp2 != NULL) &#123; List2[i] = temp2-&gt;next; delete temp2; temp2 = List2[i]; &#125;\t&#125;\treturn 0;&#125;\n 图\n 邻接矩阵\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173/*    邻接矩阵实现图的广搜和深搜*/#include&lt;iostream&gt;#include&lt;queue&gt;#define inf 1000000 //假设的无穷大#define vertex_max_num 100  //设的最大顶点数using namespace std;typedef struct &#123;    int v[vertex_max_num];//顶点名称    int adj_matrix[vertex_max_num][vertex_max_num];//邻接矩阵    int v_num, arc_num;//顶点数，弧数    int kind;//图的种类,0有向图，1有向网，2无向图，3无向网&#125;graph;int vis[vertex_max_num+1];//标志数组//标志数组初始化void init() &#123;    memset(vis, 0, sizeof(vis));&#125;//创建有向图void dir_graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的有向图的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = 0;    cout &lt;&lt; \"请依次输入邻接可达的成对结点：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2;        cin &gt;&gt; v1 &gt;&gt; v2;        G.adj_matrix[v1][v2] = 1;    &#125;&#125;//创建有向网（带权有向图）void dir_net_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的有向网的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = inf;    cout &lt;&lt; \"请依次输入邻接可达的成对结点及弧长：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2,w;        cin &gt;&gt; v1 &gt;&gt; v2 &gt;&gt; w;        G.adj_matrix[v1][v2] = w;    &#125;&#125;//创建无向图void udir_graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的无向图的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = 0;    cout &lt;&lt; \"请依次输入邻接的成对结点：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2;        cin &gt;&gt; v1 &gt;&gt; v2;        G.adj_matrix[v1][v2] = 1;        G.adj_matrix[v2][v1] = 1;    &#125;&#125;//创建无向网（带权无向图）void udir_net_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的无向网的顶点数和弧数：\"; cin &gt;&gt; G.v_num &gt;&gt; G.arc_num;    //结点初始化    for (int i = 1; i &lt;= G.v_num; i++) G.v[i] = i;//对结点编号    for (int i = 1; i &lt;= G.v_num; i++)        for (int j = 1; j &lt;= G.v_num; j++)            G.adj_matrix[i][j] = inf;    cout &lt;&lt; \"请依次输入邻接的成对结点及弧长：\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.arc_num; i++) &#123;        int v1, v2, w;        cin &gt;&gt; v1 &gt;&gt; v2 &gt;&gt; w;        G.adj_matrix[v1][v2] = w;        G.adj_matrix[v2][v1] = w;    &#125;&#125;void graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"************\" &lt;&lt; endl;    cout &lt;&lt; \"0-----有向图\" &lt;&lt; endl;    cout &lt;&lt; \"1-----有向网\" &lt;&lt; endl;    cout &lt;&lt; \"2-----无向图\" &lt;&lt; endl;    cout &lt;&lt; \"3-----无向网\" &lt;&lt; endl;    cout &lt;&lt; \"************\" &lt;&lt; endl;    cout &lt;&lt; \"根据上方菜单，输入相应数字，来创建你想要类型的图\" &lt;&lt; endl;    cin &gt;&gt; G.kind;    switch (G.kind) &#123;    case 0:dir_graph_create(G); break;    case 1:dir_net_create(G); break;    case 2:udir_graph_create(G); break;    case 3:udir_net_create(G); break;    default:return;    &#125;&#125;//图深度优先遍历void dfs1(graph G, int v) &#123;    if (!vis[v]) &#123;        cout &lt;&lt; G.v[v]&lt;&lt;\" \";        vis[v] = 1;    &#125;    for (int i = 1; i &lt;= G.v_num; i++)        if (!vis[i] &amp;&amp; G.adj_matrix[v][i]==1)            dfs1(G, i);&#125;//网深度优先遍历void dfs2(graph G, int v) &#123;    if (!vis[v]) &#123;        cout &lt;&lt; G.v[v]&lt;&lt;\" \";        vis[v] = 1;    &#125;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        if (!vis[i] &amp;&amp; G.adj_matrix[v][i] != inf)            dfs2(G, i);    &#125;&#125;//深度优先遍历void dfs(graph G, int v) &#123;    init();    cout &lt;&lt; \"深度优先遍历结果：\";    switch (G.kind) &#123;    case 0:    case 2:dfs1(G, v); break;    case 1:    case 3:dfs2(G, v); break;    default:return;    &#125;    cout &lt;&lt; endl;&#125;//广度优先遍历void bfs(graph G, int v) &#123;    init();    cout &lt;&lt; \"广度优先遍历结果：\";    queue&lt;int&gt;que;    if (!vis[v]) &#123;        cout &lt;&lt; G.v[v] &lt;&lt; \" \";        vis[v] = 1;        que.push(v);    &#125;    while (!que.empty()) &#123;        int vertex = que.front();        que.pop();        for (int i = 1; i &lt;= G.v_num; i++) &#123;            if (!vis[i]) &#123;                if (((G.kind == 0 || G.kind == 2) &amp;&amp; G.adj_matrix[vertex][i] == 1) ||                    ((G.kind==1 || G.kind==3) &amp;&amp; G.adj_matrix[vertex][i]!=inf)) &#123;                    cout &lt;&lt; G.v[i] &lt;&lt; \" \";                    vis[i] = 1;                    que.push(i);                &#125;            &#125;        &#125;    &#125;    cout &lt;&lt; endl;&#125;\n 邻接表\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include&lt;iostream&gt;#include&lt;queue&gt;using namespace std;const int vertex_max = 100;typedef char vertex_type;//边typedef struct edge_node &#123;    int vertex;//边所指向的结点编号    struct edge_node *next;//下一条边&#125;edge;//结点typedef struct vertex_node &#123;    vertex_type e;//结点名字    edge *side;&#125;vertex;typedef struct Graph &#123;    vertex adj_list[vertex_max+1];//邻接表    int w[vertex_max+1][vertex_max + 1];//边权重    int v_num, e_num;//结点数、边数&#125;graph;bool vis[vertex_max + 1];void init() &#123;    memset(vis, 0, sizeof(vis));&#125;//建立图void graph_create(graph &amp;G) &#123;    cout &lt;&lt; \"请输入要创建的图的结点数和边数：\";    cin &gt;&gt; G.v_num &gt;&gt; G.e_num;    cout &lt;&lt; \"========================================\" &lt;&lt; endl;    cout &lt;&lt; \"结点信息如下\"&lt;&lt;endl;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        cout &lt;&lt; \"第\" &lt;&lt; i &lt;&lt; \"个结点是\"; cin &gt;&gt; G.adj_list[i].e;        G.adj_list[i].side = nullptr;    &#125;    cout &lt;&lt; \"========================================\" &lt;&lt; endl;    cout &lt;&lt; \"边信息如下\" &lt;&lt; endl;    for (int i = 1; i &lt;= G.e_num; i++) &#123;        cout &lt;&lt; \"请输入第\" &lt;&lt; i &lt;&lt; \"条边相连的两个结点编号及边的权重：\";        int x, y,weight;        cin &gt;&gt; x &gt;&gt; y &gt;&gt; weight;        G.w[x][y] = G.w[y][x] = weight;        edge *p_edge = new edge;        edge *q_edge = new edge;        p_edge-&gt;next = nullptr; p_edge-&gt;vertex = y;        q_edge-&gt;next = nullptr; q_edge-&gt;vertex = x;        edge *tmp1 = G.adj_list[x].side;        edge *tmp2 = G.adj_list[y].side;        //把x结点指向y结点        while (tmp1) &#123;            if (tmp1-&gt;next == nullptr) break;            tmp1 = tmp1-&gt;next;        &#125;        if (tmp1 == nullptr) G.adj_list[x].side = p_edge;        else tmp1-&gt;next = p_edge;        //把y结点指向x结点        while (tmp2) &#123;            if (tmp2-&gt;next == nullptr) break;            tmp2 = tmp2-&gt;next;        &#125;        if (tmp2 == nullptr) G.adj_list[y].side = q_edge;        else tmp2-&gt;next = q_edge;    &#125;&#125;//打印邻接表void adj_list_print(graph G) &#123;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        cout &lt;&lt; G.adj_list[i].e;        edge *tmp = G.adj_list[i].side;        while (tmp) &#123;            cout &lt;&lt;\"→\"&lt;&lt; G.adj_list[tmp-&gt;vertex].e;            tmp = tmp-&gt;next;        &#125;        cout &lt;&lt; endl;    &#125;&#125;//深搜（从某结点出发搜索）void dfs1(graph G, int v) &#123;    if (!vis[v]) &#123;        cout &lt;&lt; G.adj_list[v].e &lt;&lt; \" \"; vis[v] = true;    &#125;    edge *p = G.adj_list[v].side;    while (p) &#123;        if (!vis[p-&gt;vertex]) dfs1(G, p-&gt;vertex);        p = p-&gt;next;    &#125;&#125;//深搜（从各个结点出发搜索）void dfs(graph G) &#123;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        init();        dfs1(G, i);        cout &lt;&lt; endl;    &#125;&#125;//广搜（从某个结点出发搜索）void bfs1(graph G,int i) &#123;        init();        queue&lt;int&gt;que;        if (!vis[i]) &#123;            cout &lt;&lt; G.adj_list[i].e &lt;&lt; \" \";            que.push(i);            vis[i] = 1;        &#125;        while (!que.empty()) &#123;            int ii = que.front();            que.pop();            edge *p = G.adj_list[ii].side;            while (p) &#123;                if (!vis[p-&gt;vertex]) &#123;                    cout &lt;&lt; G.adj_list[p-&gt;vertex].e &lt;&lt; \" \";                    que.push(p-&gt;vertex);                    vis[p-&gt;vertex] = 1;                &#125;                p = p-&gt;next;            &#125;        &#125;&#125;//广搜（从各个结点出发搜索）void bfs(graph G) &#123;    for (int i = 1; i &lt;= G.v_num; i++) &#123;        bfs1(G, i);        cout &lt;&lt; endl;    &#125;&#125;\n Dijkstra算法\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111class MatrixUDG &#123;    #define MAX    100    #define INF    (~(0x1&lt;&lt;31))        // 无穷大(即0X7FFFFFFF)    private:        char mVexs[MAX];    // 顶点集合        int mVexNum;             // 顶点数        int mEdgNum;             // 边数        int mMatrix[MAX][MAX];   // 邻接矩阵    public:        // 创建图(自己输入数据)        MatrixUDG();        // 创建图(用已提供的矩阵)        //MatrixUDG(char vexs[], int vlen, char edges[][2], int elen);        MatrixUDG(char vexs[], int vlen, int matrix[][9]);        ~MatrixUDG();        // 深度优先搜索遍历图        void DFS();        // 广度优先搜索（类似于树的层次遍历）        void BFS();        // prim最小生成树(从start开始生成最小生成树)        void prim(int start);        // 克鲁斯卡尔（Kruskal)最小生成树        void kruskal();        // Dijkstra最短路径        void dijkstra(int vs, int vexs[], int dist[]);        // 打印矩阵队列图        void print();    private:        // 读取一个输入字符        char readChar();        // 返回ch在mMatrix矩阵中的位置        int getPosition(char ch);        // 返回顶点v的第一个邻接顶点的索引，失败则返回-1        int firstVertex(int v);        // 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1        int nextVertex(int v, int w);        // 深度优先搜索遍历图的递归实现        void DFS(int i, int *visited);        // 获取图中的边        EData* getEdges();        // 对边按照权值大小进行排序(由小到大)        void sortEdges(EData* edges, int elen);        // 获取i的终点        int getEnd(int vends[], int i);&#125;;/* * Dijkstra最短路径。 * 即，统计图中\"顶点vs\"到其它各个顶点的最短路径。 * * 参数说明： *       vs -- 起始顶点(start vertex)。即计算\"顶点vs\"到其它顶点的最短路径。 *     prev -- 前驱顶点数组。即，prev[i]的值是\"顶点vs\"到\"顶点i\"的最短路径所经历的全部顶点中，位于\"顶点i\"之前的那个顶点。 *     dist -- 长度数组。即，dist[i]是\"顶点vs\"到\"顶点i\"的最短路径的长度。 */void MatrixUDG::dijkstra(int vs, int prev[], int dist[])&#123;    int i,j,k;    int min;    int tmp;    int flag[MAX];      // flag[i]=1表示\"顶点vs\"到\"顶点i\"的最短路径已成功获取。    // 初始化    for (i = 0; i &lt; mVexNum; i++)    &#123;        flag[i] = 0;              // 顶点i的最短路径还没获取到。        prev[i] = 0;              // 顶点i的前驱顶点为0。        dist[i] = mMatrix[vs][i]; // 顶点i的最短路径为\"顶点vs\"到\"顶点i\"的权。    &#125;    // 对\"顶点vs\"自身进行初始化    flag[vs] = 1;    dist[vs] = 0;    // 遍历mVexNum-1次；每次找出一个顶点的最短路径。    for (i = 1; i &lt; mVexNum; i++)    &#123;        // 寻找当前最小的路径；        // 即，在未获取最短路径的顶点中，找到离vs最近的顶点(k)。        min = INF;        for (j = 0; j &lt; mVexNum; j++)        &#123;            if (flag[j]==0 &amp;&amp; dist[j]&lt;min)            &#123;                min = dist[j];                k = j;            &#125;        &#125;        // 标记\"顶点k\"为已经获取到最短路径        flag[k] = 1;        // 修正当前最短路径和前驱顶点        // 即，当已经\"顶点k的最短路径\"之后，更新\"未获取最短路径的顶点的最短路径和前驱顶点\"。        for (j = 0; j &lt; mVexNum; j++)        &#123;            tmp = (mMatrix[k][j]==INF ? INF : (min + mMatrix[k][j]));            if (flag[j] == 0 &amp;&amp; (tmp  &lt; dist[j]) )            &#123;                dist[j] = tmp;                prev[j] = k;            &#125;        &#125;    &#125;    // 打印dijkstra最短路径的结果    cout &lt;&lt; \"dijkstra(\" &lt;&lt; mVexs[vs] &lt;&lt; \"): \" &lt;&lt; endl;    for (i = 0; i &lt; mVexNum; i++)        cout &lt;&lt; \"  shortest(\" &lt;&lt; mVexs[vs] &lt;&lt; \", \" &lt;&lt; mVexs[i] &lt;&lt; \")=\" &lt;&lt; dist[i] &lt;&lt; endl;&#125;\n 归并排序（递归）\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 归并排序_递归.cpp:// 以数组为例子#include \"stdafx.h\"#include&lt;iostream&gt;using namespace std;// 在原始数组上进行操作，将前后两个有序序列合并到一个临时数组中，并将合并后的数组复制给原始数组arrvoid merge(int arr[], int low, int middle, int high)&#123;\tint i, j, k;\ti = low; // low为第一个有序区的第一个元素\tj = middle + 1; // middle+1为第二个有序区的第一个元素\tk = 0;\tint *temp = new(nothrow) int[high - low + 1];\tif (!temp)\t&#123;\t\tcout &lt;&lt; \"内存分配失败！\" &lt;&lt; endl;\t\treturn;\t&#125;\t// 依次比较两个有序序列的第一个元素，将较小的一方存放到temp数组中\twhile (i &lt;= middle &amp;&amp; j &lt;= high)\t&#123;\t\tif (arr[i] &lt; arr[j])\t\t\ttemp[k++] = arr[i++];\t\telse\t\t\ttemp[k++] = arr[j++];\t&#125;\twhile (i &lt;= middle)\t\ttemp[k++] = arr[i++];\twhile (j &lt;= high)\t\ttemp[k++] = arr[j++];\t// 将排好序的存回arr中low到high该区间内\tfor (i = low, k = 0; i &lt;= high; i++, k++)\t\tarr[i] = temp[k];\t// 删除指针，由于指向的是数组，必须用delete []\tdelete[]temp;&#125;void mergeSort(int arr[], int low, int high)&#123;\t// 用递归应用二路归并函数实现排序——分治法\tif (low &lt; high)  //（是if，不是while！，且不含等号！否则死循环！）\t&#123;\t\tint mid = (low + high) / 2;\t\tmergeSort(arr, low, mid);\t\tmergeSort(arr, mid + 1, high);\t\tmerge(arr, low, mid, high);\t&#125;        else            return;&#125;int main()&#123;\tint x[] = &#123; -3,5,7,-7,4,1,0,9&#125;;\tint n = sizeof(x) / sizeof(int);\tmergeSort(x, 0, n-1);\tfor (int i = 0; i&lt;8; i++)\t\tcout &lt;&lt; x[i] &lt;&lt; \" \";\treturn 0;&#125;\n k路归并\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;#include &lt;iterator&gt;#include &lt;cstdlib&gt;using namespace std;template&lt;class T&gt; class MinHeap&#123;public:    MinHeap();    MinHeap(const size_t size);    ~MinHeap();    T get_min() const;    void delete_min();    void insert_element(const T&amp; e);    void adjust_min_heap(const size_t i);    size_t get_heap_size() const;    int compare(const T&amp; t1,const T&amp; t2);private:    T *heap;    size_t heap_size;&#125;;template&lt;class T&gt;MinHeap&lt;T&gt;::MinHeap():heap(NULL),heap_size(0)&#123;&#125;template&lt;class T&gt;MinHeap&lt;T&gt;::MinHeap(const size_t size)&#123;    if(!heap)        delete [] heap;    heap = new T[size+1];    heap_size = 0;&#125;template&lt;class T&gt;MinHeap&lt;T&gt;::~MinHeap()&#123;    if(!heap)        delete [] heap;    heap_size = 0;&#125;template&lt;class T&gt;T MinHeap&lt;T&gt;::get_min() const&#123;    if(heap_size &gt; 0)        return heap[1];    else        return T();&#125;template&lt;class T&gt;void MinHeap&lt;T&gt;::delete_min()&#123;    if(heap_size &gt; 0)    &#123;        heap[1] = heap[heap_size];        heap_size = heap_size - 1;        adjust_min_heap(1);    &#125;    else    &#123;        cout&lt;&lt;\"Error: the min heap is empty\"&lt;&lt;endl;    &#125;&#125;template&lt;class T&gt;void MinHeap&lt;T&gt;::insert_element(const T&amp; e)&#123;    size_t i,parent;    T temp;    heap_size = heap_size + 1;    heap[heap_size] = e;    i = heap_size;    parent = i/2;    while(i&gt;1 &amp;&amp; compare(heap[parent],heap[i]) &gt; 0)    &#123;        temp = heap[parent];        heap[parent] = heap[i];        heap[i] = temp;        i = parent;        parent = i/2;    &#125;&#125;template&lt;class T&gt;void MinHeap&lt;T&gt;::adjust_min_heap(const size_t i)&#123;    size_t left,right,least;    T temp;    left = i*2;    right = i*2+1;    if(left &lt;= heap_size &amp;&amp; compare(heap[left],heap[i]) &lt; 0)        least = left;    else        least = i;    if(right &lt;= heap_size &amp;&amp; compare(heap[right],heap[least]) &lt; 0)        least = right;    if(least != i)    &#123;        temp = heap[least];        heap[least] = heap[i];        heap[i] = temp;        adjust_min_heap(least);    &#125;&#125;template&lt;class T&gt;size_t MinHeap&lt;T&gt;::get_heap_size() const&#123;    return heap_size;&#125;template&lt;class T&gt;int MinHeap&lt;T&gt;::compare(const T&amp; t1,const T&amp; t2)&#123;    return (*t1-*t2);&#125;const static int k = 3;int main()&#123;    list&lt;int&gt; lists[k];    list&lt;int&gt;::iterator iters[k];    list&lt;int&gt; retlist;    list&lt;int&gt;::iterator retiter;    list&lt;int&gt;::iterator iter;    MinHeap&lt;list&lt;int&gt;::iterator&gt; minheap(k);    //first list &lt;12,24,52&gt;    lists[0].push_back(12);    lists[0].push_back(24);    lists[0].push_back(52);    cout&lt;&lt;\"First list: \";    for(iter=lists[0].begin();iter != lists[0].end();++iter)          cout&lt;&lt;*iter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    //second list &lt;9,32&gt;    lists[1].push_back(9);    lists[1].push_back(32);    cout&lt;&lt;\"Second list: \";    for(iter=lists[1].begin();iter != lists[1].end();++iter)          cout&lt;&lt;*iter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    //third list &lt;34,42,78&gt;    lists[2].push_back(34);    lists[2].push_back(42);    lists[2].push_back(78);    cout&lt;&lt;\"Third list: \";    for(iter=lists[2].begin();iter != lists[2].end();++iter)          cout&lt;&lt;*iter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    iters[0] = lists[0].begin();    iters[1] = lists[1].begin();    iters[2] = lists[2].begin();    minheap.insert_element(iters[0]);    minheap.insert_element(iters[1]);    minheap.insert_element(iters[2]);    while(minheap.get_heap_size())    &#123;        iter = minheap.get_min() ;        retlist.push_back(*iter);        minheap.delete_min();        ++iter;        if(iter != lists[0].end() &amp;&amp; iter != lists[1].end()           &amp;&amp;iter != lists[2].end())            minheap.insert_element(iter);    &#125;    cout&lt;&lt;\"Merge the there list is: \"&lt;&lt;endl;    for(retiter = retlist.begin();retiter!= retlist.end();retiter++)        cout&lt;&lt;*retiter&lt;&lt;\"-&gt;\";    cout&lt;&lt;\"NULL\"&lt;&lt;endl;    exit(0);&#125;\nHanyuu Furude @ 2019 all right saved.\n","plink":"hanyuulu.github.io/dataStructure/"},{"title":"Latex","date":"2018-12-01T01:09:23.000Z","updated":"2021-03-12T08:22:58.406Z","content":"\n\n\n描述\n渲染样式\n代码\n\n\n\n\nalpha\nα\\alphaα\n\\alpha\n\n\nAlpha\nA\\AlphaA\n\\Alpha\n\n\nbeta\nβ\\betaβ\n\\beta\n\n\nBeta\nB\\BetaB\n\\Beta\n\n\ngamma\nγ\\gammaγ\n\\gamma\n\n\nGamma\nΓ\\GammaΓ\n\\Gamma\n\n\ndelta\nδ\\deltaδ\n\\delta\n\n\nDelta\nΔ\\DeltaΔ\n\\Delta\n\n\nepsilon\nϵ\\epsilonϵ\n\\epsilon\n\n\nvarepsilon\nε\\varepsilonε\n\\varepsilon\n\n\nE\nEEE\nE\n\n\nzeta\nζ\\zetaζ\n\\zeta\n\n\nZeta\nZ\\ZetaZ\n\\Zeta\n\n\neta\nη\\etaη\n\\eta\n\n\nEta\nH\\EtaH\n\\Eta\n\n\ntheta\nθ\\thetaθ\n\\theta\n\n\nvartheta\nϑ\\varthetaϑ\n\\vartheta\n\n\nTheta\nΘ\\ThetaΘ\n\\Theta\n\n\niota\nι\\iotaι\n\\iota\n\n\nIota\nI\\IotaI\n\\Iota\n\n\nkappa\nκ\\kappaκ\n\\kappa\n\n\nKappa\nK\\KappaK\n\\Kappa\n\n\nlambda\nλ\\lambdaλ\n\\lambda\n\n\nLambda\nΛ\\LambdaΛ\n\\Lambda\n\n\nmu\nμ\\muμ\n\\mu\n\n\nMu\nM\\MuM\n\\Mu\n\n\nN\nNNN\n\\N\n\n\nxi\nξ\\xiξ\n\\xi\n\n\nXi\nΞ\\XiΞ\n\\Xi\n\n\no\nooo\n\\o\n\n\nO\nOOO\n\\O\n\n\npi\nπ\\piπ\n\\pi\n\n\nPi\nΠ\\PiΠ\n\\Pi\n\n\nrho\nρ\\rhoρ\n\\rho\n\n\nvarrho\nϱ\\varrhoϱ\n\\varrho\n\n\nP\nPPP\n\\P\n\n\nsigma\nσ\\sigmaσ\n\\sigma\n\n\nSigma\nΣ\\SigmaΣ\n\\Sigma\n\n\ntau\nτ\\tauτ\n\\tau\n\n\nT\nTTT\n\\T\n\n\nupsilon\nυ\\upsilonυ\n\\upsilon\n\n\nUpsilon\nΥ\\UpsilonΥ\n\\Upsilon\n\n\nphi\nϕ\\phiϕ\n\\phi\n\n\nvarphi\nφ\\varphiφ\n\\varphi\n\n\nPhi\nΦ\\PhiΦ\n\\Phi\n\n\npsi\nψ\\psiψ\n\\psi\n\n\nPsi\nΨ\\PsiΨ\n\\Psi\n\n\nomega\nω\\omegaω\n\\omega\n\n\nOmega\nΩ\\OmegaΩ\n\\Omega\n\n\n&amp;\n&amp;\\And&amp;\n\\and\n\n\n向上取整\n⌈x⌉\\lceil x \\rceil⌈x⌉\n\\lceil x \\rceil\n\n\n向下取整\n⌊x⌋\\lfloor x \\rfloor⌊x⌋\n\\floor x \\rfloor\n\n\n除法\nab\\frac{a}{b}ba​\n\\frac{a}{b}\n\n\n点乘\n⋅\\cdot⋅\n\\cdot\n\n\n求和\n∑abc\\sum_a^bc∑ab​c\n\\sum_a^bc\n\n\n分号\nab\\frac{a}{b}ba​\n\\frac{a}{b}\n\n\n积分\n∫01x\\int_0^1{x}∫01​x\n\\int_0^1{x}\n\n\n封闭积分\n∮01x\\oint_0^1{x}∮01​x\n\\oint_0^1{x}\n\n\n根号\nyx\\sqrt[x]{y}xy​\n\\sqrt[x]{y}\n\n\nmatrix\nabcd\\begin{matrix}a&amp;b\\\\c&amp;d\\end{matrix}ac​bd​\n\\begin{matrix}a&amp;\\c&amp;d\\end{matrix}\n\n\nmatrix\n(abcd)\\begin{pmatrix}a&amp;b\\\\c&amp;d\\end{pmatrix}(ac​bd​)\n\\begin{pmatrix}a&amp;\\c&amp;d\\end{pmatrix}\n\n\nmatrix\n[abcd]\\begin{bmatrix}a&amp;b\\\\c&amp;d\\end{bmatrix}[ac​bd​]\n\\begin{bmatrix}a&amp;\\c&amp;d\\end{bmatrix}\n\n\nmatrix\n{abcd}\\begin{Bmatrix}a&amp;b\\\\c&amp;d\\end{Bmatrix}{ac​bd​}\n\\begin{Bmatrix}a&amp;\\c&amp;d\\end{Bmatrix}\n\n\nmatrix\n∣abcd∣\\begin{vmatrix}a&amp;b\\\\c&amp;d\\end{vmatrix}∣∣∣∣​ac​bd​∣∣∣∣​\n\\begin{vmatrix}a&amp;\\c&amp;d\\end{vmatrix}\n\n\nmatrix\n∥abcd∥\\begin{Vmatrix}a&amp;b\\\\c&amp;d\\end{Vmatrix}∥∥∥∥​ac​bd​∥∥∥∥​\n\\begin{Vmatrix}a&amp;\\c&amp;d\\end{Vmatrix}\n\n\nuparrow\n↑\\uparrow↑\n\\uparrow\n\n\ndownarrow\n↓\\downarrow↓\n\\downarrow\n\n\nUparrow\n⇑\\Uparrow⇑\n\\Uparrow\n\n\nDownarrow\n⇓\\Downarrow⇓\n\\Downarrow\n\n\nupdownarrow\n↕\\updownarrow↕\n\\updownarrow\n\n\nUpdownarrow\n⇕\\Updownarrow⇕\n\\Updownarrow\n\n\nrightarrow\n→\\rightarrow→\n\\rightarrow\n\n\nleftarrow\n←\\leftarrow←\n\\leftarrow\n\n\nRightarrow\n⇒\\Rightarrow⇒\n\\Rightarrow\n\n\nLeftarrow\n⇐\\Leftarrow⇐\n\\Leftarrow\n\n\nleftrightarrow\n↔\\leftrightarrow↔\n\\leftrightarrow\n\n\nLeftrightarrow\n⇔\\Leftrightarrow⇔\n\\Leftrightarrow\n\n\nlongrightarrow\n⟶\\longrightarrow⟶\n\\longrightarrow\n\n\nongleftarrow\n⟵\\longleftarrow⟵\n\\longleftarrow\n\n\nLongrightarrow\n⟹\\Longrightarrow⟹\n\\Longrightarrow\n\n\nLongleftarrow\n⟸\\Longleftarrow⟸\n\\Longleftarrow\n\n\nlongleftrightarrow\n⟷\\longleftrightarrow⟷\n\\longleftrightarrow\n\n\nLongleftrightarrow\n⟺\\Longleftrightarrow⟺\n\\Longleftrightarrow\n\n\nmapsto\n↦\\mapsto↦\n\\mapsto\n\n\nlongmapsto\n⟼\\longmapsto⟼\n\\longmapsto\n\n\nhookleftarrow\n↩\\hookleftarrow↩\n\\hookleftarrow\n\n\nhookrightarrow\n↪\\hookrightarrow↪\n\\hookrightarrow\n\n\nleftharpoonup\n↼\\leftharpoonup↼\n\\leftharpoonup\n\n\nrightharpoonup\n⇀\\rightharpoonup⇀\n\\rightharpoonup\n\n\nleftharpoondown\n↽\\leftharpoondown↽\n\\leftharpoondown\n\n\nrightharpoondown\n⇁\\rightharpoondown⇁\n\\rightharpoondown\n\n\nrightleftharpoons\n⇌\\rightleftharpoons⇌\n\\rightleftharpoons\n\n\nleadsto\n⇝\\leadsto⇝\n\\leadsto\n\n\nnearrow\n↗\\nearrow↗\n\\nearrow\n\n\nsearrow\n↘\\searrow↘\n\\searrow\n\n\nswarrow\n↙\\swarrow↙\n\\swarrow\n\n\nnwarrow\n↖\\nwarrow↖\n\\nwarrow\n\n\nnleftarrow\n↚\\nleftarrow↚\n\\nleftarrow\n\n\nnrightarrow\n↛\\nrightarrow↛\n\\nrightarrow\n\n\nnLeftarrow\n⇍\\nLeftarrow⇍\n\\nLeftarrow\n\n\nnRightarrow\n⇏\\nRightarrow⇏\n\\nRightarrow\n\n\nnleftrightarrow\n↮\\nleftrightarrow↮\n\\nleftrightarrow\n\n\nnLeftrightarrow\n⇎\\nLeftrightarrow⇎\n\\nLeftrightarrow\n\n\ndashrightarrow\n⇢\\dashrightarrow⇢\n\\dashrightarrow\n\n\ndashleftarrow\n⇠\\dashleftarrow⇠\n\\dashleftarrow\n\n\nleftleftarrows\n⇇\\leftleftarrows⇇\n\\leftleftarrows\n\n\nleftrightarrows\n⇆\\leftrightarrows⇆\n\\leftrightarrows\n\n\nLleftarrow\n⇚\\Lleftarrow⇚\n\\Lleftarrow\n\n\ntwoheadleftarrow\n↞\\twoheadleftarrow↞\n\\twoheadleftarrow\n\n\nleftarrowtail\n↢\\leftarrowtail↢\n\\leftarrowtail\n\n\nlooparrowleft\n↫\\looparrowleft↫\n\\looparrowleft\n\n\nleftrightharpoons\n⇋\\leftrightharpoons⇋\n\\leftrightharpoons\n\n\ncurvearrowleft\n↶\\curvearrowleft↶\n\\curvearrowleft\n\n\ncirclearrowleft\n↺\\circlearrowleft↺\n\\circlearrowleft\n\n\nLsh\n↰\\Lsh↰\nLsh⇈\n\n\nupharpoonleft\n↿\\upharpoonleft↿\n\\upharpoonleft\n\n\ndownharpoonleft\n⇃\\downharpoonleft⇃\n\\downharpoonleft\n\n\nmultimap\n⊸\\multimap⊸\n\\multimap\n\n\nleftrightsquigarrow\n↭\\leftrightsquigarrow↭\n\\leftrightsquigarrow\n\n\nrightrightarrows\n⇉\\rightrightarrows⇉\n\\rightrightarrows\n\n\nrightleftarrows\n⇄\\rightleftarrows⇄\n\\rightleftarrows\n\n\nrightrightarrows\n⇉\\rightrightarrows⇉\n\\rightrightarrows\n\n\nrightleftarrows\n⇄\\rightleftarrows⇄\n\\rightleftarrows\n\n\ntwoheadrightarrow\n↠\\twoheadrightarrow↠\n\\twoheadrightarrow\n\n\nrightarrowtail\n↣\\rightarrowtail↣\n\\rightarrowtail\n\n\nlooparrowright\n↬\\looparrowright↬\n\\looparrowright\n\n\nrightleftharpoons\n⇌\\rightleftharpoons⇌\n\\rightleftharpoons\n\n\ncurvearrowright\n↷\\curvearrowright↷\n\\curvearrowright\n\n\ncirclearrowright\n↻\\circlearrowright↻\n\\circlearrowright\n\n\nRsh\n↱\\Rsh↱\nRsh\n\n\nupharpoonright\n↾\\upharpoonright↾\n\\upharpoonright\n\n\ndownharpoonright\n⇂\\downharpoonright⇂\n\\downharpoonright\n\n\nrightsquigarrow\n⇝\\rightsquigarrow⇝\n\\rightsquigarrow\n\n\n\n","plink":"hanyuulu.github.io/Latex/"},{"title":"清除windows更新缓存","date":"2018-10-20T00:00:00.000Z","updated":"2021-03-12T08:22:58.614Z","content":"我们将手动清除Windows Update缓存以修复Windows 10上的下载问题。在清除缓存之前，您需要停止Windows更新服务。 为此，请搜索“服务”并以管理员身份打开它。 找到“Windows Update”服务，右键单击它，然后选择“停止”选项。\n要清除缓存，请执行以下操作：\n\n\n按“Win + R”，进入C:\\WINDOWS\\SoftwareDistribution\\并按下Enter按钮。\n\n\n此文件夹包含与Windows更新相关的所有文件。\n\n\n选择所有文件并删除所有文件。\n\n\n您需要重新启动Windows Update。 为此，请再次打开服务并启动Windows Update服务。 要启动该服务，请右键单击该服务并在上下文菜单中选择开始。\n要安装最新更新，请导航到设置 - &gt;更新和安全 - &gt; Windows Update，并检查更新。\n","plink":"hanyuulu.github.io/windowsUpdateCacheClear/"},{"title":"OpenCV basic operations","date":"2018-10-02T00:00:00.000Z","updated":"2021-03-12T08:22:58.442Z","content":" 1.Accessing and Modifying pixel values\n\n12345678910import cv2import numpy as np# Load a color image.img = cv2.imread('example.jpg')px = img[100,100]print(px)# accessing only blue pixel# BGR color system!blue = img[100,100,0]print(blue)\n\nYou can access a pixel value by its row and column coordinates. For BGR image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned.\nYou can modify the pixel values the same way.\n\n12img[100,100]=[255,255,255]print(img[100,100])\n\nNumpy is a optimized library for fast array calculations. So simply accessing each and every pixel values and modifying it will be very slow and it is discouraged.\nAbove mentioned method is normally used for selecting a region of array, say first 5 rows and last 3 columns like that. For individual pixel access, Numpy array methods, and ```array.itemset()``` is considered to be better. But it always returns a scalar. So if you want to access all **B,G,R values**, you need to call ```array.item()``` separately for all.12345678* example: ```py# accessing RED valueimg.item(10,10,2)# modifying RED valueimg.itemset((10,10,2),100)img.item(10,10,2)\n\n 2. Accessing Image Properties\n\nimg.shape\n\n1print(img.shape)\n\nImage properties include number of rows, columns and channels, type of image data, number of pixels etc.\\\nShape of image is accessed by img.shape. It returns a tuple of number of rows, columns and channels (if image is color).\\\nIf image is grayscale, tuple returned contains only number of rows and columns. So it is a good method to check if loaded image is grayscale or color image.\nimg.size\n\n1print(img.size)\n\n\nTotal number of pixels is accessed by 123* img.dtype``` pyprint(img.dtype)\n\n\nis very important while debugging because a large number of errors in OpenCV-Python code is caused by invalid datatype.123456## 3. Image ROI* Sometimes, you will have to play with certain region of images. For eye detection in images, first perform face detection over the image until the face is found, then search within the face region for eyes. This approach improves accuracy (because eyes are always on faces :D ) and performance (because we search for a small area).* ROI is again obtained using Numpy indexing.``` pyclip = img[280:340, 330:390]img[273:333, 100:160] = clip\n\n\n 4.Splitting and Merging Image Channels\nThe B,G,R channels of an image can be split into their individual planes when needed. Then, the individual channels can be merged back together to form a BGR image again. This can be performed by:\n12b,g,r = cv2.split(img)img = cv2.merge((b,g,r))\nOr\n1b = img[:,:,0]\nSuppose, you want to make all the red pixels to zero, you need not split like this and put it equal to zero. You can simply use Numpy indexing which is faster.\n12# BRG color systemimg[:,:,2] = 0\n*is a costly operation (in terms of time), so only use it if necessary. Numpy indexing is much more efficient and should be used if possible.*1234567891011121314151617181920212223242526272829303132333435## 5.Making Borders for Images (Padding)If you want to create a border around the image, something like a photo frame, you can use ```cv2.copyMakeBorder()``` function. But it has more applications for convolution operation, zero padding etc. This function takes following arguments:* **src** - input image* **top, bottom, left, right** - border width in number of pixels in corresponding directions* **borderType - Flag defining what kind of border to be added. It can be following types:**   * **cv2.BORDER_CONSTANT** - Adds a constant colored border. The value should be given as next argument.   * **cv2.BORDER_REFLECT** - Border will be mirror reflection of the border elements, like this : fedcba|abcdefgh|hgfedcb   * **cv2.BORDER_REFLECT_101** or **cv2.BORDER_DEFAULT** - Same as above, but with a slight change, like this : gfedcb|abcdefgh|gfedcba   * **cv2.BORDER_REPLICATE** - Last element is replicated throughout, like this: aaaaaa|abcdefgh|hhhhhhh   * **cv2.BORDER_WRAP** - Can’t explain, it will look like this : cdefgh|abcdefgh|abcdefg* value - Color of border if border type is cv2.BORDER_CONSTANTBelow is a sample code demonstrating all these border types for better understanding:``` pyimport cv2import numpy as npfrom matplotlib import pyplot as pltBLUE = [255,0,0]img1 = cv2.imread(&apos;opencv_logo.png&apos;)replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)plt.subplot(231),plt.imshow(img1,&apos;gray&apos;),plt.title(&apos;ORIGINAL&apos;)plt.subplot(232),plt.imshow(replicate,&apos;gray&apos;),plt.title(&apos;REPLICATE&apos;)plt.subplot(233),plt.imshow(reflect,&apos;gray&apos;),plt.title(&apos;REFLECT&apos;)plt.subplot(234),plt.imshow(reflect101,&apos;gray&apos;),plt.title(&apos;REFLECT_101&apos;)plt.subplot(235),plt.imshow(wrap,&apos;gray&apos;),plt.title(&apos;WRAP&apos;)plt.subplot(236),plt.imshow(constant,&apos;gray&apos;),plt.title(&apos;CONSTANT&apos;)\nSee the result below. (Image is displayed with matplotlib. So RED and BLUE planes will be interchanged):\n\n\n Example\n123456789101112131415import cv2img = cv2.imread('example.jpg')print('img[300,300]=%s' % img[300,300])print('blue pixel %s' %img[300,300,0])print('green pixel %s' %img[300,300,1])print('red pixel %s' %img[300,300,2])print(img[300,300,3])cv2.imshow('img', img)k = cv2.waitKey(0)  # &amp; 0xffif k == 27:  # ESC\tcv2.destroyAllWindows()elif k == ord('s'):\tcv2.imwrite('Save.jpg', img)","plink":"hanyuulu.github.io/OpenCVBasicOperations/"},{"title":"OpenCV function reference","date":"2018-10-02T00:00:00.000Z","updated":"2021-03-12T08:22:58.442Z","content":" 1.图像读取\n\ncv2.imread()\n\n123import numpy as mpimport cv2img =cv2.imread('example.jpg',0)\n\nUse the function cv2.imread() to read an image. The image should be in the working directory or a full path of image should be given.[[/]]\nSecond argument is a flag which specifies the way image should be read.\\\n\ncv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\ncv2.IMREAD_GRAYSCALE : Loads image in grayscale mode\ncv2.IMREAD_UNCHANGED : Loads image as such including alpha channel\n\nInstead of these three flags, you can simply pass integers 1, 0 or -1 respectively.\n*Even if the image path is wrong, it won’t throw any error, but img``` will give you ```None```*1234567## 2.图像显示* cv2.inshow()``` pycv2.imshow(&apos;image&apos;,img)cv2.waitKey(0)cv2.destroyAllWindows()\n\n\n\n\nUse the function cv2.imshow() to display an image in a window. The window automatically fits to the image size. \nFirst argument is a window name which is a string. second argument is our image. You can create as many windows as you wish, but with different window names.\n\n\ncv2.waitKey()\n\n\ncv2.waitKey() is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke. It can also be set to detect specific key strokes like, if key a is pressed etc which we will discuss below.\n\n\nBesides binding keyboard events this function also processes many other GUI events, so you MUST use it to actually display the image.\n\n\n\n\ncv2.destoryAllWindows()\n\n\ncv2.destroyAllWindows() simply destroys all the windows we created. If you want to destroy any specific window, use the function cv2.destroyWindow() where you pass the exact window name as the argument.\n\n\nThere is a special case where you can already create a window and load image to it later. In that case, you can specify whether window is resizable or not. It is done with the function cv2.namedWindow(). By default, the flag is cv2.WINDOW_AUTOSIZE. But if you specify flag to be cv2.WINDOW_NORMAL, you can resize window. It will be helpful when image is too large in dimension and adding track bar to windows.\n\n\n\n 3.图像写入\n\ncv2.imwrite()\n\n1cv2.imwrite('messigray.png',img)\n\nUse the function cv2.imwrite() to save an image. \nFirst argument is the file name, second argument is the image you want to save.\n\n 4.SumUp\n1234567891011import numpy as npimport cv2img = cv2.imread('messi5.jpg',0)cv2.imshow('image',img)k = cv2.waitKey(0)if k == 27:         # wait for ESC key to exit    cv2.destroyAllWindows()elif k == ord('s'): # wait for 's' key to save and exit    cv2.imwrite('messigray.png',img)    cv2.destroyAllWindows()\n\n\n*If you are using a 64-bit machine, you will have to modify 12345678910111213141516171819202122## 5.视频写入&gt; 由于暂时没有需求，本部分暂时未深入，[跳转到相关链接](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html)## 6.绘画操作### common arguments&gt;* img : The image where you want to draw the shapes&gt;* color : Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.&gt;* thickness : Thickness of the line or circle etc. If -1 is passed for closed figures like circles, it will fill the shape. default thickness = 1&gt;* lineType : Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv2.LINE_AA gives anti-aliased line which looks great for curves.* cv2.line()``` pyimport numpy as npimport cv2# Create a black imageimg = np.zeros((512,512,3), np.uint8)# Draw a diagonal blue line with thickness of 5 pximg = cv2.line(img,(0,0),(511,511),(255,0,0),5)\n\n\n\ncv2.circle()\n\n1img = cv2.circle(img,(447,63), 63, (0,0,255), -1)\n\ncv2.rectangle()\n\n1img = cv2.rectangle(img,(384,0),(510,128),(0,255,0),3)\n\ncv2.ellipse()\n\n1img = cv2.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n\n\nTo draw the ellipse, we need to pass several arguments. One argument is the center location (x,y). Next argument is axes lengths (major axis length, minor axis length). is the angle of rotation of ellipse in anti-clockwise direction. ```startAngle``` and ```endAngle``` denotes the starting and ending of ellipse arc measured in clockwise direction from major axis. i.e. giving values 0 and 360 gives the full ellipse. For more details, check the documentation of ```cv2.ellipse()```. Below example draws a half ellipse at the center of the image.123456*  cv2.polylines()``` pypts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)pts = pts.reshape((-1,1,2))img = cv2.polylines(img,[pts],True,(0,255,255))\n\n\n\n\nTo draw a polygon, first you need coordinates of vertices. Make those points into an array of shape where ROWS are number of vertices and it should be of type ```int32```. Here we draw a small polygon of with four vertices in yellow color.123456&gt;* If third argument is False, you will get a polylines joining all the points, not a closed shape.&gt;* ```cv2.polylines()``` can be used to draw multiple lines. Just create a list of all the lines you want to draw and pass it to the function. All lines will be drawn individually. It is more better and faster way to draw a group of lines than calling ```cv2.line()``` for each line.* cv2.putText()``` pyfont = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img,&apos;OpenCV&apos;,(10,500), font, 4,(255,255,255),2,cv2.LINE_AA)\n\n\n\nTo put texts in images, you need specify following things.\n\nText data that you want to write\nPosition coordinates of where you want put it (i.e. bottom-left corner where data starts).\nFont type (Check cv2.putText() docs for supported fonts)\nFont Scale (specifies the size of font)\nregular things like color, thickness, lineType etc. For better look, lineType = cv2.LINE_AA is recommended.\n\n\n\n\n123456789101112131415161718192021222324252627282930313233&gt;Converts an image from one color space to another.&gt;* C++: void cvtColor(InputArray src, OutputArray dst, int code, int dstCn=0 )&gt; *  Python: cv2.cvtColor(src, code[, dst[, dstCn]]) → dst&gt; *  C: void cvCvtColor(const CvArr* src, CvArr* dst, int code)&gt; * s  Python: cv.CvtColor(src, dst, code) → None&gt;&gt;Parameters:&gt;* src – input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC… ), or single-precision floating-point.&gt;* dst  – output image of the same size and depth as src.&gt;* code – color space conversion code (see the description below).&gt;* dstCn – number of channels in the destination image; if the parameter is 0, the number of the channels is derived automatically from src and code.&gt;&gt; The function converts an input image from one color space to another. In case of a transformation to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.## 3. example``` pyimport cv2 as cv2import numpy as npimg=cv2.imread(&apos;a&apos;)img = cv2.imread(&apos;example.jpg&apos;, 1)font = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img, &apos;OpenCV&apos;, (10, 500), font, 4, (255, 0, 0), 2, cv2.LINE_AA)cv2.imshow(&apos;image&apos;, img)# Create a black imageimg = np.zeros((512, 512, 3), np.uint8)cv2.imshow(&apos;image0&apos;, img)# Draw a diagonal blue line with thickness of 5 pximg = cv2.line(img, (0, 0), (511, 511), (255, 0, 0), 5)cv2.imshow(&apos;image1&apos;, img)k = cv2.waitKey(0) &amp; 0xffaif k == 27:  # ESC    cv2.destroyAllWindows()elif k == ord(&apos;s&apos;):    cv2.imwrite(&apos;Save.jpg&apos;, img)\n\n","plink":"hanyuulu.github.io/OpenCVFunctionRef/"},{"title":"Python function reference","date":"2018-10-01T00:00:00.000Z","updated":"2021-03-12T08:22:58.442Z","content":" Sys\n\n sys模块包含了与python解释器和它的环境有关的函数，这个你可以通过dir(sys)来查看他里面的方法和成员属性。\n\n\n\n```  123456789101112查询系统环境变量，返回一个list。* ```sys.path.append(&apos;address&apos;)```  添加定义的搜索目录到环境变量。&gt;作用域仅在该脚本运行时，运行完毕即失效* ```sys.path.insert(0,&apos;address&apos;)```  同上，不过是插入。&gt;如果您想要添加永久路径  &gt;1.将py文件置于环境变量目录下(注意路径顺序和文件名冲突)  &gt;2.[尚未验证对python3是否可用]在 /usr/lib/python2.6/site-packages 下面新建一个.pth 文件(以pth作为后缀名)将模块的路径写进去，一行一个路径，如```vim pythonmodule.pth```  &gt;3.使用PYTHONPATH环境变量```export PYTHONPATH=$PYTHONPATH:/home/liu/shell/config\n\n","plink":"hanyuulu.github.io/PythonFunctionRef/"},{"title":"Python Excel file reader","date":"2018-10-01T00:00:00.000Z","updated":"2021-03-12T08:22:58.630Z","content":" python xlrd\n1、导入模块\nimport xlrd\n2、打开Excel文件读取数据\n1data = xlrd.open_workbook('excelFile.xls')\n3、使用方法\n获取一个工作表\n12345678910111213141516171819202122232425262728table = data.sheets()[0]      #通过索引顺序获取table = data.sheet_by_index(0) #通过索引顺序获取table = data.sheet_by_name(u'Sheet1')#通过名称获取#获取整行和整列的值（数组）table.row_values(i)table.col_values(i)#获取行数和列数nrows = table.nrowsncols = table.ncols#循环行列表数据for i in range(nrows ):print table.row_values(i)#单元格cell_A1 = table.cell(0,0).valuecell_C4 = table.cell(2,3).value#使用行列索引cell_A1 = table.row(0)[0].valuecell_A2 = table.col(1)[0].value#简单的写入row = 0col = 0#类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 errorctype = 1 value = '单元格的值'xf = 0 # 扩展的格式化table.put_cell(row, col, ctype, value, xf)table.cell(0,0)  #单元格的值'table.cell(0,0).value #单元格的值'# python xlrd\n Demo\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# -*- coding: utf-8 -*- import  xdrlib ,sysimport xlrddef open_excel(file= 'file.xls'):    try:        data = xlrd.open_workbook(file)        return data    except Exception,e:        print str(e)#根据索引获取Excel表格中的数据   参数:file：Excel文件路径     colnameindex：表头列名所在行的所以  ，by_index：表的索引def excel_table_byindex(file= 'file.xls',colnameindex=0,by_index=0):    data = open_excel(file)    table = data.sheets()[by_index]    nrows = table.nrows #行数    ncols = table.ncols #列数    colnames =  table.row_values(colnameindex) #某一行数据     list =[]    for rownum in range(1,nrows):         row = table.row_values(rownum)         if row:             app = &#123;&#125;             for i in range(len(colnames)):                app[colnames[i]] = row[i]              list.append(app)    return list#根据名称获取Excel表格中的数据   参数:file：Excel文件路径     colnameindex：表头列名所在行的所以  ，by_name：Sheet1名称def excel_table_byname(file= 'file.xls',colnameindex=0,by_name=u'Sheet1'):    data = open_excel(file)    table = data.sheet_by_name(by_name)    nrows = table.nrows #行数     colnames =  table.row_values(colnameindex) #某一行数据     list =[]    for rownum in range(1,nrows):         row = table.row_values(rownum)         if row:             app = &#123;&#125;             for i in range(len(colnames)):                app[colnames[i]] = row[i]             list.append(app)    return listdef main():   tables = excel_table_byindex()   for row in tables:       print row   tables = excel_table_byname()   for row in tables:       print rowif __name__==\"__main__\":    main()","plink":"hanyuulu.github.io/xlrd/"},{"title":"Hanyuu's  blog.","date":"2018-01-01T00:00:00.000Z","updated":"2021-03-12T08:22:58.382Z","content":"\n该站点目前由GitHub Actions自动部署\n最近更新：\n\n12345678                  ##         .            ## ## ##        ==         ## ## ## ## ##    ===     /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ ===~~~ &#123;~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~     \\______ o           __/       \\    \\         __/        \\____\\_______/\n\nCopyright © 2017-2020 Hanyuu Lu  All Right Reserved\n\n","plink":"hanyuulu.github.io/Blog/"},{"title":"LICENSE","date":"2018-01-01T00:00:00.000Z","updated":"2021-03-12T08:22:58.562Z","content":"123456789The MIT License (MIT)Copyright (c) 2018-2019 Hanyuu FurudePermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sub license, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NON INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","plink":"hanyuulu.github.io/license/"},{"title":"Title","date":"2000-03-05T00:00:00.000Z","updated":"2021-03-12T08:22:58.378Z","content":"","plink":"hanyuulu.github.io/Template/"}]